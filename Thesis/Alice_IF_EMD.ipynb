{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5b15b5ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: MacOSX\n"
     ]
    }
   ],
   "source": [
    "%matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "11613b5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import re\n",
    "from pprint import pprint\n",
    "\n",
    "import numpy as np\n",
    "from scipy import signal, ndimage\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import pyplot\n",
    "import pandas as pd\n",
    "\n",
    "import emd\n",
    "import eelbrain\n",
    "import mne\n",
    "import trftools"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a79a8f6e",
   "metadata": {},
   "source": [
    "## How to get the IF from the envelope, and turn it into the TRF?\n",
    "\n",
    "1. Load in the envelope\n",
    "2. Emd sift the envelope\n",
    "3. Save the IF value\n",
    "4. Pack the IF value with the sensor\n",
    "5. Calculate the IF's TRF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "81c8e883",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['S13_Alice-natives_sfreq-100_raw.fif', 'S14_Alice-natives_sfreq-100_raw.fif', 'S12_Alice-natives_sfreq-100_raw.fif', 'S15_Alice-natives_sfreq-100_raw.fif', 'S11_Alice-natives_sfreq-100_raw.fif', 'S16_Alice-natives_sfreq-100_raw.fif', 'S17_Alice-natives_sfreq-100_raw.fif', 'S18_Alice-natives_sfreq-100_raw.fif', 'S19_Alice-natives_sfreq-100_raw.fif', 'S20_Alice-natives_sfreq-100_raw.fif', 'S21_Alice-natives_sfreq-100_raw.fif', 'S01_Alice-natives_sfreq-100_raw.fif', 'S03_Alice-natives_sfreq-100_raw.fif', 'S04_Alice-natives_sfreq-100_raw.fif', 'S05_Alice-natives_sfreq-100_raw.fif', 'S06_Alice-natives_sfreq-100_raw.fif', 'S08_Alice-natives_sfreq-100_raw.fif', 'S10_Alice-natives_sfreq-100_raw.fif', 'S22_Alice-natives_sfreq-100_raw.fif', 'S25_Alice-natives_sfreq-100_raw.fif', 'S26_Alice-natives_sfreq-100_raw.fif', 'S34_Alice-natives_sfreq-100_raw.fif', 'S35_Alice-natives_sfreq-100_raw.fif', 'S36_Alice-natives_sfreq-100_raw.fif', 'S37_Alice-natives_sfreq-100_raw.fif', 'S38_Alice-natives_sfreq-100_raw.fif', 'S39_Alice-natives_sfreq-100_raw.fif', 'S40_Alice-natives_sfreq-100_raw.fif', 'S41_Alice-natives_sfreq-100_raw.fif', 'S42_Alice-natives_sfreq-100_raw.fif', 'S44_Alice-natives_sfreq-100_raw.fif', 'S45_Alice-natives_sfreq-100_raw.fif', 'S48_Alice-natives_sfreq-100_raw.fif']\n",
      "33\n"
     ]
    }
   ],
   "source": [
    "## NATIVES ##\n",
    "\n",
    "STIMULI = [str(i) for i in range(1, 13)]\n",
    "DATA_ROOT = Path(\"/Volumes/Neurolang_1/Master Program/New_Thesis_topic/Experiments_Results\")  #Path(\"~\").expanduser() / 'Data' / 'Alice'\n",
    "PREDICTOR_audio_DIR = DATA_ROOT / 'TRFs_pridictors/audio_predictors'\n",
    "PREDICTOR_word_DIR = DATA_ROOT / 'TRFs_pridictors/word_predictors'\n",
    "EEG_DIR = DATA_ROOT / 'EEG_Natives' / 'Alice_natives_ICAed_fif'\n",
    "Native_SUBJECTS = [path.name for path in EEG_DIR.iterdir() if re.match(r'S\\d*', path.name)]\n",
    "# Define a target directory for TRF estimates and make sure the directory is created\n",
    "TRF_DIR = DATA_ROOT / 'TRFs_Natives'\n",
    "TRF_DIR.mkdir(exist_ok=True)\n",
    "print(Native_SUBJECTS)\n",
    "print(len(Native_SUBJECTS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "01186976",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(73654,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\n# Plot every envelope (Don't know why it all overlay into one figs)\\nfor i in range(0, 2):\\n    p = None\\n    print(envelope[i].get_data())\\n    p = plt.plot(envelope[i].get_data())\\n\""
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the broad-band envelope from the gammatone pickle files\n",
    "envelope = [eelbrain.load.unpickle(PREDICTOR_audio_DIR / f'{stimulus}~gammatone-1.pickle') for stimulus in STIMULI]  # Load in the data\n",
    "\"\"\"# Code Explanation\n",
    "envelopeL = []\n",
    "for stimulus in STIMULI:\n",
    "    envelope = eelbrain.load.unpickle(PREDICTOR_audio_DIR / f'{stimulus}~gammatone-1.pickle')\n",
    "    print(envelope)\n",
    "    envelopeL.append(envelope)\n",
    "\"\"\"\n",
    "# To down sample into 100 Hz\n",
    "envelope = [x.bin(0.01, dim='time', label='start') for x in envelope]\n",
    "#print(envelope)\n",
    "\"\"\" # Code Explanation\n",
    "envelopeL_2 = []\n",
    "for x in envelope:\n",
    "    envelope = x.bin(0.01, dim='time', label='start')\n",
    "    envelopeL_2.append(envelope)\n",
    "\"\"\"\n",
    "# To covert it into the NDVar structures\n",
    "envelope = [trftools.pad(x, tstart=-0.100, tstop=x.time.tstop + 1, name='envelope') for x in envelope]\n",
    "\"\"\" # Code Explanation\n",
    "envelopeL_3 = []\n",
    "for x in envelope:\n",
    "    envelope = trftools.pad(x, tstart=-0.100, tstop=x.time.tstop + 1, name='envelope')\n",
    "    envelopeL_3.append(envelope)\n",
    "print(envelopeL_3)\n",
    "\"\"\"\n",
    "n_envelope = np.concatenate(envelope)\n",
    "\n",
    "print(n_envelope.shape)\n",
    "#dir(envelope[1])\n",
    "#print(envelope[1].get_data())\n",
    "\n",
    "\"\"\"\n",
    "# Plot every envelope (Don't know why it all overlay into one figs)\n",
    "for i in range(0, 2):\n",
    "    p = None\n",
    "    print(envelope[i].get_data())\n",
    "    p = plt.plot(envelope[i].get_data())\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "20432fcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21.51142955 10.75571477  5.37785739  2.68892869  1.34446435  0.67223217]\n",
      "(5862, 6)\n",
      "(5862, 6)\n",
      "[18.86807686  9.43403843  4.71701922  2.35850961  1.1792548   0.5896274 ]\n",
      "(6193, 6)\n",
      "(12055, 6)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/h7/sdf5cvgx3qzf5rh744693x0r0000gn/T/ipykernel_69032/3230898397.py:26: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  n_IF_ndARRAY = np.concatenate(np.array(IF_ndarrayLIST))   #np.concatenate(np.array(IF_ndarrayLIST)).shape == (73654, 6)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23.70220703 11.85110351  5.92555176  2.96277588  1.48138794  0.74069397]\n",
      "(6434, 6)\n",
      "(18489, 6)\n",
      "[22.66779232 11.33389616  5.66694808  2.83347404  1.41673702  0.70836851]\n",
      "(7107, 6)\n",
      "(25596, 6)\n",
      "[23.21852732 11.60926366  5.80463183  2.90231591  1.45115796  0.72557898]\n",
      "(6736, 6)\n",
      "(32332, 6)\n",
      "[22.4525975  11.22629875  5.61314938  2.80657469  1.40328734  0.70164367]\n",
      "(6487, 6)\n",
      "(38819, 6)\n",
      "[22.8508909  11.42544545  5.71272273  2.85636136  1.42818068  0.71409034]\n",
      "(6398, 6)\n",
      "(45217, 6)\n",
      "[21.77598904 10.88799452  5.44399726  2.72199863  1.36099931  0.68049966]\n",
      "(5839, 6)\n",
      "(51056, 6)\n",
      "[21.08557709 10.54278854  5.27139427  2.63569714  1.31784857  0.65892428]\n",
      "(5831, 6)\n",
      "(56887, 6)\n",
      "[21.98877306 10.99438653  5.49719326  2.74859663  1.37429832  0.68714916]\n",
      "(6235, 6)\n",
      "(63122, 6)\n",
      "[21.72925764 10.86462882  5.43231441  2.71615721  1.3580786   0.6790393 ]\n",
      "(5725, 6)\n",
      "(68847, 6)\n",
      "[21.67672145 10.83836072  5.41918036  2.70959018  1.35479509  0.67739755]\n",
      "(4807, 6)\n",
      "(73654, 6)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\n[18.86807686  9.43403843  4.71701922  2.35850961  1.1792548   0.5896274 ]>> = 每個IMF最多的頻率\\n# 每個ＩＭＦ的順時頻率都做一個TRF 去跑統計\\n4hz>> close to the syllables, 18 hz >> close to phoneme speed, but normally we consider syllables as speed\\n>> use the third IMF >> \\n# IP, IF, IA = emd.spectra.frequency_transform(imf, sample_rate, 'hilbert') get the IF\\n\""
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_rate = 100\n",
    "\"\"\"  # For IMF & IF testing commands\n",
    "imf, mask_freqs = emd.sift.mask_sift(envelope[1].get_data(), ret_mask_freq=True, max_imfs=6)  \n",
    "# delete >>, mask_freqs=30/sample_rate\n",
    "# xy = envelope data \n",
    "#print(mask_freqs * sample_rate)\n",
    "#emd.plotting.plot_imfs(imf)\n",
    "IP, IF, IA = emd.spectra.frequency_transform(imf, sample_rate, 'nht')\n",
    "\n",
    "pprint(IF[1:])\n",
    "print(IF.shape)\n",
    "#print(IF)\n",
    "\"\"\"\n",
    "# \n",
    "\n",
    "IF_ndarrayLIST = []\n",
    "for i in range(0, 12):\n",
    "    imf, mask_freqs = emd.sift.mask_sift(envelope[i].get_data(), ret_mask_freq=True, max_imfs=6)  \n",
    "    # delete >>, mask_freqs=30/sample_rate   # xy = envelope data \n",
    "    print(mask_freqs * sample_rate)\n",
    "    #emd.plotting.plot_imfs(imf)\n",
    "    IP, IF, IA = emd.spectra.frequency_transform(imf, sample_rate, 'hilbert') #get the IF\n",
    "    IF_lenINT = IF.shape[0]\n",
    "    print(IF.shape) # ==(len(IF.shape[0]), 6))\n",
    "    IF_ndarrayLIST.append(IF)\n",
    "    n_IF_ndARRAY = np.concatenate(np.array(IF_ndarrayLIST))   #np.concatenate(np.array(IF_ndarrayLIST)).shape == (73654, 6)\n",
    "    print(n_IF_ndARRAY.shape)\n",
    "\n",
    "    \n",
    "\n",
    "\"\"\"\n",
    "dataDICT = pd.DataFrame(IF, columns = ['IMF1','IMF2','IMF3', 'IMF4','IMF5','IMF6'])\n",
    "file_name = 'ALL_IF_TRF_predictor_testing_tables.csv'\n",
    "save_path = DATA_ROOT/ \"TRFs_pridictors\" / Path(file_name)\n",
    "dataDICT.to_csv(save_path, sep = \",\" ,index = False , header = True, encoding = \"UTF-8\")\n",
    "\"\"\"\n",
    "\"\"\"\n",
    "[18.86807686  9.43403843  4.71701922  2.35850961  1.1792548   0.5896274 ]>> = 每個IMF最多的頻率\n",
    "# 每個ＩＭＦ的順時頻率都做一個TRF 去跑統計\n",
    "4hz>> close to the syllables, 18 hz >> close to phoneme speed, but normally we consider syllables as speed\n",
    ">> use the third IMF >> \n",
    "# IP, IF, IA = emd.spectra.frequency_transform(imf, sample_rate, 'hilbert') get the IF\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "866364f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To save the IF into a csv file\n",
    "dataDICT = pd.DataFrame(IF, columns = ['IMF1','IMF2','IMF3', 'IMF4','IMF5','IMF6'])\n",
    "#data_path = Path(\"/Volumes/Neurolang_1/Master Program/New_Thesis_topic/Experiments_Results/TRFs_pridictors\")\n",
    "file_name = 'IF_TRF_predictor_testing_tables.csv'\n",
    "save_path = DATA_ROOT/ \"TRFs_pridictors\" / Path(file_name)\n",
    "dataDICT.to_csv(save_path, sep = \",\" ,index = False , header = True, encoding = \"UTF-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "bbf4f85c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['S13_Alice-natives_sfreq-100_raw.fif', 'S14_Alice-natives_sfreq-100_raw.fif', 'S12_Alice-natives_sfreq-100_raw.fif', 'S15_Alice-natives_sfreq-100_raw.fif', 'S11_Alice-natives_sfreq-100_raw.fif', 'S16_Alice-natives_sfreq-100_raw.fif', 'S17_Alice-natives_sfreq-100_raw.fif', 'S18_Alice-natives_sfreq-100_raw.fif', 'S19_Alice-natives_sfreq-100_raw.fif', 'S20_Alice-natives_sfreq-100_raw.fif', 'S21_Alice-natives_sfreq-100_raw.fif', 'S01_Alice-natives_sfreq-100_raw.fif', 'S03_Alice-natives_sfreq-100_raw.fif', 'S04_Alice-natives_sfreq-100_raw.fif', 'S05_Alice-natives_sfreq-100_raw.fif', 'S06_Alice-natives_sfreq-100_raw.fif', 'S08_Alice-natives_sfreq-100_raw.fif', 'S10_Alice-natives_sfreq-100_raw.fif', 'S22_Alice-natives_sfreq-100_raw.fif', 'S25_Alice-natives_sfreq-100_raw.fif', 'S26_Alice-natives_sfreq-100_raw.fif', 'S34_Alice-natives_sfreq-100_raw.fif', 'S35_Alice-natives_sfreq-100_raw.fif', 'S36_Alice-natives_sfreq-100_raw.fif', 'S37_Alice-natives_sfreq-100_raw.fif', 'S38_Alice-natives_sfreq-100_raw.fif', 'S39_Alice-natives_sfreq-100_raw.fif', 'S40_Alice-natives_sfreq-100_raw.fif', 'S41_Alice-natives_sfreq-100_raw.fif', 'S42_Alice-natives_sfreq-100_raw.fif', 'S44_Alice-natives_sfreq-100_raw.fif', 'S45_Alice-natives_sfreq-100_raw.fif', 'S48_Alice-natives_sfreq-100_raw.fif']\n",
      "33\n",
      "[<NDVar 'envelope': 5862 time>, <NDVar 'envelope': 6193 time>, <NDVar 'envelope': 6434 time>, <NDVar 'envelope': 7107 time>, <NDVar 'envelope': 6736 time>, <NDVar 'envelope': 6487 time>, <NDVar 'envelope': 6398 time>, <NDVar 'envelope': 5839 time>, <NDVar 'envelope': 5831 time>, <NDVar 'envelope': 6235 time>, <NDVar 'envelope': 5725 time>, <NDVar 'envelope': 4807 time>]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/h7/sdf5cvgx3qzf5rh744693x0r0000gn/T/ipykernel_69032/3354584463.py:120: RuntimeWarning: No bad channels to interpolate. Doing nothing...\n",
      "  raw.interpolate_bads()\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding:utf-8 -*-\n",
    "\n",
    "\"\"\"This script estimates TRFs for several models and saves them\"\"\"\n",
    "from pathlib import Path\n",
    "import re\n",
    "\n",
    "import eelbrain\n",
    "import mne\n",
    "import trftools\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    STIMULI = [str(i) for i in range(1, 13)]\n",
    "    DATA_ROOT = Path(\"/Volumes/Neurolang_1/Master Program/New_Thesis_topic/Experiments_Results\")#Path(\"/Volumes/Neurolang_1/Master Program/New_Thesis_topic/Experiments_Results\")  #Path(\"~\").expanduser() / 'Data' / 'Alice'\n",
    "    PREDICTOR_audio_DIR = DATA_ROOT / 'TRFs_pridictors/audio_predictors'\n",
    "    PREDICTOR_word_DIR = DATA_ROOT / 'TRFs_pridictors/word_predictors'\n",
    "    EEG_DIR = DATA_ROOT / 'EEG_Natives' / 'Alice_natives_ICAed_fif'\n",
    "    SUBJECTS = [path.name for path in EEG_DIR.iterdir() if re.match(r'S\\d*', path.name[:4])]\n",
    "    # Define a target directory for TRF estimates and make sure the directory is created\n",
    "    TRF_DIR = DATA_ROOT / 'TRFs_Natives'\n",
    "    TRF_DIR.mkdir(exist_ok=True)\n",
    "    print(SUBJECTS)\n",
    "    print(len(SUBJECTS))\n",
    "    \n",
    "    # Load stimuli\n",
    "    # ------------\n",
    "    # Make sure to name the stimuli so that the TRFs can later be distinguished\n",
    "    # Load the gammatone-spectrograms; use the time axis of these as reference\n",
    "    gammatone = [eelbrain.load.unpickle(PREDICTOR_audio_DIR / f'{stimulus}~gammatone-8.pickle') for stimulus in STIMULI]\n",
    "    \n",
    "    # Resample the spectrograms to 100 Hz (time-step = 0.01 s), which we will use for TRFs\n",
    "    gammatone = [x.bin(0.01, dim='time', label='start') for x in gammatone]\n",
    "    \n",
    "    # Pad onset with 100 ms and offset with 1 second; make sure to give the predictor a unique name as that will make it easier to identify the TRF later\n",
    "    gammatone = [trftools.pad(x, tstart=-0.100, tstop=x.time.tstop + 1, name='gammatone') for x in gammatone]\n",
    "    #\"\"\"\n",
    "    # Load the broad-band envelope and process it in the same way\n",
    "    envelope = [eelbrain.load.unpickle(PREDICTOR_audio_DIR / f'{stimulus}~gammatone-1.pickle') for stimulus in STIMULI]  # Load in the data\n",
    "    envelope = [x.bin(0.01, dim='time', label='start') for x in envelope]\n",
    "    envelope = [trftools.pad(x, tstart=-0.100, tstop=x.time.tstop + 1, name='envelope') for x in envelope]\n",
    "    onset_envelope = [eelbrain.load.unpickle(PREDICTOR_audio_DIR / f'{stimulus}~gammatone-on-1.pickle') for stimulus in STIMULI]\n",
    "    onset_envelope = [x.bin(0.01, dim='time', label='start') for x in onset_envelope]\n",
    "    onset_envelope = [trftools.pad(x, tstart=-0.100, tstop=x.time.tstop + 1, name='onset') for x in onset_envelope]\n",
    "    \n",
    "    # Load onset spectrograms and make sure the time dimension is equal to the gammatone spectrograms\n",
    "    gammatone_onsets = [eelbrain.load.unpickle(PREDICTOR_audio_DIR / f'{stimulus}~gammatone-on-8.pickle') for stimulus in STIMULI]\n",
    "    gammatone_onsets = [x.bin(0.01, dim='time', label='start') for x in gammatone_onsets]\n",
    "    gammatone_onsets = [eelbrain.set_time(x, gt.time, name='gammatone_on') for x, gt in zip(gammatone_onsets, gammatone)]\n",
    "    #\"\"\"\n",
    "    # Load word tables and convert tables into continuous time-series with matching time dimension\n",
    "    word_tables = [eelbrain.load.unpickle(PREDICTOR_word_DIR / f'{stimulus}~Ngram-CFG_word.pickle') for stimulus in STIMULI]\n",
    "    word_onsets = [eelbrain.event_impulse_predictor(gt.time, ds=ds, name='word') for gt, ds in zip(gammatone, word_tables)] # not sure why they could get the word onset this way\n",
    "    \n",
    "    # Function and content word impulses based on the boolean variables in the word-tables\n",
    "    word_lexical = [eelbrain.event_impulse_predictor(gt.time, value='lexical', ds=ds, name='lexical') for gt, ds in zip(gammatone, word_tables)]\n",
    "    word_nlexical = [eelbrain.event_impulse_predictor(gt.time, value='nlexical', ds=ds, name='non_lexical') for gt, ds in zip(gammatone, word_tables)]\n",
    "    \n",
    "    # NGRAM/CFG word impulses based on the values in the word-tables\n",
    "    word_Ngram = [eelbrain.event_impulse_predictor(gt.time, value='NGRAM', ds=ds, name='n-gram') for gt, ds in zip(gammatone, word_tables)]\n",
    "    word_CFG = [eelbrain.event_impulse_predictor(gt.time, value='CFG', ds=ds, name='cfg') for gt, ds in zip(gammatone, word_tables)]\n",
    "    \n",
    "    # Extract the duration of the stimuli, so we can later match the EEG to the stimuli\n",
    "    durations = [gt.time.tmax for stimulus, gt in zip(STIMULI, gammatone)]\n",
    "    \n",
    "    # Models\n",
    "    # ------\n",
    "    # Pre-define models here to have easier access during estimation. In the future, additional models could be added here and the script re-run to generate additional TRFs.\n",
    "    models = {\n",
    "        # Acoustic models\n",
    "        'envelope': [envelope],\n",
    "        'envelope+onset': [envelope, onset_envelope],\n",
    "        'acoustic': [gammatone, gammatone_onsets],\n",
    "        \n",
    "        # Models with word-onsets and word-class\n",
    "        'words': [word_onsets],\n",
    "        'words+lexical': [word_onsets, word_lexical, word_nlexical],\n",
    "        'acoustic+words': [gammatone, gammatone_onsets, word_onsets],\n",
    "        'acoustic+words+lexical': [gammatone, gammatone_onsets, word_onsets, word_lexical, word_nlexical],\n",
    "\n",
    "        # Language Models\n",
    "        'Ngram': [word_Ngram, word_onsets, word_lexical, word_nlexical],\n",
    "        'CFG': [word_CFG, word_onsets, word_lexical, word_nlexical],\n",
    "        'Ngram-CFG_all': [word_Ngram, word_CFG, word_onsets, word_lexical, word_nlexical]\n",
    "\n",
    "    }\n",
    "    \"\"\"\n",
    "    # Acoustic models\n",
    "    'envelope': [envelope],\n",
    "    'envelope+onset': [envelope, onset_envelope],\n",
    "    'acoustic': [gammatone, gammatone_onsets],\n",
    "    # Models with word-onsets and word-class\n",
    "    'words': [word_onsets],\n",
    "    'words+lexical': [word_onsets, word_lexical, word_nlexical],\n",
    "    'acoustic+words': [gammatone, gammatone_onsets, word_onsets],\n",
    "    'acoustic+words+lexical': [gammatone, gammatone_onsets, word_onsets, word_lexical, word_nlexical],\n",
    "    # Language Models\n",
    "    'Ngram': [word_Ngram, word_onsets, word_lexical, word_nlexical],\n",
    "    'CFG': [word_CFG, word_onsets, word_lexical, word_nlexical],\n",
    "    'Ngram-CFG_all': [word_Ngram, word_CFG, word_onsets, word_lexical, word_nlexical]\n",
    "    \"\"\"    \n",
    "    \n",
    "    print(envelope)\n",
    "    # Estimate TRFs\n",
    "    # -------------\n",
    "    # Loop through subjects to estimate TRFs\n",
    "    for subject in SUBJECTS:\n",
    "        subject_trf_dir = TRF_DIR / subject[:3]\n",
    "        subject_trf_dir.mkdir(exist_ok=True)\n",
    "        # Generate all TRF paths so we can check whether any new TRFs need to be estimated\n",
    "        trf_paths = {model: subject_trf_dir / f'{subject[:3]} {model}.pickle' for model in models}\n",
    "        # Skip this subject if all files already exist\n",
    "        #if all(path.exists() for path in trf_paths.values()):\n",
    "            #continue\n",
    "        # Load the EEG data\n",
    "        raw = mne.io.read_raw_fif(EEG_DIR / f'{subject}', preload=True)  # subject /\n",
    "        # Band-pass filter the raw data between 0.5 and 20 Hz\n",
    "        raw.filter(0.5, 20)\n",
    "        # Interpolate bad channels\n",
    "        raw.interpolate_bads()\n",
    "        # Extract the events marking the stimulus presentation from the EEG file\n",
    "        events = eelbrain.load.fiff.events(raw)\n",
    "        # Not all subjects have all trials; determine which stimuli are present\n",
    "        trial_indexes = [STIMULI.index(stimulus) for stimulus in events['event']]\n",
    "        # Extract the EEG data segments corresponding to the stimuli\n",
    "        trial_durations = [durations[i] for i in trial_indexes]\n",
    "        eeg = eelbrain.load.fiff.variable_length_epochs(events, -0.100, trial_durations, connectivity='auto')  #, decim=5 #decim=5 meaning to resample to sfreq=100Hz\n",
    "        # Since trials are of unequal length, we will concatenate them for the TRF estimation.\n",
    "        eeg_concatenated = eelbrain.concatenate(eeg)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f4d6850",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
