{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5b15b5ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: MacOSX\n"
     ]
    }
   ],
   "source": [
    "%matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "11613b5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import re\n",
    "from pprint import pprint\n",
    "\n",
    "import numpy as np\n",
    "from scipy import signal, ndimage\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import pyplot\n",
    "import pandas as pd\n",
    "\n",
    "import emd\n",
    "import eelbrain\n",
    "import mne\n",
    "import trftools"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a79a8f6e",
   "metadata": {},
   "source": [
    "## How to get the IF from the envelope, and turn it into the TRF?\n",
    "\n",
    "1. Load in the envelope\n",
    "2. Emd sift the envelope\n",
    "3. Save the IF value\n",
    "4. Pack the IF value with the sensor\n",
    "5. Calculate the IF's TRF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "81c8e883",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['S13_Alice-natives_sfreq-100_raw.fif', 'S14_Alice-natives_sfreq-100_raw.fif', 'S12_Alice-natives_sfreq-100_raw.fif', 'S15_Alice-natives_sfreq-100_raw.fif', 'S11_Alice-natives_sfreq-100_raw.fif', 'S16_Alice-natives_sfreq-100_raw.fif', 'S17_Alice-natives_sfreq-100_raw.fif', 'S18_Alice-natives_sfreq-100_raw.fif', 'S19_Alice-natives_sfreq-100_raw.fif', 'S20_Alice-natives_sfreq-100_raw.fif', 'S21_Alice-natives_sfreq-100_raw.fif', 'S01_Alice-natives_sfreq-100_raw.fif', 'S03_Alice-natives_sfreq-100_raw.fif', 'S04_Alice-natives_sfreq-100_raw.fif', 'S05_Alice-natives_sfreq-100_raw.fif', 'S06_Alice-natives_sfreq-100_raw.fif', 'S08_Alice-natives_sfreq-100_raw.fif', 'S10_Alice-natives_sfreq-100_raw.fif', 'S22_Alice-natives_sfreq-100_raw.fif', 'S25_Alice-natives_sfreq-100_raw.fif', 'S26_Alice-natives_sfreq-100_raw.fif', 'S34_Alice-natives_sfreq-100_raw.fif', 'S35_Alice-natives_sfreq-100_raw.fif', 'S36_Alice-natives_sfreq-100_raw.fif', 'S37_Alice-natives_sfreq-100_raw.fif', 'S38_Alice-natives_sfreq-100_raw.fif', 'S39_Alice-natives_sfreq-100_raw.fif', 'S40_Alice-natives_sfreq-100_raw.fif', 'S41_Alice-natives_sfreq-100_raw.fif', 'S42_Alice-natives_sfreq-100_raw.fif', 'S44_Alice-natives_sfreq-100_raw.fif', 'S45_Alice-natives_sfreq-100_raw.fif', 'S48_Alice-natives_sfreq-100_raw.fif']\n",
      "33\n"
     ]
    }
   ],
   "source": [
    "## NATIVES ##\n",
    "\n",
    "STIMULI = [str(i) for i in range(1, 13)]\n",
    "DATA_ROOT = Path(\"/Volumes/Neurolang_1/Master Program/New_Thesis_topic/Experiments_Results\")  #Path(\"~\").expanduser() / 'Data' / 'Alice'\n",
    "PREDICTOR_audio_DIR = DATA_ROOT / 'TRFs_pridictors/audio_predictors'\n",
    "PREDICTOR_word_DIR = DATA_ROOT / 'TRFs_pridictors/word_predictors'\n",
    "EEG_DIR = DATA_ROOT / 'EEG_Natives' / 'Alice_natives_ICAed_fif'\n",
    "Native_SUBJECTS = [path.name for path in EEG_DIR.iterdir() if re.match(r'S\\d*', path.name)]\n",
    "# Define a target directory for TRF estimates and make sure the directory is created\n",
    "TRF_DIR = DATA_ROOT / 'TRFs_Natives'\n",
    "TRF_DIR.mkdir(exist_ok=True)\n",
    "print(Native_SUBJECTS)\n",
    "print(len(Native_SUBJECTS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "01186976",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<NDVar 'DownTheRabbitHoleFinal_SoundFile1.wav': 5753 time>, <NDVar 'DownTheRabbitHoleFinal_SoundFile2.wav': 6084 time>, <NDVar 'DownTheRabbitHoleFinal_SoundFile3.wav': 6325 time>, <NDVar 'DownTheRabbitHoleFinal_SoundFile4.wav': 6998 time>, <NDVar 'DownTheRabbitHoleFinal_SoundFile5.wav': 6627 time>, <NDVar 'DownTheRabbitHoleFinal_SoundFile6.wav': 6377 time>, <NDVar 'DownTheRabbitHoleFinal_SoundFile7.wav': 6289 time>, <NDVar 'DownTheRabbitHoleFinal_SoundFile8.wav': 5730 time>, <NDVar 'DownTheRabbitHoleFinal_SoundFile9.wav': 5722 time>, <NDVar 'DownTheRabbitHoleFinal_SoundFile10.wav': 6126 time>, <NDVar 'DownTheRabbitHoleFinal_SoundFile11.wav': 5616 time>, <NDVar 'DownTheRabbitHoleFinal_SoundFile12.wav': 4698 time>]\n",
      "(73665,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\n# Plot every envelope (Don't know why it all overlay into one figs)\\nfor i in range(0, 2):\\n    p = None\\n    print(envelope[i].get_data())\\n    p = plt.plot(envelope[i].get_data())\\n\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the broad-band envelope from the gammatone pickle files\n",
    "envelope = [eelbrain.load.unpickle(PREDICTOR_audio_DIR / f'{stimulus}~gammatone-1.pickle') for stimulus in STIMULI]  # Load in the data\n",
    "\"\"\"# Code Explanation\n",
    "envelopeL = []\n",
    "for stimulus in STIMULI:\n",
    "    envelope = eelbrain.load.unpickle(PREDICTOR_audio_DIR / f'{stimulus}~gammatone-1.pickle')\n",
    "    print(envelope)\n",
    "    envelopeL.append(envelope)\n",
    "\"\"\"\n",
    "# To down sample into 100 Hz\n",
    "envelope = [x.bin(0.01, dim='time', label='start') for x in envelope]\n",
    "print(envelope)\n",
    "\"\"\" # Code Explanation\n",
    "envelopeL_2 = []\n",
    "for x in envelope:\n",
    "    envelope = x.bin(0.01, dim='time', label='start')\n",
    "    envelopeL_2.append(envelope)\n",
    "\"\"\"\n",
    "# To covert it into the NDVar structures\n",
    "envelope = [trftools.pad(x, tstart=-0.100, tstop=x.time.tstop + 1, name='envelope') for x in envelope]\n",
    "\"\"\" # Code Explanation\n",
    "envelopeL_3 = []\n",
    "for x in envelope:\n",
    "    envelope = trftools.pad(x, tstart=-0.100, tstop=x.time.tstop + 1, name='envelope')\n",
    "    envelopeL_3.append(envelope)\n",
    "print(envelopeL_3)\n",
    "\"\"\"\n",
    "n_envelope = np.concatenate(envelope)\n",
    "\n",
    "print(n_envelope.shape)\n",
    "#dir(envelope[1])\n",
    "#print(envelope[1].get_data())\n",
    "\n",
    "\"\"\"\n",
    "# Plot every envelope (Don't know why it all overlay into one figs)\n",
    "for i in range(0, 2):\n",
    "    p = None\n",
    "    print(envelope[i].get_data())\n",
    "    p = plt.plot(envelope[i].get_data())\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "20432fcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6, 5863)\n",
      "(6, 6194)\n",
      "(6, 6435)\n",
      "(6, 7108)\n",
      "(6, 6737)\n",
      "(6, 6487)\n",
      "(6, 6399)\n",
      "(6, 5840)\n",
      "(6, 5832)\n",
      "(6, 6236)\n",
      "(6, 5726)\n",
      "(6, 4808)\n",
      "12\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n# Saving the self_paced_rt result into csv file\\ndataDICT = pd.DataFrame({\\'IMF_1\\':IMF_1_LIST,\\n                        \\'IMF_2\\':IMF_2_LIST,\\n                        \\'IMF_3\\':IMF_3_LIST,\\n                        \\'IMF_4\\':IMF_4_LIST,\\n                        \\'IMF_5\\':IMF_5_LIST,\\n                        \\'IMF_6\\':IMF_6_LIST,\\n                           })\\n                           \\n#data_path = \"/Users/ting-hsin/Docs/Github/ICN_related/\"\\nfile_name = \\'Alice_IF_TRF_predictor_tables.csv\\'\\nsave_path = DATA_ROOT/ \"TRFs_pridictors\" / Path(file_name)\\ndataDICT.to_csv(save_path, sep = \",\" ,index = False , header = True, encoding = \"UTF-8\")\\n'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "[18.86807686  9.43403843  4.71701922  2.35850961  1.1792548   0.5896274 ]>> = 每個IMF最多的頻率\n",
    "# 每個ＩＭＦ的順時頻率都做一個TRF 去跑統計\n",
    "4hz>> close to the syllables, 18 hz >> close to phoneme speed, but normally we consider syllables as speed\n",
    ">> use the third IMF >> \n",
    "# IP, IF, IA = emd.spectra.frequency_transform(imf, sample_rate, 'hilbert') get the IF\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"  # For IMF & IF testing commands\n",
    "imf, mask_freqs = emd.sift.mask_sift(envelope[1].get_data(), ret_mask_freq=True, max_imfs=6)  \n",
    "# delete >>, mask_freqs=30/sample_rate\n",
    "# xy = envelope data \n",
    "#print(mask_freqs * sample_rate)\n",
    "#emd.plotting.plot_imfs(imf)\n",
    "IP, IF, IA = emd.spectra.frequency_transform(imf, sample_rate, 'nht')\n",
    "\n",
    "pprint(IF[1:])\n",
    "print(IF.shape)\n",
    "#print(IF)\n",
    "\"\"\"\n",
    "\n",
    "sample_rate = 100\n",
    "## To extract the IF out of the IMFs\n",
    "# Create blank LISTs to save data\n",
    "IF_ndarrayLIST = []\n",
    "IMF_1_LIST = []\n",
    "IMF_2_LIST = []\n",
    "IMF_3_LIST = []\n",
    "IMF_4_LIST = []\n",
    "IMF_5_LIST = []\n",
    "IMF_6_LIST = []\n",
    "\n",
    "# To get every tape of its IMF, then get the IF out of it\n",
    "for i in range(0, 12):\n",
    "    imf, mask_freqs = emd.sift.mask_sift(envelope[i].get_data(), ret_mask_freq=True, max_imfs=6)  \n",
    "    # delete >>, mask_freqs=30/sample_rate   # xy = envelope data \n",
    "    #print(mask_freqs * sample_rate)\n",
    "    #emd.plotting.plot_imfs(imf)\n",
    "    IP, IF, IA = emd.spectra.frequency_transform(imf, sample_rate, 'hilbert') #get the IF\n",
    "    n_IF = IF.T\n",
    "    print(n_IF.shape)\n",
    "    IF_ndarrayLIST.append(n_IF)\n",
    "print(len(IF_ndarrayLIST))\n",
    "\n",
    "# Rearrange the IF according to the IMF\n",
    "for IMF_IF in IF_ndarrayLIST:\n",
    "    #print(IF_ndarrayLIST.index(IMF_IF))\n",
    "    #print(type(IMF_IF))\n",
    "    #print(len(IMF_IF))\n",
    "    IMF_1_LIST.append(IMF_IF[0])\n",
    "    IMF_2_LIST.append(IMF_IF[1])\n",
    "    IMF_3_LIST.append(IMF_IF[2])\n",
    "    IMF_4_LIST.append(IMF_IF[3])\n",
    "    IMF_5_LIST.append(IMF_IF[4])\n",
    "    IMF_6_LIST.append(IMF_IF[5])\n",
    "\n",
    "\"\"\"\n",
    "# Saving the self_paced_rt result into csv file\n",
    "dataDICT = pd.DataFrame({'IMF_1':IMF_1_LIST,\n",
    "                        'IMF_2':IMF_2_LIST,\n",
    "                        'IMF_3':IMF_3_LIST,\n",
    "                        'IMF_4':IMF_4_LIST,\n",
    "                        'IMF_5':IMF_5_LIST,\n",
    "                        'IMF_6':IMF_6_LIST,\n",
    "                           })\n",
    "                           \n",
    "#data_path = \"/Users/ting-hsin/Docs/Github/ICN_related/\"\n",
    "file_name = 'Alice_IF_TRF_predictor_tables.csv'\n",
    "save_path = DATA_ROOT/ \"TRFs_pridictors\" / Path(file_name)\n",
    "dataDICT.to_csv(save_path, sep = \",\" ,index = False , header = True, encoding = \"UTF-8\")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "db8b9aa2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "<class 'numpy.ndarray'>\n",
      "[ 1.61084993e+00  1.61084993e+00  5.34091200e+00 ...  2.63400413e-12\n",
      " -1.46658436e-09 -1.47169858e-09]\n",
      "6194\n"
     ]
    }
   ],
   "source": [
    "print(type(IMF_1_LIST))\n",
    "print(type(IMF_1_LIST[1]))\n",
    "print(IMF_1_LIST[1])\n",
    "print(len(IMF_1_LIST[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4205d3dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tstep = 1. / mdata['Fs'][0, 0]\n",
    "# To save the IMF into NDVar one by one (change the IMF_[123]_LIST's num)\n",
    "IMF_NDVar = []\n",
    "\n",
    "for i in range(12):\n",
    "    tstep = 1/100  # sampling rate's 倒數\n",
    "    n_times = len(IMF_6_LIST[i])\n",
    "    time = eelbrain.UTS(0, tstep=tstep, nsamples=n_times) # UTS(-0.1, tstep=tstep, nsamples=n_times+100)\n",
    "    tmpIMF_ = eelbrain.NDVar(IMF_6_LIST[i], (time,), name='IMF_6')\n",
    "    #IMF_ = trftools.pad(tmpIMF_, tstart=-0.100, tstop=tmpIMF_.time.tstop + 1, name='IMF_1')\n",
    "    IMF_NDVar.append(tmpIMF_)\n",
    "#print(IMF__NDVar)\n",
    "#print(type(IMF_1_NDVar))\n",
    "\n",
    "# save the IMF into pickle files\n",
    "IMF_save_path = DATA_ROOT/ \"TRFs_pridictors/IF_predictors\" / Path(\"Alice_IF_IMF_6.pickle\")\n",
    "eelbrain.save.pickle(IMF_NDVar, IMF_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "6b10bdc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alice_IF_IMF_1.pickle\n",
      "Alice_IF_IMF_2.pickle\n",
      "Alice_IF_IMF_3.pickle\n",
      "Alice_IF_IMF_4.pickle\n",
      "Alice_IF_IMF_5.pickle\n",
      "Alice_IF_IMF_6.pickle\n",
      "[[<NDVar 'IMF_1': 5863 time>, <NDVar 'IMF_1': 6194 time>, <NDVar 'IMF_1': 6435 time>, <NDVar 'IMF_1': 7108 time>, <NDVar 'IMF_1': 6737 time>, <NDVar 'IMF_1': 6487 time>, <NDVar 'IMF_1': 6399 time>, <NDVar 'IMF_1': 5840 time>, <NDVar 'IMF_1': 5832 time>, <NDVar 'IMF_1': 6236 time>, <NDVar 'IMF_1': 5726 time>, <NDVar 'IMF_1': 4808 time>], [<NDVar 'IMF_2': 5863 time>, <NDVar 'IMF_2': 6194 time>, <NDVar 'IMF_2': 6435 time>, <NDVar 'IMF_2': 7108 time>, <NDVar 'IMF_2': 6737 time>, <NDVar 'IMF_2': 6487 time>, <NDVar 'IMF_2': 6399 time>, <NDVar 'IMF_2': 5840 time>, <NDVar 'IMF_2': 5832 time>, <NDVar 'IMF_2': 6236 time>, <NDVar 'IMF_2': 5726 time>, <NDVar 'IMF_2': 4808 time>], [<NDVar 'IMF_3': 5863 time>, <NDVar 'IMF_3': 6194 time>, <NDVar 'IMF_3': 6435 time>, <NDVar 'IMF_3': 7108 time>, <NDVar 'IMF_3': 6737 time>, <NDVar 'IMF_3': 6487 time>, <NDVar 'IMF_3': 6399 time>, <NDVar 'IMF_3': 5840 time>, <NDVar 'IMF_3': 5832 time>, <NDVar 'IMF_3': 6236 time>, <NDVar 'IMF_3': 5726 time>, <NDVar 'IMF_3': 4808 time>], [<NDVar 'IMF_4': 5863 time>, <NDVar 'IMF_4': 6194 time>, <NDVar 'IMF_4': 6435 time>, <NDVar 'IMF_4': 7108 time>, <NDVar 'IMF_4': 6737 time>, <NDVar 'IMF_4': 6487 time>, <NDVar 'IMF_4': 6399 time>, <NDVar 'IMF_4': 5840 time>, <NDVar 'IMF_4': 5832 time>, <NDVar 'IMF_4': 6236 time>, <NDVar 'IMF_4': 5726 time>, <NDVar 'IMF_4': 4808 time>], [<NDVar 'IMF_5': 5863 time>, <NDVar 'IMF_5': 6194 time>, <NDVar 'IMF_5': 6435 time>, <NDVar 'IMF_5': 7108 time>, <NDVar 'IMF_5': 6737 time>, <NDVar 'IMF_5': 6487 time>, <NDVar 'IMF_5': 6399 time>, <NDVar 'IMF_5': 5840 time>, <NDVar 'IMF_5': 5832 time>, <NDVar 'IMF_5': 6236 time>, <NDVar 'IMF_5': 5726 time>, <NDVar 'IMF_5': 4808 time>], [<NDVar 'IMF_6': 5863 time>, <NDVar 'IMF_6': 6194 time>, <NDVar 'IMF_6': 6435 time>, <NDVar 'IMF_6': 7108 time>, <NDVar 'IMF_6': 6737 time>, <NDVar 'IMF_6': 6487 time>, <NDVar 'IMF_6': 6399 time>, <NDVar 'IMF_6': 5840 time>, <NDVar 'IMF_6': 5832 time>, <NDVar 'IMF_6': 6236 time>, <NDVar 'IMF_6': 5726 time>, <NDVar 'IMF_6': 4808 time>]]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "# just checking whether all IMFs were included\n",
    "IMF_DIR = DATA_ROOT/ \"TRFs_pridictors/IF_predictors\"\n",
    "All_IMFs_LIST = []\n",
    "for IMFs_name in IMFsLIST:\n",
    "    tmpIMF = eelbrain.load.unpickle(IMF_DIR / IMFs_name)\n",
    "    All_IMFs_LIST.append(tmpIMF)\n",
    "    print(IMFs_name)\n",
    "print(All_IMFs_LIST)\n",
    "#IMFs = [eelbrain.load.unpickle(IMF_save_path / IMFs_name) ]\n",
    "#print(IMFs)\n",
    "#print(len(IMFs))\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b8a6ea9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['S13_Alice-natives_sfreq-100_raw.fif', 'S14_Alice-natives_sfreq-100_raw.fif', 'S12_Alice-natives_sfreq-100_raw.fif', 'S15_Alice-natives_sfreq-100_raw.fif', 'S11_Alice-natives_sfreq-100_raw.fif', 'S16_Alice-natives_sfreq-100_raw.fif', 'S17_Alice-natives_sfreq-100_raw.fif', 'S18_Alice-natives_sfreq-100_raw.fif', 'S19_Alice-natives_sfreq-100_raw.fif', 'S20_Alice-natives_sfreq-100_raw.fif', 'S21_Alice-natives_sfreq-100_raw.fif', 'S01_Alice-natives_sfreq-100_raw.fif', 'S03_Alice-natives_sfreq-100_raw.fif', 'S04_Alice-natives_sfreq-100_raw.fif', 'S05_Alice-natives_sfreq-100_raw.fif', 'S06_Alice-natives_sfreq-100_raw.fif', 'S08_Alice-natives_sfreq-100_raw.fif', 'S10_Alice-natives_sfreq-100_raw.fif', 'S22_Alice-natives_sfreq-100_raw.fif', 'S25_Alice-natives_sfreq-100_raw.fif', 'S26_Alice-natives_sfreq-100_raw.fif', 'S34_Alice-natives_sfreq-100_raw.fif', 'S35_Alice-natives_sfreq-100_raw.fif', 'S36_Alice-natives_sfreq-100_raw.fif', 'S37_Alice-natives_sfreq-100_raw.fif', 'S38_Alice-natives_sfreq-100_raw.fif', 'S39_Alice-natives_sfreq-100_raw.fif', 'S40_Alice-natives_sfreq-100_raw.fif', 'S41_Alice-natives_sfreq-100_raw.fif', 'S42_Alice-natives_sfreq-100_raw.fif', 'S44_Alice-natives_sfreq-100_raw.fif', 'S45_Alice-natives_sfreq-100_raw.fif', 'S48_Alice-natives_sfreq-100_raw.fif']\n",
      "33\n",
      "['Alice_IF_IMF_1.pickle', 'Alice_IF_IMF_2.pickle', 'Alice_IF_IMF_3.pickle', 'Alice_IF_IMF_4.pickle', 'Alice_IF_IMF_5.pickle', 'Alice_IF_IMF_6.pickle']\n"
     ]
    }
   ],
   "source": [
    "# Making the TRF now (testing)\n",
    "STIMULI = [str(i) for i in range(1, 13)]\n",
    "DATA_ROOT = Path(\"/Volumes/Neurolang_1/Master Program/New_Thesis_topic/Experiments_Results\")#Path(\"/Volumes/Neurolang_1/Master Program/New_Thesis_topic/Experiments_Results\")  #Path(\"~\").expanduser() / 'Data' / 'Alice'\n",
    "EEG_DIR = DATA_ROOT / 'EEG_Natives' / 'Alice_natives_ICAed_fif'\n",
    "IMF_DIR = DATA_ROOT/ \"TRFs_pridictors/IF_predictors\"\n",
    "IMFsLIST = [path.name for path in IMF_DIR.iterdir() if re.match(r'Alice_IF_IMF_*', path.name)]\n",
    "SUBJECTS = [path.name for path in EEG_DIR.iterdir() if re.match(r'S\\d*', path.name[:4])]\n",
    "# Define a target directory for TRF estimates and make sure the directory is created\n",
    "TRF_DIR = DATA_ROOT / 'TRFs_Natives'\n",
    "TRF_DIR.mkdir(exist_ok=True)\n",
    "print(SUBJECTS)\n",
    "print(len(SUBJECTS))\n",
    "print(IMFsLIST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "611a5335",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  59 out of  59 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimating: S13 ~ IMF_1\n",
      "[<NDVar 'IMF_1': 73665 time>]\n"
     ]
    }
   ],
   "source": [
    "# Make sure to name the stimuli so that the TRFs can later be distinguished\n",
    "# Load the gammatone-spectrograms; use the time axis of these as reference\n",
    "gammatone = [eelbrain.load.unpickle(PREDICTOR_audio_DIR / f'{stimulus}~gammatone-8.pickle') for stimulus in STIMULI]\n",
    "\n",
    "# Resample the spectrograms to 100 Hz (time-step = 0.01 s), which we will use for TRFs\n",
    "gammatone = [x.bin(0.01, dim='time', label='start') for x in gammatone]\n",
    "\n",
    "# Pad onset with 100 ms and offset with 1 second; make sure to give the predictor a unique name as that will make it easier to identify the TRF later\n",
    "gammatone = [trftools.pad(x, tstart=-0.100, tstop=x.time.tstop + 1, name='gammatone') for x in gammatone]\n",
    "\n",
    "# Extract the duration of the stimuli, so we can later match the EEG to the stimuli\n",
    "durations = [gt.time.tmax for stimulus, gt in zip(STIMULI, gammatone)]\n",
    "\n",
    "imf_1 = eelbrain.load.unpickle(IMF_DIR / IMFsLIST[0])\n",
    "imf_2 = eelbrain.load.unpickle(IMF_DIR / IMFsLIST[1])\n",
    "imf_3 = eelbrain.load.unpickle(IMF_DIR / IMFsLIST[2])\n",
    "imf_4 = eelbrain.load.unpickle(IMF_DIR / IMFsLIST[3])\n",
    "imf_5 = eelbrain.load.unpickle(IMF_DIR / IMFsLIST[4])\n",
    "imf_6 = eelbrain.load.unpickle(IMF_DIR / IMFsLIST[5])\n",
    "# Models\n",
    "# ------\n",
    "# Pre-define models here to have easier access during estimation. In the future, additional models could be added here and the script re-run to generate additional TRFs.\n",
    "models = {\n",
    "    # IFs\n",
    "    'IMF_1':[imf_1],\n",
    "    'IMF_2':[imf_2],\n",
    "    'IMF_3':[imf_3],\n",
    "    'IMF_4':[imf_4],\n",
    "    'IMF_5':[imf_5],\n",
    "    'IMF_6':[imf_6],\n",
    "}\n",
    "\"\"\"\n",
    "# Acoustic models\n",
    "'envelope': [envelope],\n",
    "'envelope+onset': [envelope, onset_envelope],\n",
    "'acoustic': [gammatone, gammatone_onsets],\n",
    "# Models with word-onsets and word-class\n",
    "'words': [word_onsets],\n",
    "'words+lexical': [word_onsets, word_lexical, word_nlexical],\n",
    "'acoustic+words': [gammatone, gammatone_onsets, word_onsets],\n",
    "'acoustic+words+lexical': [gammatone, gammatone_onsets, word_onsets, word_lexical, word_nlexical],\n",
    "# Language Models\n",
    "'Ngram': [word_Ngram, word_onsets, word_lexical, word_nlexical],\n",
    "'CFG': [word_CFG, word_onsets, word_lexical, word_nlexical],\n",
    "'Ngram-CFG_all': [word_Ngram, word_CFG, word_onsets, word_lexical, word_nlexical]\n",
    "# F0 & IF\n",
    "'IF': [IMFs]\n",
    "# IFs\n",
    "    'IMF_1':[imf_1],\n",
    "    'IMF_2':[imf_2],\n",
    "    'IMF_3':[imf_3],\n",
    "    'IMF_4':[imf_4],\n",
    "    'IMF_5':[imf_5],\n",
    "    'IMF_6':[imf_6],\n",
    "\"\"\"    \n",
    "# Estimate TRFs\n",
    "# -------------\n",
    "# Loop through subjects to estimate TRFs\n",
    "for subject in SUBJECTS[:1]:\n",
    "    subject_trf_dir = TRF_DIR / subject[:3]\n",
    "    subject_trf_dir.mkdir(exist_ok=True)\n",
    "    # Generate all TRF paths so we can check whether any new TRFs need to be estimated\n",
    "    trf_paths = {model: subject_trf_dir / f'{subject[:3]} {model}.pickle' for model in models}\n",
    "    # Skip this subject if all files already exist\n",
    "    #if all(path.exists() for path in trf_paths.values()):\n",
    "        #continue\n",
    "    # Load the EEG data\n",
    "    raw = mne.io.read_raw_fif(EEG_DIR / f'{subject}', preload=True)  # subject /\n",
    "    # Band-pass filter the raw data between 0.5 and 20 Hz\n",
    "    raw.filter(0.5, 20)\n",
    "    # Interpolate bad channels\n",
    "    raw.interpolate_bads()\n",
    "    # Extract the events marking the stimulus presentation from the EEG file\n",
    "    events = eelbrain.load.fiff.events(raw)\n",
    "    # Not all subjects have all trials; determine which stimuli are present\n",
    "    trial_indexes = [STIMULI.index(stimulus) for stimulus in events['event']]\n",
    "    # Extract the EEG data segments corresponding to the stimuli\n",
    "    trial_durations = [durations[i] for i in trial_indexes]\n",
    "    eeg = eelbrain.load.fiff.variable_length_epochs(events, -0.100, trial_durations, connectivity='auto')  #, decim=5 #decim=5 meaning to resample to sfreq=100Hz\n",
    "    # Since trials are of unequal length, we will concatenate them for the TRF estimation.\n",
    "    eeg_concatenated = eelbrain.concatenate(eeg)\n",
    "    for model, predictors in models.items():\n",
    "        path = trf_paths[model]\n",
    "        # Skip if this file already exists\n",
    "        #if path.exists():\n",
    "            #continue\n",
    "        print(f\"Estimating: {subject[:3]} ~ {model}\")\n",
    "        # Select and concetenate the predictors corresponding to the EEG trials\n",
    "        predictors_concatenated = []\n",
    "        for predictor in predictors:\n",
    "            #print(predictor)\n",
    "            predictors_concatenated.append(eelbrain.concatenate([predictor[i] for i in trial_indexes]))\n",
    "        print(predictors_concatenated)\n",
    "        # Fit the mTRF\n",
    "        trf = eelbrain.boosting(eeg_concatenated, predictors_concatenated, -0.100, 1.000, error='l1', basis=0.050, partitions=5, test=1, selective_stopping=True)\n",
    "        p = eelbrain.plot.TopoButterfly(trf.h_scaled)\n",
    "        p\n",
    "        # Save the TRF for later analysis\n",
    "        #eelbrain.save.pickle(trf, path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8d811d2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
