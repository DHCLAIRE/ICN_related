{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5b15b5ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: <object object at 0x108772310>\n"
     ]
    }
   ],
   "source": [
    "%matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "11613b5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import re\n",
    "from pprint import pprint\n",
    "\n",
    "import numpy as np\n",
    "from scipy import signal, ndimage\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import pyplot\n",
    "import pandas as pd\n",
    "\n",
    "import emd\n",
    "import eelbrain\n",
    "import mne\n",
    "import trftools"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a79a8f6e",
   "metadata": {},
   "source": [
    "## How to get the IF from the envelope, and turn it into the TRF?\n",
    "\n",
    "1. Load in the envelope\n",
    "2. Emd sift the envelope\n",
    "3. Save the IF value\n",
    "4. Pack the IF value with the sensor\n",
    "5. Calculate the IF's TRF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "81c8e883",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['S13_Alice-natives_sfreq-100_raw.fif', 'S14_Alice-natives_sfreq-100_raw.fif', 'S12_Alice-natives_sfreq-100_raw.fif', 'S15_Alice-natives_sfreq-100_raw.fif', 'S11_Alice-natives_sfreq-100_raw.fif', 'S16_Alice-natives_sfreq-100_raw.fif', 'S17_Alice-natives_sfreq-100_raw.fif', 'S18_Alice-natives_sfreq-100_raw.fif', 'S19_Alice-natives_sfreq-100_raw.fif', 'S20_Alice-natives_sfreq-100_raw.fif', 'S21_Alice-natives_sfreq-100_raw.fif', 'S01_Alice-natives_sfreq-100_raw.fif', 'S03_Alice-natives_sfreq-100_raw.fif', 'S04_Alice-natives_sfreq-100_raw.fif', 'S05_Alice-natives_sfreq-100_raw.fif', 'S06_Alice-natives_sfreq-100_raw.fif', 'S08_Alice-natives_sfreq-100_raw.fif', 'S10_Alice-natives_sfreq-100_raw.fif', 'S22_Alice-natives_sfreq-100_raw.fif', 'S25_Alice-natives_sfreq-100_raw.fif', 'S26_Alice-natives_sfreq-100_raw.fif', 'S34_Alice-natives_sfreq-100_raw.fif', 'S35_Alice-natives_sfreq-100_raw.fif', 'S36_Alice-natives_sfreq-100_raw.fif', 'S37_Alice-natives_sfreq-100_raw.fif', 'S38_Alice-natives_sfreq-100_raw.fif', 'S39_Alice-natives_sfreq-100_raw.fif', 'S40_Alice-natives_sfreq-100_raw.fif', 'S41_Alice-natives_sfreq-100_raw.fif', 'S42_Alice-natives_sfreq-100_raw.fif', 'S44_Alice-natives_sfreq-100_raw.fif', 'S45_Alice-natives_sfreq-100_raw.fif', 'S48_Alice-natives_sfreq-100_raw.fif']\n",
      "33\n"
     ]
    }
   ],
   "source": [
    "## NATIVES ##\n",
    "\n",
    "STIMULI = [str(i) for i in range(1, 13)]\n",
    "DATA_ROOT = Path(\"/Volumes/Neurolang_1/Master Program/New_Thesis_topic/Experiments_Results\")  #Path(\"~\").expanduser() / 'Data' / 'Alice'\n",
    "PREDICTOR_audio_DIR = DATA_ROOT / 'TRFs_pridictors/audio_predictors'\n",
    "PREDICTOR_word_DIR = DATA_ROOT / 'TRFs_pridictors/word_predictors'\n",
    "EEG_DIR = DATA_ROOT / 'EEG_Natives' / 'Alice_natives_ICAed_fif'\n",
    "Native_SUBJECTS = [path.name for path in EEG_DIR.iterdir() if re.match(r'S\\d*', path.name)]\n",
    "# Define a target directory for TRF estimates and make sure the directory is created\n",
    "TRF_DIR = DATA_ROOT / 'TRFs_Natives'\n",
    "TRF_DIR.mkdir(exist_ok=True)\n",
    "print(Native_SUBJECTS)\n",
    "print(len(Native_SUBJECTS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "01186976",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<NDVar 'DownTheRabbitHoleFinal_SoundFile1.wav': 5753 time>, <NDVar 'DownTheRabbitHoleFinal_SoundFile2.wav': 6084 time>, <NDVar 'DownTheRabbitHoleFinal_SoundFile3.wav': 6325 time>, <NDVar 'DownTheRabbitHoleFinal_SoundFile4.wav': 6998 time>, <NDVar 'DownTheRabbitHoleFinal_SoundFile5.wav': 6627 time>, <NDVar 'DownTheRabbitHoleFinal_SoundFile6.wav': 6377 time>, <NDVar 'DownTheRabbitHoleFinal_SoundFile7.wav': 6289 time>, <NDVar 'DownTheRabbitHoleFinal_SoundFile8.wav': 5730 time>, <NDVar 'DownTheRabbitHoleFinal_SoundFile9.wav': 5722 time>, <NDVar 'DownTheRabbitHoleFinal_SoundFile10.wav': 6126 time>, <NDVar 'DownTheRabbitHoleFinal_SoundFile11.wav': 5616 time>, <NDVar 'DownTheRabbitHoleFinal_SoundFile12.wav': 4698 time>]\n",
      "(73665,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\n# Plot every envelope (Don't know why it all overlay into one figs)\\nfor i in range(0, 2):\\n    p = None\\n    print(envelope[i].get_data())\\n    p = plt.plot(envelope[i].get_data())\\n\""
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the broad-band envelope from the gammatone pickle files\n",
    "envelope = [eelbrain.load.unpickle(PREDICTOR_audio_DIR / f'{stimulus}~gammatone-1.pickle') for stimulus in STIMULI]  # Load in the data\n",
    "\"\"\"# Code Explanation\n",
    "envelopeL = []\n",
    "for stimulus in STIMULI:\n",
    "    envelope = eelbrain.load.unpickle(PREDICTOR_audio_DIR / f'{stimulus}~gammatone-1.pickle')\n",
    "    print(envelope)\n",
    "    envelopeL.append(envelope)\n",
    "\"\"\"\n",
    "# To down sample into 100 Hz\n",
    "envelope = [x.bin(0.01, dim='time', label='start') for x in envelope]\n",
    "print(envelope)\n",
    "\"\"\" # Code Explanation\n",
    "envelopeL_2 = []\n",
    "for x in envelope:\n",
    "    envelope = x.bin(0.01, dim='time', label='start')\n",
    "    envelopeL_2.append(envelope)\n",
    "\"\"\"\n",
    "# To covert it into the NDVar structures\n",
    "envelope = [trftools.pad(x, tstart=-0.100, tstop=x.time.tstop + 1, name='envelope') for x in envelope]\n",
    "\"\"\" # Code Explanation\n",
    "envelopeL_3 = []\n",
    "for x in envelope:\n",
    "    envelope = trftools.pad(x, tstart=-0.100, tstop=x.time.tstop + 1, name='envelope')\n",
    "    envelopeL_3.append(envelope)\n",
    "print(envelopeL_3)\n",
    "\"\"\"\n",
    "n_envelope = np.concatenate(envelope)\n",
    "\n",
    "print(n_envelope.shape)\n",
    "#dir(envelope[1])\n",
    "#print(envelope[1].get_data())\n",
    "\n",
    "\"\"\"\n",
    "# Plot every envelope (Don't know why it all overlay into one figs)\n",
    "for i in range(0, 2):\n",
    "    p = None\n",
    "    print(envelope[i].get_data())\n",
    "    p = plt.plot(envelope[i].get_data())\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "20432fcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6, 5863)\n",
      "(6, 6194)\n",
      "(6, 6435)\n",
      "(6, 7108)\n",
      "(6, 6737)\n",
      "(6, 6487)\n",
      "(6, 6399)\n",
      "(6, 5840)\n",
      "(6, 5832)\n",
      "(6, 6236)\n",
      "(6, 5726)\n",
      "(6, 4808)\n",
      "12\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n# Saving the self_paced_rt result into csv file\\ndataDICT = pd.DataFrame({\\'IMF_1\\':IMF_1_LIST,\\n                        \\'IMF_2\\':IMF_2_LIST,\\n                        \\'IMF_3\\':IMF_3_LIST,\\n                        \\'IMF_4\\':IMF_4_LIST,\\n                        \\'IMF_5\\':IMF_5_LIST,\\n                        \\'IMF_6\\':IMF_6_LIST,\\n                           })\\n                           \\n#data_path = \"/Users/ting-hsin/Docs/Github/ICN_related/\"\\nfile_name = \\'Alice_IF_TRF_predictor_tables.csv\\'\\nsave_path = DATA_ROOT/ \"TRFs_pridictors\" / Path(file_name)\\ndataDICT.to_csv(save_path, sep = \",\" ,index = False , header = True, encoding = \"UTF-8\")\\n'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "[18.86807686  9.43403843  4.71701922  2.35850961  1.1792548   0.5896274 ]>> = 每個IMF最多的頻率\n",
    "# 每個ＩＭＦ的順時頻率都做一個TRF 去跑統計\n",
    "4hz>> close to the syllables, 18 hz >> close to phoneme speed, but normally we consider syllables as speed\n",
    ">> use the third IMF >> \n",
    "# IP, IF, IA = emd.spectra.frequency_transform(imf, sample_rate, 'hilbert') get the IF\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"  # For IMF & IF testing commands\n",
    "imf, mask_freqs = emd.sift.mask_sift(envelope[1].get_data(), ret_mask_freq=True, max_imfs=6)  \n",
    "# delete >>, mask_freqs=30/sample_rate\n",
    "# xy = envelope data \n",
    "#print(mask_freqs * sample_rate)\n",
    "#emd.plotting.plot_imfs(imf)\n",
    "IP, IF, IA = emd.spectra.frequency_transform(imf, sample_rate, 'nht')\n",
    "\n",
    "pprint(IF[1:])\n",
    "print(IF.shape)\n",
    "#print(IF)\n",
    "\"\"\"\n",
    "\n",
    "sample_rate = 100\n",
    "## To extract the IF out of the IMFs\n",
    "# Create blank LISTs to save data\n",
    "IF_ndarrayLIST = []\n",
    "IMF_1_LIST = []\n",
    "IMF_2_LIST = []\n",
    "IMF_3_LIST = []\n",
    "IMF_4_LIST = []\n",
    "IMF_5_LIST = []\n",
    "IMF_6_LIST = []\n",
    "\n",
    "# To get every tape of its IMF, then get the IF out of it\n",
    "for i in range(0, 12):\n",
    "    imf, mask_freqs = emd.sift.mask_sift(envelope[i].get_data(), ret_mask_freq=True, max_imfs=6)  \n",
    "    # delete >>, mask_freqs=30/sample_rate   # xy = envelope data \n",
    "    #print(mask_freqs * sample_rate)\n",
    "    #emd.plotting.plot_imfs(imf)\n",
    "    IP, IF, IA = emd.spectra.frequency_transform(imf, sample_rate, 'hilbert') #get the IF\n",
    "    n_IF = IF.T\n",
    "    print(n_IF.shape)\n",
    "    IF_ndarrayLIST.append(n_IF)\n",
    "print(len(IF_ndarrayLIST))\n",
    "\n",
    "# Rearrange the IF according to the IMF\n",
    "for IMF_IF in IF_ndarrayLIST:\n",
    "    #print(IF_ndarrayLIST.index(IMF_IF))\n",
    "    #print(type(IMF_IF))\n",
    "    #print(len(IMF_IF))\n",
    "    IMF_1_LIST.append(IMF_IF[0])\n",
    "    IMF_2_LIST.append(IMF_IF[1])\n",
    "    IMF_3_LIST.append(IMF_IF[2])\n",
    "    IMF_4_LIST.append(IMF_IF[3])\n",
    "    IMF_5_LIST.append(IMF_IF[4])\n",
    "    IMF_6_LIST.append(IMF_IF[5])\n",
    "\n",
    "\"\"\"\n",
    "# Saving the self_paced_rt result into csv file\n",
    "dataDICT = pd.DataFrame({'IMF_1':IMF_1_LIST,\n",
    "                        'IMF_2':IMF_2_LIST,\n",
    "                        'IMF_3':IMF_3_LIST,\n",
    "                        'IMF_4':IMF_4_LIST,\n",
    "                        'IMF_5':IMF_5_LIST,\n",
    "                        'IMF_6':IMF_6_LIST,\n",
    "                           })\n",
    "                           \n",
    "#data_path = \"/Users/ting-hsin/Docs/Github/ICN_related/\"\n",
    "file_name = 'Alice_IF_TRF_predictor_tables.csv'\n",
    "save_path = DATA_ROOT/ \"TRFs_pridictors\" / Path(file_name)\n",
    "dataDICT.to_csv(save_path, sep = \",\" ,index = False , header = True, encoding = \"UTF-8\")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "db8b9aa2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "<class 'numpy.ndarray'>\n",
      "[ 1.61084993e+00  1.61084993e+00  5.34091200e+00 ...  2.63400413e-12\n",
      " -1.46658436e-09 -1.47169858e-09]\n",
      "6194\n"
     ]
    }
   ],
   "source": [
    "print(type(IMF_1_LIST))\n",
    "print(type(IMF_1_LIST[1]))\n",
    "print(IMF_1_LIST[1])\n",
    "print(len(IMF_1_LIST[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "4205d3dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tstep = 1. / mdata['Fs'][0, 0]\n",
    "# To save the IMF into NDVar one by one (change the IMF_[123]_LIST's num)\n",
    "IMF_NDVar = []\n",
    "\n",
    "for i in range(12):\n",
    "    #tstep = 1\n",
    "    n_times = len(IMF_1_LIST[i])\n",
    "    time = eelbrain.UTS(0, tstep=1, nsamples=n_times)\n",
    "    tmpIMF_ = eelbrain.NDVar(IMF_1_LIST[i], (time,), name='IMF_1')\n",
    "    #IMF_ = trftools.pad(tmpIMF_, tstart=-0.100, tstop=tmpIMF_.time.tstop + 1, name='IMF_1')\n",
    "    IMF_NDVar.append(tmpIMF_)\n",
    "#print(IMF__NDVar)\n",
    "#print(type(IMF_1_NDVar))\n",
    "\n",
    "# save the IMF into pickle files\n",
    "IMF_save_path = DATA_ROOT/ \"TRFs_pridictors/IF_predictors\" / Path(\"Alice_IF_IMF_1.pickle\")\n",
    "eelbrain.save.pickle(IMF_NDVar, IMF_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "6b10bdc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alice_IF_IMF_1.pickle\n",
      "Alice_IF_IMF_2.pickle\n",
      "Alice_IF_IMF_3.pickle\n",
      "Alice_IF_IMF_4.pickle\n",
      "Alice_IF_IMF_5.pickle\n",
      "Alice_IF_IMF_6.pickle\n",
      "[[<NDVar 'IMF_1': 5863 time>, <NDVar 'IMF_1': 6194 time>, <NDVar 'IMF_1': 6435 time>, <NDVar 'IMF_1': 7108 time>, <NDVar 'IMF_1': 6737 time>, <NDVar 'IMF_1': 6487 time>, <NDVar 'IMF_1': 6399 time>, <NDVar 'IMF_1': 5840 time>, <NDVar 'IMF_1': 5832 time>, <NDVar 'IMF_1': 6236 time>, <NDVar 'IMF_1': 5726 time>, <NDVar 'IMF_1': 4808 time>], [<NDVar 'IMF_2': 5863 time>, <NDVar 'IMF_2': 6194 time>, <NDVar 'IMF_2': 6435 time>, <NDVar 'IMF_2': 7108 time>, <NDVar 'IMF_2': 6737 time>, <NDVar 'IMF_2': 6487 time>, <NDVar 'IMF_2': 6399 time>, <NDVar 'IMF_2': 5840 time>, <NDVar 'IMF_2': 5832 time>, <NDVar 'IMF_2': 6236 time>, <NDVar 'IMF_2': 5726 time>, <NDVar 'IMF_2': 4808 time>], [<NDVar 'IMF_3': 5863 time>, <NDVar 'IMF_3': 6194 time>, <NDVar 'IMF_3': 6435 time>, <NDVar 'IMF_3': 7108 time>, <NDVar 'IMF_3': 6737 time>, <NDVar 'IMF_3': 6487 time>, <NDVar 'IMF_3': 6399 time>, <NDVar 'IMF_3': 5840 time>, <NDVar 'IMF_3': 5832 time>, <NDVar 'IMF_3': 6236 time>, <NDVar 'IMF_3': 5726 time>, <NDVar 'IMF_3': 4808 time>], [<NDVar 'IMF_4': 5863 time>, <NDVar 'IMF_4': 6194 time>, <NDVar 'IMF_4': 6435 time>, <NDVar 'IMF_4': 7108 time>, <NDVar 'IMF_4': 6737 time>, <NDVar 'IMF_4': 6487 time>, <NDVar 'IMF_4': 6399 time>, <NDVar 'IMF_4': 5840 time>, <NDVar 'IMF_4': 5832 time>, <NDVar 'IMF_4': 6236 time>, <NDVar 'IMF_4': 5726 time>, <NDVar 'IMF_4': 4808 time>], [<NDVar 'IMF_5': 5863 time>, <NDVar 'IMF_5': 6194 time>, <NDVar 'IMF_5': 6435 time>, <NDVar 'IMF_5': 7108 time>, <NDVar 'IMF_5': 6737 time>, <NDVar 'IMF_5': 6487 time>, <NDVar 'IMF_5': 6399 time>, <NDVar 'IMF_5': 5840 time>, <NDVar 'IMF_5': 5832 time>, <NDVar 'IMF_5': 6236 time>, <NDVar 'IMF_5': 5726 time>, <NDVar 'IMF_5': 4808 time>], [<NDVar 'IMF_6': 5863 time>, <NDVar 'IMF_6': 6194 time>, <NDVar 'IMF_6': 6435 time>, <NDVar 'IMF_6': 7108 time>, <NDVar 'IMF_6': 6737 time>, <NDVar 'IMF_6': 6487 time>, <NDVar 'IMF_6': 6399 time>, <NDVar 'IMF_6': 5840 time>, <NDVar 'IMF_6': 5832 time>, <NDVar 'IMF_6': 6236 time>, <NDVar 'IMF_6': 5726 time>, <NDVar 'IMF_6': 4808 time>]]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "# just checking whether all IMFs were included\n",
    "IMF_DIR = DATA_ROOT/ \"TRFs_pridictors/IF_predictors\"\n",
    "All_IMFs_LIST = []\n",
    "for IMFs_name in IMFsLIST:\n",
    "    tmpIMF = eelbrain.load.unpickle(IMF_DIR / IMFs_name)\n",
    "    All_IMFs_LIST.append(tmpIMF)\n",
    "    print(IMFs_name)\n",
    "print(All_IMFs_LIST)\n",
    "#IMFs = [eelbrain.load.unpickle(IMF_save_path / IMFs_name) ]\n",
    "#print(IMFs)\n",
    "#print(len(IMFs))\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b8a6ea9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['S13_Alice-natives_sfreq-100_raw.fif', 'S14_Alice-natives_sfreq-100_raw.fif', 'S12_Alice-natives_sfreq-100_raw.fif', 'S15_Alice-natives_sfreq-100_raw.fif', 'S11_Alice-natives_sfreq-100_raw.fif', 'S16_Alice-natives_sfreq-100_raw.fif', 'S17_Alice-natives_sfreq-100_raw.fif', 'S18_Alice-natives_sfreq-100_raw.fif', 'S19_Alice-natives_sfreq-100_raw.fif', 'S20_Alice-natives_sfreq-100_raw.fif', 'S21_Alice-natives_sfreq-100_raw.fif', 'S01_Alice-natives_sfreq-100_raw.fif', 'S03_Alice-natives_sfreq-100_raw.fif', 'S04_Alice-natives_sfreq-100_raw.fif', 'S05_Alice-natives_sfreq-100_raw.fif', 'S06_Alice-natives_sfreq-100_raw.fif', 'S08_Alice-natives_sfreq-100_raw.fif', 'S10_Alice-natives_sfreq-100_raw.fif', 'S22_Alice-natives_sfreq-100_raw.fif', 'S25_Alice-natives_sfreq-100_raw.fif', 'S26_Alice-natives_sfreq-100_raw.fif', 'S34_Alice-natives_sfreq-100_raw.fif', 'S35_Alice-natives_sfreq-100_raw.fif', 'S36_Alice-natives_sfreq-100_raw.fif', 'S37_Alice-natives_sfreq-100_raw.fif', 'S38_Alice-natives_sfreq-100_raw.fif', 'S39_Alice-natives_sfreq-100_raw.fif', 'S40_Alice-natives_sfreq-100_raw.fif', 'S41_Alice-natives_sfreq-100_raw.fif', 'S42_Alice-natives_sfreq-100_raw.fif', 'S44_Alice-natives_sfreq-100_raw.fif', 'S45_Alice-natives_sfreq-100_raw.fif', 'S48_Alice-natives_sfreq-100_raw.fif']\n",
      "33\n",
      "['Alice_IF_IMF_1.pickle', 'Alice_IF_IMF_2.pickle', 'Alice_IF_IMF_3.pickle', 'Alice_IF_IMF_4.pickle', 'Alice_IF_IMF_5.pickle', 'Alice_IF_IMF_6.pickle']\n"
     ]
    }
   ],
   "source": [
    "# Making the TRF now (testing)\n",
    "STIMULI = [str(i) for i in range(1, 13)]\n",
    "DATA_ROOT = Path(\"/Volumes/Neurolang_1/Master Program/New_Thesis_topic/Experiments_Results\")#Path(\"/Volumes/Neurolang_1/Master Program/New_Thesis_topic/Experiments_Results\")  #Path(\"~\").expanduser() / 'Data' / 'Alice'\n",
    "EEG_DIR = DATA_ROOT / 'EEG_Natives' / 'Alice_natives_ICAed_fif'\n",
    "IMF_DIR = DATA_ROOT/ \"TRFs_pridictors/IF_predictors\"\n",
    "IMFsLIST = [path.name for path in IMF_DIR.iterdir() if re.match(r'Alice_IF_IMF_*', path.name)]\n",
    "SUBJECTS = [path.name for path in EEG_DIR.iterdir() if re.match(r'S\\d*', path.name[:4])]\n",
    "# Define a target directory for TRF estimates and make sure the directory is created\n",
    "TRF_DIR = DATA_ROOT / 'TRFs_Natives'\n",
    "TRF_DIR.mkdir(exist_ok=True)\n",
    "print(SUBJECTS)\n",
    "print(len(SUBJECTS))\n",
    "print(IMFsLIST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "611a5335",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  59 out of  59 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimating: S13 ~ IMF_1\n",
      "[<NDVar 'IMF_1': 5865 time>, <NDVar 'IMF_1': 6196 time>, <NDVar 'IMF_1': 6437 time>, <NDVar 'IMF_1': 7110 time>, <NDVar 'IMF_1': 6739 time>, <NDVar 'IMF_1': 6489 time>, <NDVar 'IMF_1': 6401 time>, <NDVar 'IMF_1': 5842 time>, <NDVar 'IMF_1': 5834 time>, <NDVar 'IMF_1': 6238 time>, <NDVar 'IMF_1': 5728 time>, <NDVar 'IMF_1': 4810 time>]\n",
      "[<NDVar 'IMF_1': 73689 time>]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "y does not have the same time dimension as x",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [58], line 95\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[38;5;28mprint\u001b[39m(predictors_concatenated)\n\u001b[1;32m     94\u001b[0m \u001b[38;5;66;03m# Fit the mTRF\u001b[39;00m\n\u001b[0;32m---> 95\u001b[0m trf \u001b[38;5;241m=\u001b[39m \u001b[43meelbrain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mboosting\u001b[49m\u001b[43m(\u001b[49m\u001b[43meeg_concatenated\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpredictors_concatenated\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m0.100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1.000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merror\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43ml1\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbasis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.050\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpartitions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mselective_stopping\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     96\u001b[0m \u001b[38;5;66;03m# Save the TRF for later analysis\u001b[39;00m\n\u001b[1;32m     97\u001b[0m \u001b[38;5;66;03m#eelbrain.save.pickle(trf, path)\u001b[39;00m\n",
      "File \u001b[0;32m/Applications/anaconda3/envs/eelbrain_0_36/lib/python3.10/contextlib.py:79\u001b[0m, in \u001b[0;36mContextDecorator.__call__.<locals>.inner\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(func)\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minner\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds):\n\u001b[1;32m     78\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_recreate_cm():\n\u001b[0;32m---> 79\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Applications/anaconda3/envs/eelbrain_0_36/lib/python3.10/site-packages/eelbrain/_trf/_boosting.py:961\u001b[0m, in \u001b[0;36mboosting\u001b[0;34m(y, x, tstart, tstop, scale_data, delta, mindelta, error, basis, basis_window, partitions, model, validate, test, ds, selective_stopping, partition_results, debug)\u001b[0m\n\u001b[1;32m    958\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m selective_stopping \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    959\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mselective_stopping\u001b[38;5;132;01m=}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 961\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[43mDeconvolutionData\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscale_in_place\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    962\u001b[0m data\u001b[38;5;241m.\u001b[39mapply_basis(basis, basis_window)\n\u001b[1;32m    963\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m scale_data:\n",
      "File \u001b[0;32m/Applications/anaconda3/envs/eelbrain_0_36/lib/python3.10/site-packages/eelbrain/_trf/shared.py:339\u001b[0m, in \u001b[0;36mDeconvolutionData.__init__\u001b[0;34m(self, y, x, ds, in_place)\u001b[0m\n\u001b[1;32m    337\u001b[0m y \u001b[38;5;241m=\u001b[39m asndvar(y, ds\u001b[38;5;241m=\u001b[39mds)\n\u001b[1;32m    338\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y\u001b[38;5;241m.\u001b[39mget_dim(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtime\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;241m!=\u001b[39m x_data\u001b[38;5;241m.\u001b[39mtime_dim:\n\u001b[0;32m--> 339\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my does not have the same time dimension as x\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    340\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y\u001b[38;5;241m.\u001b[39mhas_case \u001b[38;5;241m^\u001b[39m x_data\u001b[38;5;241m.\u001b[39mhas_case:\n\u001b[1;32m    341\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00my\u001b[38;5;132;01m=}\u001b[39;00m\u001b[38;5;124m: case dimension does not match x\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: y does not have the same time dimension as x"
     ]
    }
   ],
   "source": [
    "# Make sure to name the stimuli so that the TRFs can later be distinguished\n",
    "# Load the gammatone-spectrograms; use the time axis of these as reference\n",
    "gammatone = [eelbrain.load.unpickle(PREDICTOR_audio_DIR / f'{stimulus}~gammatone-8.pickle') for stimulus in STIMULI]\n",
    "\n",
    "# Resample the spectrograms to 100 Hz (time-step = 0.01 s), which we will use for TRFs\n",
    "gammatone = [x.bin(0.01, dim='time', label='start') for x in gammatone]\n",
    "\n",
    "# Pad onset with 100 ms and offset with 1 second; make sure to give the predictor a unique name as that will make it easier to identify the TRF later\n",
    "gammatone = [trftools.pad(x, tstart=-0.100, tstop=x.time.tstop + 1, name='gammatone') for x in gammatone]\n",
    "\n",
    "# Extract the duration of the stimuli, so we can later match the EEG to the stimuli\n",
    "durations = [gt.time.tmax for stimulus, gt in zip(STIMULI, gammatone)]\n",
    "\n",
    "imf_1 = eelbrain.load.unpickle(IMF_DIR / IMFsLIST[0])\n",
    "imf_2 = eelbrain.load.unpickle(IMF_DIR / IMFsLIST[1])\n",
    "imf_3 = eelbrain.load.unpickle(IMF_DIR / IMFsLIST[2])\n",
    "imf_4 = eelbrain.load.unpickle(IMF_DIR / IMFsLIST[3])\n",
    "imf_5 = eelbrain.load.unpickle(IMF_DIR / IMFsLIST[4])\n",
    "imf_6 = eelbrain.load.unpickle(IMF_DIR / IMFsLIST[5])\n",
    "# Models\n",
    "# ------\n",
    "# Pre-define models here to have easier access during estimation. In the future, additional models could be added here and the script re-run to generate additional TRFs.\n",
    "models = {\n",
    "    # IFs\n",
    "    'IMF_1':[imf_1],\n",
    "    'IMF_2':[imf_2],\n",
    "    'IMF_3':[imf_3],\n",
    "    'IMF_4':[imf_4],\n",
    "    'IMF_5':[imf_5],\n",
    "    'IMF_6':[imf_6],\n",
    "}\n",
    "\"\"\"\n",
    "# Acoustic models\n",
    "'envelope': [envelope],\n",
    "'envelope+onset': [envelope, onset_envelope],\n",
    "'acoustic': [gammatone, gammatone_onsets],\n",
    "# Models with word-onsets and word-class\n",
    "'words': [word_onsets],\n",
    "'words+lexical': [word_onsets, word_lexical, word_nlexical],\n",
    "'acoustic+words': [gammatone, gammatone_onsets, word_onsets],\n",
    "'acoustic+words+lexical': [gammatone, gammatone_onsets, word_onsets, word_lexical, word_nlexical],\n",
    "# Language Models\n",
    "'Ngram': [word_Ngram, word_onsets, word_lexical, word_nlexical],\n",
    "'CFG': [word_CFG, word_onsets, word_lexical, word_nlexical],\n",
    "'Ngram-CFG_all': [word_Ngram, word_CFG, word_onsets, word_lexical, word_nlexical]\n",
    "# F0 & IF\n",
    "'IF': [IMFs]\n",
    "# IFs\n",
    "    'IMF_1':[imf_1],\n",
    "    'IMF_2':[imf_2],\n",
    "    'IMF_3':[imf_3],\n",
    "    'IMF_4':[imf_4],\n",
    "    'IMF_5':[imf_5],\n",
    "    'IMF_6':[imf_6],\n",
    "\"\"\"    \n",
    "# Estimate TRFs\n",
    "# -------------\n",
    "# Loop through subjects to estimate TRFs\n",
    "for subject in SUBJECTS:\n",
    "    subject_trf_dir = TRF_DIR / subject[:3]\n",
    "    subject_trf_dir.mkdir(exist_ok=True)\n",
    "    # Generate all TRF paths so we can check whether any new TRFs need to be estimated\n",
    "    trf_paths = {model: subject_trf_dir / f'{subject[:3]} {model}.pickle' for model in models}\n",
    "    # Skip this subject if all files already exist\n",
    "    #if all(path.exists() for path in trf_paths.values()):\n",
    "        #continue\n",
    "    # Load the EEG data\n",
    "    raw = mne.io.read_raw_fif(EEG_DIR / f'{subject}', preload=True)  # subject /\n",
    "    # Band-pass filter the raw data between 0.5 and 20 Hz\n",
    "    raw.filter(0.5, 20)\n",
    "    # Interpolate bad channels\n",
    "    raw.interpolate_bads()\n",
    "    # Extract the events marking the stimulus presentation from the EEG file\n",
    "    events = eelbrain.load.fiff.events(raw)\n",
    "    # Not all subjects have all trials; determine which stimuli are present\n",
    "    trial_indexes = [STIMULI.index(stimulus) for stimulus in events['event']]\n",
    "    # Extract the EEG data segments corresponding to the stimuli\n",
    "    trial_durations = [durations[i] for i in trial_indexes]\n",
    "    eeg = eelbrain.load.fiff.variable_length_epochs(events, -0.100, trial_durations, connectivity='auto')  #, decim=5 #decim=5 meaning to resample to sfreq=100Hz\n",
    "    # Since trials are of unequal length, we will concatenate them for the TRF estimation.\n",
    "    eeg_concatenated = eelbrain.concatenate(eeg)\n",
    "    for model, predictors in models.items():\n",
    "        path = trf_paths[model]\n",
    "        # Skip if this file already exists\n",
    "        #if path.exists():\n",
    "            #continue\n",
    "        print(f\"Estimating: {subject[:3]} ~ {model}\")\n",
    "        # Select and concetenate the predictors corresponding to the EEG trials\n",
    "        predictors_concatenated = []\n",
    "        for predictor in predictors:\n",
    "            print(predictor)\n",
    "            predictors_concatenated.append(eelbrain.concatenate([predictor[i] for i in trial_indexes]))\n",
    "        print(predictors_concatenated)\n",
    "        # Fit the mTRF\n",
    "        trf = eelbrain.boosting(eeg_concatenated, predictors_concatenated, -0.100, 1.000, error='l1', basis=0.050, partitions=5, test=1, selective_stopping=True)\n",
    "        # Save the TRF for later analysis\n",
    "        #eelbrain.save.pickle(trf, path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "a66a882c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['n_2_S019_ICAed_raw.fif', 'n_2_S020_ICAed_raw.fif', 'n_2_S021_ICAed_raw.fif', 'n_2_S022_ICAed_raw.fif', 'n_2_S023_ICAed_raw.fif', 'n_2_S026_ICAed_raw.fif', 'n_2_S024_ICAed_raw.fif', 'n_2_S012_ICAed_raw.fif', 'n_2_S013_ICAed_raw.fif', 'n_2_S015_ICAed_raw.fif', 'n_2_S016_ICAed_raw.fif', 'n_2_S011_ICAed_raw.fif', 'n_2_S010_ICAed_raw.fif', 'n_2_S029_ICAed_raw.fif', 'n_2_S027_ICAed_raw.fif', 'n_2_S028_ICAed_raw.fif', 'n_2_S030_ICAed_raw.fif', 'n_2_S031_ICAed_raw.fif', 'n_2_S017_ICAed_raw.fif', 'n_2_S025_ICAed_raw.fif', 'n_2_S032_ICAed_raw.fif', 'n_2_S034_ICAed_raw.fif', 'n_2_S035_ICAed_raw.fif', 'n_2_S036_ICAed_raw.fif', 'n_2_S038_ICAed_raw.fif', 'n_2_S039_ICAed_raw.fif']\n",
      "Estimating: n_2_S019_ICAed_raw.fif ~ Ngram\n",
      "[<NDVar 'n-gram': 73654 time>, <NDVar 'word': 73654 time>, <NDVar 'lexical': 73654 time>, <NDVar 'non_lexical': 73654 time>]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fitting models:   0%|                                  | 0/1140 [00:00<?, ?it/s]Exception ignored in: <function _releaseLock at 0x1047c0a60>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/envs/eelbrain/lib/python3.9/logging/__init__.py\", line 227, in _releaseLock\n",
      "Process ForkProcess-3:\n",
      "Process ForkProcess-5:\n",
      "Process ForkProcess-1:\n",
      "Process ForkProcess-4:\n",
      "Process ForkProcess-2:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "    def _releaseLock():\n",
      "KeyboardInterrupt: \n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/envs/eelbrain/lib/python3.9/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/anaconda3/envs/eelbrain/lib/python3.9/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/anaconda3/envs/eelbrain/lib/python3.9/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/anaconda3/envs/eelbrain/lib/python3.9/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/anaconda3/envs/eelbrain/lib/python3.9/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/anaconda3/envs/eelbrain/lib/python3.9/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/anaconda3/envs/eelbrain/lib/python3.9/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/anaconda3/envs/eelbrain/lib/python3.9/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/anaconda3/envs/eelbrain/lib/python3.9/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/anaconda3/envs/eelbrain/lib/python3.9/site-packages/eelbrain/_trf/_boosting.py\", line 1164, in boosting_worker\n",
      "    i_y, i_split = job_queue.get()\n",
      "  File \"/opt/anaconda3/envs/eelbrain/lib/python3.9/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/anaconda3/envs/eelbrain/lib/python3.9/site-packages/eelbrain/_trf/_boosting.py\", line 1164, in boosting_worker\n",
      "    i_y, i_split = job_queue.get()\n",
      "  File \"/opt/anaconda3/envs/eelbrain/lib/python3.9/site-packages/eelbrain/_trf/_boosting.py\", line 1164, in boosting_worker\n",
      "    i_y, i_split = job_queue.get()\n",
      "  File \"/opt/anaconda3/envs/eelbrain/lib/python3.9/multiprocessing/queues.py\", line 102, in get\n",
      "    with self._rlock:\n",
      "  File \"/opt/anaconda3/envs/eelbrain/lib/python3.9/multiprocessing/queues.py\", line 102, in get\n",
      "    with self._rlock:\n",
      "  File \"/opt/anaconda3/envs/eelbrain/lib/python3.9/site-packages/eelbrain/_trf/_boosting.py\", line 1164, in boosting_worker\n",
      "    i_y, i_split = job_queue.get()\n",
      "  File \"/opt/anaconda3/envs/eelbrain/lib/python3.9/multiprocessing/queues.py\", line 102, in get\n",
      "    with self._rlock:\n",
      "Fitting models:   0%|                        | 1/1140 [00:22<7:12:17, 22.77s/it]  File \"/opt/anaconda3/envs/eelbrain/lib/python3.9/multiprocessing/queues.py\", line 102, in get\n",
      "    with self._rlock:\n",
      "  File \"/opt/anaconda3/envs/eelbrain/lib/python3.9/multiprocessing/queues.py\", line 103, in get\n",
      "    res = self._recv_bytes()\n",
      "  File \"/opt/anaconda3/envs/eelbrain/lib/python3.9/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/opt/anaconda3/envs/eelbrain/lib/python3.9/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/opt/anaconda3/envs/eelbrain/lib/python3.9/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/opt/anaconda3/envs/eelbrain/lib/python3.9/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "  File \"/opt/anaconda3/envs/eelbrain/lib/python3.9/multiprocessing/connection.py\", line 221, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/opt/anaconda3/envs/eelbrain/lib/python3.9/multiprocessing/connection.py\", line 419, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/opt/anaconda3/envs/eelbrain/lib/python3.9/multiprocessing/connection.py\", line 384, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "KeyboardInterrupt\n",
      "Fitting models:  61%|██████████████▌         | 691/1140 [01:01<00:27, 16.10it/s]Process ForkProcess-8:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/envs/eelbrain/lib/python3.9/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/anaconda3/envs/eelbrain/lib/python3.9/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "Process ForkProcess-7:\n",
      "  File \"/opt/anaconda3/envs/eelbrain/lib/python3.9/site-packages/eelbrain/_trf/_boosting.py\", line 1167, in boosting_worker\n",
      "    h = boost(y[i_y], x, x_pads, splits[i_split], i_start, i_stop, delta, mindelta, error, selective_stopping)\n",
      "  File \"/opt/anaconda3/envs/eelbrain/lib/python3.9/site-packages/eelbrain/_trf/_boosting.py\", line 1092, in boost\n",
      "    generate_options(y_error, x, x_pads, x_active, split.train, i_start, i_start_by_x, i_stop_by_x, delta_error_func, delta, new_error, new_sign)\n",
      "Process ForkProcess-6:\n",
      "KeyboardInterrupt\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/envs/eelbrain/lib/python3.9/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/anaconda3/envs/eelbrain/lib/python3.9/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/anaconda3/envs/eelbrain/lib/python3.9/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/anaconda3/envs/eelbrain/lib/python3.9/site-packages/eelbrain/_trf/_boosting.py\", line 1167, in boosting_worker\n",
      "    h = boost(y[i_y], x, x_pads, splits[i_split], i_start, i_stop, delta, mindelta, error, selective_stopping)\n",
      "  File \"/opt/anaconda3/envs/eelbrain/lib/python3.9/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/anaconda3/envs/eelbrain/lib/python3.9/site-packages/eelbrain/_trf/_boosting.py\", line 1167, in boosting_worker\n",
      "    h = boost(y[i_y], x, x_pads, splits[i_split], i_start, i_stop, delta, mindelta, error, selective_stopping)\n",
      "  File \"/opt/anaconda3/envs/eelbrain/lib/python3.9/site-packages/eelbrain/_trf/_boosting.py\", line 1092, in boost\n",
      "    generate_options(y_error, x, x_pads, x_active, split.train, i_start, i_start_by_x, i_stop_by_x, delta_error_func, delta, new_error, new_sign)\n",
      "KeyboardInterrupt\n",
      "  File \"/opt/anaconda3/envs/eelbrain/lib/python3.9/site-packages/eelbrain/_trf/_boosting.py\", line 1092, in boost\n",
      "    generate_options(y_error, x, x_pads, x_active, split.train, i_start, i_start_by_x, i_stop_by_x, delta_error_func, delta, new_error, new_sign)\n",
      "KeyboardInterrupt\n",
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/envs/eelbrain/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3457, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/var/folders/h7/sdf5cvgx3qzf5rh744693x0r0000gn/T/ipykernel_69032/694412746.py\", line 173, in <module>\n",
      "    trf = eelbrain.boosting(eeg_concatenated, predictors_concatenated, -0.100, 1.000, error='l1', basis=0.050, partitions=5, test=1, selective_stopping=True)\n",
      "  File \"/opt/anaconda3/envs/eelbrain/lib/python3.9/contextlib.py\", line 79, in inner\n",
      "    return func(*args, **kwds)\n",
      "  File \"/opt/anaconda3/envs/eelbrain/lib/python3.9/site-packages/eelbrain/_trf/_boosting.py\", line 964, in boosting\n",
      "    fit.fit(tstart, tstop, selective_stopping, error, delta, mindelta)\n",
      "  File \"/opt/anaconda3/envs/eelbrain/lib/python3.9/site-packages/eelbrain/_trf/_boosting.py\", line 598, in fit\n",
      "    i_y, i_split, h = result_queue.get()\n",
      "  File \"/opt/anaconda3/envs/eelbrain/lib/python3.9/multiprocessing/queues.py\", line 103, in get\n",
      "    res = self._recv_bytes()\n",
      "  File \"/opt/anaconda3/envs/eelbrain/lib/python3.9/multiprocessing/connection.py\", line 221, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/opt/anaconda3/envs/eelbrain/lib/python3.9/multiprocessing/connection.py\", line 419, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/opt/anaconda3/envs/eelbrain/lib/python3.9/multiprocessing/connection.py\", line 384, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/envs/eelbrain/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 2077, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/envs/eelbrain/lib/python3.9/site-packages/IPython/core/ultratb.py\", line 1101, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"/opt/anaconda3/envs/eelbrain/lib/python3.9/site-packages/IPython/core/ultratb.py\", line 248, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/opt/anaconda3/envs/eelbrain/lib/python3.9/site-packages/IPython/core/ultratb.py\", line 281, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"/opt/anaconda3/envs/eelbrain/lib/python3.9/inspect.py\", line 1543, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"/opt/anaconda3/envs/eelbrain/lib/python3.9/inspect.py\", line 1505, in getframeinfo\n",
      "    lines, lnum = findsource(frame)\n",
      "  File \"/opt/anaconda3/envs/eelbrain/lib/python3.9/site-packages/IPython/core/ultratb.py\", line 182, in findsource\n",
      "    lines = linecache.getlines(file, globals_dict)\n",
      "  File \"/opt/anaconda3/envs/eelbrain/lib/python3.9/linecache.py\", line 46, in getlines\n",
      "    return updatecache(filename, module_globals)\n",
      "  File \"/opt/anaconda3/envs/eelbrain/lib/python3.9/linecache.py\", line 136, in updatecache\n",
      "    with tokenize.open(fullname) as fp:\n",
      "  File \"/opt/anaconda3/envs/eelbrain/lib/python3.9/tokenize.py\", line 394, in open\n",
      "    encoding, lines = detect_encoding(buffer.readline)\n",
      "  File \"/opt/anaconda3/envs/eelbrain/lib/python3.9/tokenize.py\", line 363, in detect_encoding\n",
      "    first = read_or_stop()\n",
      "  File \"/opt/anaconda3/envs/eelbrain/lib/python3.9/tokenize.py\", line 321, in read_or_stop\n",
      "    return readline()\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "object of type 'NoneType' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "\u001b[0;32m/var/folders/h7/sdf5cvgx3qzf5rh744693x0r0000gn/T/ipykernel_69032/694412746.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    172\u001b[0m             \u001b[0;31m# Fit the mTRF\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 173\u001b[0;31m             \u001b[0mtrf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meelbrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mboosting\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meeg_concatenated\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredictors_concatenated\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m0.100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'l1'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbasis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.050\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpartitions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mselective_stopping\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    174\u001b[0m             \u001b[0;31m# Save the TRF for later analysis\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/eelbrain/lib/python3.9/contextlib.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m     78\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_recreate_cm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/eelbrain/lib/python3.9/site-packages/eelbrain/_trf/_boosting.py\u001b[0m in \u001b[0;36mboosting\u001b[0;34m(y, x, tstart, tstop, scale_data, delta, mindelta, error, basis, basis_window, partitions, model, validate, test, ds, selective_stopping, partition_results, debug)\u001b[0m\n\u001b[1;32m    963\u001b[0m     \u001b[0mfit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBoosting\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 964\u001b[0;31m     \u001b[0mfit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtstart\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtstop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mselective_stopping\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmindelta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    965\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mfit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpartition_results\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpartition_results\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/eelbrain/lib/python3.9/site-packages/eelbrain/_trf/_boosting.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, tstart, tstop, selective_stopping, error, delta, mindelta)\u001b[0m\n\u001b[1;32m    597\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_y\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mn_splits\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 598\u001b[0;31m                     \u001b[0mi_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi_split\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    599\u001b[0m                     \u001b[0msplit_results\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi_split\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_h\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/eelbrain/lib/python3.9/multiprocessing/queues.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    102\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_rlock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m                 \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_recv_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/eelbrain/lib/python3.9/multiprocessing/connection.py\u001b[0m in \u001b[0;36mrecv_bytes\u001b[0;34m(self, maxlength)\u001b[0m\n\u001b[1;32m    220\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"negative maxlength\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 221\u001b[0;31m         \u001b[0mbuf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_recv_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaxlength\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbuf\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/eelbrain/lib/python3.9/multiprocessing/connection.py\u001b[0m in \u001b[0;36m_recv_bytes\u001b[0;34m(self, maxsize)\u001b[0m\n\u001b[1;32m    418\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_recv_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 419\u001b[0;31m         \u001b[0mbuf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_recv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    420\u001b[0m         \u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstruct\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munpack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"!i\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/eelbrain/lib/python3.9/multiprocessing/connection.py\u001b[0m in \u001b[0;36m_recv\u001b[0;34m(self, size, read)\u001b[0m\n\u001b[1;32m    383\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0mremaining\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 384\u001b[0;31m             \u001b[0mchunk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mremaining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    385\u001b[0m             \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/opt/anaconda3/envs/eelbrain/lib/python3.9/site-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[0;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[1;32m   2076\u001b[0m                         \u001b[0;31m# in the engines. This should return a list of strings.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2077\u001b[0;31m                         \u001b[0mstb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_render_traceback_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2078\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'KeyboardInterrupt' object has no attribute '_render_traceback_'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/eelbrain/lib/python3.9/site-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[0;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[1;32m   2077\u001b[0m                         \u001b[0mstb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_render_traceback_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2078\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2079\u001b[0;31m                         stb = self.InteractiveTB.structured_traceback(etype,\n\u001b[0m\u001b[1;32m   2080\u001b[0m                                             value, tb, tb_offset=tb_offset)\n\u001b[1;32m   2081\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/eelbrain/lib/python3.9/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1365\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1366\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1367\u001b[0;31m         return FormattedTB.structured_traceback(\n\u001b[0m\u001b[1;32m   1368\u001b[0m             self, etype, value, tb, tb_offset, number_of_lines_of_context)\n\u001b[1;32m   1369\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/eelbrain/lib/python3.9/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1265\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose_modes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1266\u001b[0m             \u001b[0;31m# Verbose modes need a full traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1267\u001b[0;31m             return VerboseTB.structured_traceback(\n\u001b[0m\u001b[1;32m   1268\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb_offset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumber_of_lines_of_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1269\u001b[0m             )\n",
      "\u001b[0;32m/opt/anaconda3/envs/eelbrain/lib/python3.9/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, evalue, etb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1122\u001b[0m         \u001b[0;34m\"\"\"Return a nice text document describing the traceback.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1124\u001b[0;31m         formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n\u001b[0m\u001b[1;32m   1125\u001b[0m                                                                tb_offset)\n\u001b[1;32m   1126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/eelbrain/lib/python3.9/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mformat_exception_as_a_whole\u001b[0;34m(self, etype, evalue, etb, number_of_lines_of_context, tb_offset)\u001b[0m\n\u001b[1;32m   1080\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1081\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1082\u001b[0;31m         \u001b[0mlast_unique\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfind_recursion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morig_etype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1083\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1084\u001b[0m         \u001b[0mframes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat_records\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlast_unique\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/eelbrain/lib/python3.9/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mfind_recursion\u001b[0;34m(etype, value, records)\u001b[0m\n\u001b[1;32m    380\u001b[0m     \u001b[0;31m# first frame (from in to out) that looks different.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_recursion_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 382\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    383\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m     \u001b[0;31m# Select filename, lineno, func_name to track frames with\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: object of type 'NoneType' has no len()"
     ]
    }
   ],
   "source": [
    "#### FOR ESLs ####\n",
    "#!/usr/bin/env python3\n",
    "# -*- coding:utf-8 -*-\n",
    "\n",
    "\"\"\"This script estimates TRFs for several models and saves them\"\"\"\n",
    "from pathlib import Path\n",
    "import re\n",
    "\n",
    "import eelbrain\n",
    "import mne\n",
    "import trftools\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    STIMULI = [str(i) for i in range(1, 13)]\n",
    "    DATA_ROOT = Path(\"/Volumes/Neurolang_1/Master Program/New_Thesis_topic/Experiments_Results\")  #Path(\"~\").expanduser() / 'Data' / 'Alice'\n",
    "    #DATA_ROOT = Path(\"/Users/neuroling/Downloads/DINGHSIN_Results/Alice_Experiments_Results\")\n",
    "    PREDICTOR_audio_DIR = DATA_ROOT / 'TRFs_pridictors/audio_predictors'\n",
    "    PREDICTOR_word_DIR = DATA_ROOT / 'TRFs_pridictors/word_predictors'\n",
    "    EEG_DIR = DATA_ROOT / 'EEG_ESLs' / 'Alice_ESL_ICAed_fif'\n",
    "    SUBJECTS = [path.name for path in EEG_DIR.iterdir() if re.match(r'n_2_S\\d', path.name)]  #S01_alice-raw.fif\n",
    "    # Define a target directory for TRF estimates and make sure the directory is created\n",
    "    TRF_DIR = DATA_ROOT / 'TRFs_ESLs'\n",
    "    TRF_DIR.mkdir(exist_ok=True)\n",
    "    print(SUBJECTS)\n",
    "\n",
    "    \n",
    "    # Load stimuli\n",
    "    # ------------\n",
    "    # Make sure to name the stimuli so that the TRFs can later be distinguished\n",
    "    # Load the gammatone-spectrograms; use the time axis of these as reference\n",
    "    gammatone = [eelbrain.load.unpickle(PREDICTOR_audio_DIR / f'{stimulus}~gammatone-8.pickle') for stimulus in STIMULI]\n",
    "    \n",
    "    # Resample the spectrograms to 100 Hz (time-step = 0.01 s), which we will use for TRFs\n",
    "    gammatone = [x.bin(0.01, dim='time', label='start') for x in gammatone]\n",
    "    \n",
    "    # Pad onset with 100 ms and offset with 1 second; make sure to give the predictor a unique name as that will make it easier to identify the TRF later\n",
    "    gammatone = [trftools.pad(x, tstart=-0.100, tstop=x.time.tstop + 1, name='gammatone') for x in gammatone]\n",
    "    \n",
    "    # Load the broad-band envelope and process it in the same way\n",
    "    envelope = [eelbrain.load.unpickle(PREDICTOR_audio_DIR / f'{stimulus}~gammatone-1.pickle') for stimulus in STIMULI]  # Load in the data\n",
    "    envelope = [x.bin(0.01, dim='time', label='start') for x in envelope]\n",
    "    envelope = [trftools.pad(x, tstart=-0.100, tstop=x.time.tstop + 1, name='envelope') for x in envelope]\n",
    "    onset_envelope = [eelbrain.load.unpickle(PREDICTOR_audio_DIR / f'{stimulus}~gammatone-on-1.pickle') for stimulus in STIMULI]\n",
    "    onset_envelope = [x.bin(0.01, dim='time', label='start') for x in onset_envelope]\n",
    "    onset_envelope = [trftools.pad(x, tstart=-0.100, tstop=x.time.tstop + 1, name='onset') for x in onset_envelope]\n",
    "    \n",
    "    # Load onset spectrograms and make sure the time dimension is equal to the gammatone spectrograms\n",
    "    gammatone_onsets = [eelbrain.load.unpickle(PREDICTOR_audio_DIR / f'{stimulus}~gammatone-on-8.pickle') for stimulus in STIMULI]\n",
    "    gammatone_onsets = [x.bin(0.01, dim='time', label='start') for x in gammatone_onsets]\n",
    "    gammatone_onsets = [eelbrain.set_time(x, gt.time, name='gammatone_on') for x, gt in zip(gammatone_onsets, gammatone)]\n",
    "\n",
    "    # Load word tables and convert tables into continuous time-series with matching time dimension\n",
    "    word_tables = [eelbrain.load.unpickle(PREDICTOR_word_DIR / f'{stimulus}~Ngram-CFG_word.pickle') for stimulus in STIMULI]\n",
    "    word_onsets = [eelbrain.event_impulse_predictor(gt.time, ds=ds, name='word') for gt, ds in zip(gammatone, word_tables)]\n",
    "    \n",
    "    # Function and content word impulses based on the boolean variables in the word-tables\n",
    "    word_lexical = [eelbrain.event_impulse_predictor(gt.time, value='lexical', ds=ds, name='lexical') for gt, ds in zip(gammatone, word_tables)]\n",
    "    word_nlexical = [eelbrain.event_impulse_predictor(gt.time, value='nlexical', ds=ds, name='non_lexical') for gt, ds in zip(gammatone, word_tables)]\n",
    "    \n",
    "    # NGRAM/CFG word impulses based on the values in the word-tables\n",
    "    word_Ngram = [eelbrain.event_impulse_predictor(gt.time, value='NGRAM', ds=ds, name='n-gram') for gt, ds in zip(gammatone, word_tables)]\n",
    "    word_CFG = [eelbrain.event_impulse_predictor(gt.time, value='CFG', ds=ds, name='cfg') for gt, ds in zip(gammatone, word_tables)]\n",
    "    \n",
    "    # Extract the duration of the stimuli, so we can later match the EEG to the stimuli\n",
    "    durations = [gt.time.tmax for stimulus, gt in zip(STIMULI, gammatone)]\n",
    "    #print(durations)\n",
    "    \n",
    "    # Models\n",
    "    # ------\n",
    "    # Pre-define models here to have easier access during estimation. In the future, additional models could be added here and the script re-run to generate additional TRFs.\n",
    "    models = {     \n",
    "        # Language Models\n",
    "        'Ngram': [word_Ngram, word_onsets, word_lexical, word_nlexical],\n",
    "        'CFG': [word_CFG, word_onsets, word_lexical, word_nlexical],\n",
    "        'Ngram-CFG_all': [word_Ngram, word_CFG, word_onsets, word_lexical, word_nlexical]\n",
    "    }\n",
    "    \n",
    "    \"\"\"\n",
    "    models = {\n",
    "        # Acoustic models\n",
    "        'envelope': [envelope],\n",
    "        'envelope+onset': [envelope, onset_envelope],\n",
    "        'acoustic': [gammatone, gammatone_onsets],\n",
    "        # Models with word-onsets and word-class\n",
    "        'words': [word_onsets],\n",
    "        'words+lexical': [word_onsets, word_lexical, word_nlexical],\n",
    "        'acoustic+words': [gammatone, gammatone_onsets, word_onsets],\n",
    "        'acoustic+words+lexical': [gammatone, gammatone_onsets, word_onsets, word_lexical, word_nlexical],\n",
    "    }\n",
    "    \"\"\"\n",
    "    # Estimate TRFs\n",
    "    # -------------\n",
    "    # Loop through subjects to estimate TRFs\n",
    "    for subject in SUBJECTS:  #type(subject) == str\n",
    "        subject_trf_dir = TRF_DIR / subject[4:8]\n",
    "        subject_trf_dir.mkdir(exist_ok=True)\n",
    "        # Generate all TRF paths so we can check whether any new TRFs need to be estimated\n",
    "        trf_paths = {model: subject_trf_dir / f'{subject[4:8]} {model}.pickle' for model in models}\n",
    "        # Skip this subject if all files already exist\n",
    "        #if all(path.exists() for path in trf_paths.values()):\n",
    "            #continue\n",
    "        # Load the EEG data\n",
    "        raw = mne.io.read_raw_fif(EEG_DIR / f'{subject}', preload=True)\n",
    "        # Band-pass filter the raw data between 0.5 and 20 Hz\n",
    "        raw.filter(0.5, 20)  #.resample(sfreq=100)  # >> already resample to sfreq=100\n",
    "        \n",
    "        # Interpolate bad channels  \n",
    "        #raw.interpolate_bads()  #>> to rewrite if there're no bad channels to interpolate, skip it\n",
    "        \n",
    "        # Extract the events marking the stimulus presentation from the EEG file\n",
    "        events = eelbrain.load.fiff.events(raw)  # To check to events\n",
    "        #print(events)\n",
    "        # Not all subjects have all trials; determine which stimuli are present\n",
    "        trial_indexes = [STIMULI.index(stimulus) for stimulus in events['event'] if stimulus in STIMULI]  # type(trial_indexes)==LIST\n",
    "        #print(trial_indexes)\n",
    "        \n",
    "        # Extract the EEG data segments corresponding to the stimuli\n",
    "        trial_durations = [durations[i] for i in trial_indexes]  # needs modification for having questions inbetween the tapes\n",
    "        #print(trial_durations)\n",
    "        \n",
    "        #all_trial_durations = np.sum(np.array(trial_durations))\n",
    "        #print(all_trial_durations)\n",
    "        \n",
    "        #eeg = eelbrain.load.fiff.variable_length_epochs(events, -0.100, trial_durations, decim=5, connectivity='auto')  #, decim=5  #trial_durations >> figure out how to cut on the right time\n",
    "        #print(eeg)\n",
    "        \n",
    "        \n",
    "        # Since trials are of unequal length, we will concatenate them for the TRF estimation.\n",
    "        #eeg_concatenated = eelbrain.concatenate(eeg)\n",
    "        #print(eeg_concatenated)\n",
    "        \n",
    "        for model, predictors in models.items():\n",
    "            path = trf_paths[model]\n",
    "            # Skip if this file already exists\n",
    "            #if path.exists():\n",
    "                #continue\n",
    "            print(f\"Estimating: {subject} ~ {model}\")\n",
    "            # Select and concetenate the predictors corresponding to the EEG trials\n",
    "            predictors_concatenated = []\n",
    "            for predictor in predictors:\n",
    "                #print(predictor)\n",
    "                predictors_concatenated.append(eelbrain.concatenate([predictor[i] for i in trial_indexes]))\n",
    "            print(predictors_concatenated)\n",
    "            \n",
    "            # Homemade NDVar instead of using .fiff.variable_length_epochs()\n",
    "            eeg_ = raw.get_data()\n",
    "            \n",
    "            #[<NDVar 'envelope': 5863 time>, <NDVar 'envelope': 6194 time>, <NDVar 'envelope': 6435 time>, <NDVar 'envelope': 7108 time>, \n",
    "            # <NDVar 'envelope': 6737 time>, <NDVar 'envelope': 6487 time>, <NDVar 'envelope': 6399 time>, <NDVar 'envelope': 5840 time>, \n",
    "            # <NDVar 'envelope': 5832 time>, <NDVar 'envelope': 6236 time>, <NDVar 'envelope': 5726 time>, <NDVar 'envelope': 4808 time>]\n",
    "            #[<NDVar 'envelope': 73665 time>]\n",
    "            \n",
    "            # Check if the data length is the same as the stimuli's length\n",
    "            if eeg_.shape[1] > 73654:\n",
    "                eeg_ = eeg_[:, :73654]\n",
    "            \n",
    "            # produce the time for NDVar production\n",
    "            tstep = 1. / raw.info[\"sfreq\"]  # already resample to 100Hz\n",
    "            n_times = eeg_.shape[1] #audio.shape[0]\n",
    "            time = eelbrain.UTS(0, tstep, n_times)\n",
    "            #print(time)\n",
    "        \n",
    "            # NDVar production\n",
    "            montage_x = eelbrain.load.fiff.sensor_dim(raw.info)\n",
    "            temp_data = eeg_.T *1e+6\n",
    "            eeg_concatenated = eelbrain.NDVar(temp_data, (time, montage_x), name='EEG', info={'unit': 'µV'})\n",
    "            #print(eegNDVar)\n",
    "            \n",
    "            # Fit the mTRF\n",
    "            trf = eelbrain.boosting(eeg_concatenated, predictors_concatenated, -0.100, 1.000, error='l1', basis=0.050, partitions=5, test=1, selective_stopping=True)\n",
    "            # Save the TRF for later analysis\n",
    "            #eelbrain.save.pickle(trf, path)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8d811d2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
