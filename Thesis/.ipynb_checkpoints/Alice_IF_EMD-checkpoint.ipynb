{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5b15b5ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: MacOSX\n"
     ]
    }
   ],
   "source": [
    "%matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "11613b5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import re\n",
    "from pprint import pprint\n",
    "\n",
    "import numpy as np\n",
    "from scipy import signal, ndimage\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import pyplot\n",
    "import pandas as pd\n",
    "\n",
    "import emd\n",
    "import eelbrain\n",
    "import mne\n",
    "import trftools"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a79a8f6e",
   "metadata": {},
   "source": [
    "## How to get the IF from the envelope, and turn it into the TRF?\n",
    "\n",
    "1. Load in the envelope\n",
    "2. Emd sift the envelope\n",
    "3. Save the IF value\n",
    "4. Pack the IF value with the sensor\n",
    "5. Calculate the IF's TRF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "81c8e883",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['S13_Alice-natives_sfreq-100_raw.fif', 'S14_Alice-natives_sfreq-100_raw.fif', 'S12_Alice-natives_sfreq-100_raw.fif', 'S15_Alice-natives_sfreq-100_raw.fif', 'S11_Alice-natives_sfreq-100_raw.fif', 'S16_Alice-natives_sfreq-100_raw.fif', 'S17_Alice-natives_sfreq-100_raw.fif', 'S18_Alice-natives_sfreq-100_raw.fif', 'S19_Alice-natives_sfreq-100_raw.fif', 'S20_Alice-natives_sfreq-100_raw.fif', 'S21_Alice-natives_sfreq-100_raw.fif', 'S01_Alice-natives_sfreq-100_raw.fif', 'S03_Alice-natives_sfreq-100_raw.fif', 'S04_Alice-natives_sfreq-100_raw.fif', 'S05_Alice-natives_sfreq-100_raw.fif', 'S06_Alice-natives_sfreq-100_raw.fif', 'S08_Alice-natives_sfreq-100_raw.fif', 'S10_Alice-natives_sfreq-100_raw.fif', 'S22_Alice-natives_sfreq-100_raw.fif', 'S25_Alice-natives_sfreq-100_raw.fif', 'S26_Alice-natives_sfreq-100_raw.fif', 'S34_Alice-natives_sfreq-100_raw.fif', 'S35_Alice-natives_sfreq-100_raw.fif', 'S36_Alice-natives_sfreq-100_raw.fif', 'S37_Alice-natives_sfreq-100_raw.fif', 'S38_Alice-natives_sfreq-100_raw.fif', 'S39_Alice-natives_sfreq-100_raw.fif', 'S40_Alice-natives_sfreq-100_raw.fif', 'S41_Alice-natives_sfreq-100_raw.fif', 'S42_Alice-natives_sfreq-100_raw.fif', 'S44_Alice-natives_sfreq-100_raw.fif', 'S45_Alice-natives_sfreq-100_raw.fif', 'S48_Alice-natives_sfreq-100_raw.fif']\n",
      "33\n"
     ]
    }
   ],
   "source": [
    "## NATIVES ##\n",
    "\n",
    "STIMULI = [str(i) for i in range(1, 13)]\n",
    "DATA_ROOT = Path(\"/Volumes/Neurolang_1/Master Program/New_Thesis_topic/Experiments_Results\")  #Path(\"~\").expanduser() / 'Data' / 'Alice'\n",
    "PREDICTOR_audio_DIR = DATA_ROOT / 'TRFs_pridictors/audio_predictors'\n",
    "PREDICTOR_word_DIR = DATA_ROOT / 'TRFs_pridictors/word_predictors'\n",
    "EEG_DIR = DATA_ROOT / 'EEG_Natives' / 'Alice_natives_ICAed_fif'\n",
    "Native_SUBJECTS = [path.name for path in EEG_DIR.iterdir() if re.match(r'S\\d*', path.name)]\n",
    "# Define a target directory for TRF estimates and make sure the directory is created\n",
    "TRF_DIR = DATA_ROOT / 'TRFs_Natives'\n",
    "TRF_DIR.mkdir(exist_ok=True)\n",
    "print(Native_SUBJECTS)\n",
    "print(len(Native_SUBJECTS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "01186976",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<NDVar 'envelope': 5862 time>, <NDVar 'envelope': 6193 time>, <NDVar 'envelope': 6434 time>, <NDVar 'envelope': 7107 time>, <NDVar 'envelope': 6736 time>, <NDVar 'envelope': 6487 time>, <NDVar 'envelope': 6398 time>, <NDVar 'envelope': 5839 time>, <NDVar 'envelope': 5831 time>, <NDVar 'envelope': 6235 time>, <NDVar 'envelope': 5725 time>, <NDVar 'envelope': 4807 time>]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\n# Plot every envelope (Don't know why it all overlay into one figs)\\nfor i in range(0, 2):\\n    p = None\\n    print(envelope[i].get_data())\\n    p = plt.plot(envelope[i].get_data())\\n\""
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the broad-band envelope from the gammatone pickle files\n",
    "envelope = [eelbrain.load.unpickle(PREDICTOR_audio_DIR / f'{stimulus}~gammatone-1.pickle') for stimulus in STIMULI]  # Load in the data\n",
    "\"\"\"# Code Explanation\n",
    "envelopeL = []\n",
    "for stimulus in STIMULI:\n",
    "    envelope = eelbrain.load.unpickle(PREDICTOR_audio_DIR / f'{stimulus}~gammatone-1.pickle')\n",
    "    print(envelope)\n",
    "    envelopeL.append(envelope)\n",
    "\"\"\"\n",
    "# To down sample into 100 Hz\n",
    "envelope = [x.bin(0.01, dim='time', label='start') for x in envelope]\n",
    "#print(envelope)\n",
    "\"\"\" # Code Explanation\n",
    "envelopeL_2 = []\n",
    "for x in envelope:\n",
    "    envelope = x.bin(0.01, dim='time', label='start')\n",
    "    envelopeL_2.append(envelope)\n",
    "\"\"\"\n",
    "# To covert it into the NDVar structures\n",
    "envelope = [trftools.pad(x, tstart=-0.100, tstop=x.time.tstop + 1, name='envelope') for x in envelope]\n",
    "\"\"\" # Code Explanation\n",
    "envelopeL_3 = []\n",
    "for x in envelope:\n",
    "    envelope = trftools.pad(x, tstart=-0.100, tstop=x.time.tstop + 1, name='envelope')\n",
    "    envelopeL_3.append(envelope)\n",
    "print(envelopeL_3)\n",
    "\"\"\"\n",
    "\n",
    "print(envelope)\n",
    "#dir(envelope[1])\n",
    "#print(envelope[1].get_data())\n",
    "\n",
    "\"\"\"\n",
    "# Plot every envelope (Don't know why it all overlay into one figs)\n",
    "for i in range(0, 2):\n",
    "    p = None\n",
    "    print(envelope[i].get_data())\n",
    "    p = plt.plot(envelope[i].get_data())\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "20432fcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21.51142955 10.75571477  5.37785739  2.68892869  1.34446435  0.67223217]\n",
      "(5862, 6)\n",
      "(5862, 6)\n",
      "[18.86807686  9.43403843  4.71701922  2.35850961  1.1792548   0.5896274 ]\n",
      "(6193, 6)\n",
      "(12055, 6)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/h7/sdf5cvgx3qzf5rh744693x0r0000gn/T/ipykernel_69032/2844608183.py:25: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  n_IF = np.concatenate(np.array(IF_ndarray)) #, axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23.70220703 11.85110351  5.92555176  2.96277588  1.48138794  0.74069397]\n",
      "(6434, 6)\n",
      "(18489, 6)\n",
      "[22.66779232 11.33389616  5.66694808  2.83347404  1.41673702  0.70836851]\n",
      "(7107, 6)\n",
      "(25596, 6)\n",
      "[23.21852732 11.60926366  5.80463183  2.90231591  1.45115796  0.72557898]\n",
      "(6736, 6)\n",
      "(32332, 6)\n",
      "[22.4525975  11.22629875  5.61314938  2.80657469  1.40328734  0.70164367]\n",
      "(6487, 6)\n",
      "(38819, 6)\n",
      "[22.8508909  11.42544545  5.71272273  2.85636136  1.42818068  0.71409034]\n",
      "(6398, 6)\n",
      "(45217, 6)\n",
      "[21.77598904 10.88799452  5.44399726  2.72199863  1.36099931  0.68049966]\n",
      "(5839, 6)\n",
      "(51056, 6)\n",
      "[21.08557709 10.54278854  5.27139427  2.63569714  1.31784857  0.65892428]\n",
      "(5831, 6)\n",
      "(56887, 6)\n",
      "[21.98877306 10.99438653  5.49719326  2.74859663  1.37429832  0.68714916]\n",
      "(6235, 6)\n",
      "(63122, 6)\n",
      "[21.72925764 10.86462882  5.43231441  2.71615721  1.3580786   0.6790393 ]\n",
      "(5725, 6)\n",
      "(68847, 6)\n",
      "[21.67672145 10.83836072  5.41918036  2.70959018  1.35479509  0.67739755]\n",
      "(4807, 6)\n",
      "(73654, 6)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\n[18.86807686  9.43403843  4.71701922  2.35850961  1.1792548   0.5896274 ]>> = 每個IMF最多的頻率\\n# 每個ＩＭＦ的順時頻率都做一個TRF 去跑統計\\n4hz>> close to the syllables, 18 hz >> close to phoneme speed, but normally we consider syllables as speed\\n>> use the third IMF >> \\n# IP, IF, IA = emd.spectra.frequency_transform(imf, sample_rate, 'hilbert') get the IF\\n\""
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_rate = 100\n",
    "\"\"\"  # For IMF & IF testing commands\n",
    "imf, mask_freqs = emd.sift.mask_sift(envelope[1].get_data(), ret_mask_freq=True, max_imfs=6)  \n",
    "# delete >>, mask_freqs=30/sample_rate\n",
    "# xy = envelope data \n",
    "#print(mask_freqs * sample_rate)\n",
    "#emd.plotting.plot_imfs(imf)\n",
    "IP, IF, IA = emd.spectra.frequency_transform(imf, sample_rate, 'nht')\n",
    "\n",
    "pprint(IF[1:])\n",
    "print(IF.shape)\n",
    "#print(IF)\n",
    "\"\"\"\n",
    "#IF_ndarray = np.zeros(shape=[73665, 6])\n",
    "\n",
    "IF_ndarrayLIST = []\n",
    "for i in range(0, 12):\n",
    "    imf, mask_freqs = emd.sift.mask_sift(envelope[i].get_data(), ret_mask_freq=True, max_imfs=6)  \n",
    "    # delete >>, mask_freqs=30/sample_rate   # xy = envelope data \n",
    "    print(mask_freqs * sample_rate)\n",
    "    #emd.plotting.plot_imfs(imf)\n",
    "    IP, IF, IA = emd.spectra.frequency_transform(imf, sample_rate, 'hilbert') #get the IF\n",
    "    print(IF.shape)\n",
    "    IF_ndarrayLIST.append(IF)\n",
    "    n_IF_ndARRAY = np.concatenate(np.array(IF_ndarrayLIST))\n",
    "    print(n_IF_ndARRAY.shape)\n",
    "\n",
    "    \n",
    "\n",
    "\"\"\"\n",
    "dataDICT = pd.DataFrame(IF, columns = ['IMF1','IMF2','IMF3', 'IMF4','IMF5','IMF6'])\n",
    "file_name = 'ALL_IF_TRF_predictor_testing_tables.csv'\n",
    "save_path = DATA_ROOT/ \"TRFs_pridictors\" / Path(file_name)\n",
    "dataDICT.to_csv(save_path, sep = \",\" ,index = False , header = True, encoding = \"UTF-8\")\n",
    "\"\"\"\n",
    "\"\"\"\n",
    "[18.86807686  9.43403843  4.71701922  2.35850961  1.1792548   0.5896274 ]>> = 每個IMF最多的頻率\n",
    "# 每個ＩＭＦ的順時頻率都做一個TRF 去跑統計\n",
    "4hz>> close to the syllables, 18 hz >> close to phoneme speed, but normally we consider syllables as speed\n",
    ">> use the third IMF >> \n",
    "# IP, IF, IA = emd.spectra.frequency_transform(imf, sample_rate, 'hilbert') get the IF\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "866364f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To save the IF into a csv file\n",
    "dataDICT = pd.DataFrame(IF, columns = ['IMF1','IMF2','IMF3', 'IMF4','IMF5','IMF6'])\n",
    "#data_path = Path(\"/Volumes/Neurolang_1/Master Program/New_Thesis_topic/Experiments_Results/TRFs_pridictors\")\n",
    "file_name = 'IF_TRF_predictor_testing_tables.csv'\n",
    "save_path = DATA_ROOT/ \"TRFs_pridictors\" / Path(file_name)\n",
    "dataDICT.to_csv(save_path, sep = \",\" ,index = False , header = True, encoding = \"UTF-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59fb791e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
