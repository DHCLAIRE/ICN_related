{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7237917c-db70-442b-97d1-8d04eaee9bb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3d1c9c24-9a0f-450f-8360-dcb4186d8397",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/neuroling/anaconda3/envs/eelbrain/lib/python3.11/site-packages/eelbrain/mne_fixes/_interpolation.py:13: FutureWarning: mne.io.pick.pick_types is deprecated will be removed in 1.6, use documented public API instead. If no appropriate public API exists, please open an issue on GitHub.\n",
      "  from mne.io.pick import pick_types, pick_channels\n",
      "/Users/neuroling/anaconda3/envs/eelbrain/lib/python3.11/site-packages/eelbrain/mne_fixes/_interpolation.py:13: FutureWarning: mne.io.pick.pick_channels is deprecated will be removed in 1.6, use documented public API instead. If no appropriate public API exists, please open an issue on GitHub.\n",
      "  from mne.io.pick import pick_types, pick_channels\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import pyplot\n",
    "import eelbrain\n",
    "import mne\n",
    "#import trftools\n",
    "\n",
    "from pprint import pprint\n",
    "import numpy as np\n",
    "\n",
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "# import eelbrain\n",
    "# from pathlib import Path\n",
    "# import re\n",
    "import emd  # Ensure you ran: pip install EMD-signal\n",
    "from scipy.signal import hilbert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "68a6da85-e566-4830-8c9d-40c93a8ef389",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['n_2_S030_ICAed_raw.fif', 'n_2_S027_ICAed_raw.fif', 'n_2_S023_ICAed_raw.fif', 'n_2_S034_ICAed_raw.fif', 'n_2_S024_ICAed_raw.fif', 'n_2_S019_ICAed_raw.fif', 'n_2_S020_ICAed_raw.fif', 'n_2_S013_ICAed_raw.fif', 'n_2_S017_ICAed_raw.fif', 'n_2_S039_ICAed_raw.fif', 'n_2_S010_ICAed_raw.fif', 'n_2_S029_ICAed_raw.fif', 'n_2_S015_ICAed_raw.fif', 'n_2_S028_ICAed_raw.fif', 'n_2_S011_ICAed_raw.fif', 'n_2_S038_ICAed_raw.fif', 'n_2_S016_ICAed_raw.fif', 'n_2_S012_ICAed_raw.fif', 'n_2_S021_ICAed_raw.fif', 'n_2_S036_ICAed_raw.fif', 'n_2_S032_ICAed_raw.fif', 'n_2_S025_ICAed_raw.fif', 'n_2_S035_ICAed_raw.fif', 'n_2_S022_ICAed_raw.fif', 'n_2_S026_ICAed_raw.fif', 'n_2_S031_ICAed_raw.fif']\n",
      "26\n"
     ]
    }
   ],
   "source": [
    "## ESLs ##\n",
    "## Import the raw EEG data of ESLs(Alice)\n",
    "\n",
    "STIMULI = [str(i) for i in range(1, 13)]\n",
    "DATA_ROOT = Path(\"/Users/neuroling/Downloads/DINGHSIN_Results/Alice_Experiments_Results\")\n",
    "#DATA_ROOT = Path(\"/Volumes/Neurolang_1/Master Program/New_Thesis_topic/Experiments_Results\")  #Path(\"~\").expanduser() / 'Data' / 'Alice'\n",
    "PREDICTOR_audio_DIR = DATA_ROOT / 'TRFs_pridictors/audio_predictors'\n",
    "PREDICTOR_word_DIR = DATA_ROOT / 'TRFs_pridictors/word_predictors'\n",
    "EEG_DIR = DATA_ROOT / 'EEG_ESLs' / 'Alice_ESL_ICAed_fif'\n",
    "ESL_SUBJECTS = [path.name for path in EEG_DIR.iterdir() if re.match(r'n_2_S\\d*', path.name)]  #S01_alice-raw.fif\n",
    "# Define a target directory for TRF estimates and make sure the directory is created\n",
    "TRF_DIR = DATA_ROOT / 'TRFs_ESLs'\n",
    "TRF_DIR.mkdir(exist_ok=True)\n",
    "print(ESL_SUBJECTS)\n",
    "print(len(ESL_SUBJECTS))  # 26\n",
    "\n",
    "DST = TRF_DIR / 'ESLs_figures'\n",
    "DST.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4745a1e4-b314-4eef-8bcd-33744acd0daa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['S44_Alice-natives_sfreq-100_raw.fif', 'S20_Alice-natives_sfreq-100_raw.fif', 'S13_Alice-natives_sfreq-100_raw.fif', 'S01_Alice-natives_sfreq-100_raw.fif', 'S16_Alice-natives_sfreq-100_raw.fif', 'S41_Alice-natives_sfreq-100_raw.fif', 'S25_Alice-natives_sfreq-100_raw.fif', 'S37_Alice-natives_sfreq-100_raw.fif', 'S04_Alice-natives_sfreq-100_raw.fif', 'S18_Alice-natives_sfreq-100_raw.fif', 'S39_Alice-natives_sfreq-100_raw.fif', 'S10_Alice-natives_sfreq-100_raw.fif', 'S15_Alice-natives_sfreq-100_raw.fif', 'S26_Alice-natives_sfreq-100_raw.fif', 'S42_Alice-natives_sfreq-100_raw.fif', 'S34_Alice-natives_sfreq-100_raw.fif', 'S38_Alice-natives_sfreq-100_raw.fif', 'S19_Alice-natives_sfreq-100_raw.fif', 'S06_Alice-natives_sfreq-100_raw.fif', 'S35_Alice-natives_sfreq-100_raw.fif', 'S14_Alice-natives_sfreq-100_raw.fif', 'S03_Alice-natives_sfreq-100_raw.fif', 'S11_Alice-natives_sfreq-100_raw.fif', 'S22_Alice-natives_sfreq-100_raw.fif', 'S05_Alice-natives_sfreq-100_raw.fif', 'S36_Alice-natives_sfreq-100_raw.fif', 'S40_Alice-natives_sfreq-100_raw.fif', 'S17_Alice-natives_sfreq-100_raw.fif', 'S12_Alice-natives_sfreq-100_raw.fif', 'S45_Alice-natives_sfreq-100_raw.fif', 'S21_Alice-natives_sfreq-100_raw.fif', 'S48_Alice-natives_sfreq-100_raw.fif', 'S08_Alice-natives_sfreq-100_raw.fif']\n",
      "33\n"
     ]
    }
   ],
   "source": [
    "## Natives ##\n",
    "## Import the raw EEG data of ESLs(Alice)\n",
    "\n",
    "STIMULI = [str(i) for i in range(1, 13)]\n",
    "DATA_ROOT = Path(\"/Users/neuroling/Downloads/DINGHSIN_Results/Alice_Experiments_Results\") #Path(\"/Volumes/Neurolang_1/Master Program/New_Thesis_topic/Experiments_Results\")  #Path(\"~\").expanduser() / 'Data' / 'Alice'\n",
    "PREDICTOR_audio_DIR = DATA_ROOT / 'TRFs_pridictors/audio_predictors'\n",
    "PREDICTOR_word_DIR = DATA_ROOT / 'TRFs_pridictors/word_predictors'\n",
    "IMF_DIR = DATA_ROOT/ \"TRFs_pridictors/IF_predictors\"\n",
    "F0_DIR = DATA_ROOT/ \"TRFs_pridictors/F0_predictors\"\n",
    "IMFsLIST = [path.name for path in IMF_DIR.iterdir() if re.match(r'Alice_IF_IMF_*', path.name)]\n",
    "EEG_DIR = DATA_ROOT / 'EEG_Natives' / 'Alice_natives_ICAed_fif'\n",
    "SUBJECTS = [path.name for path in EEG_DIR.iterdir() if re.match(r'S\\d*', path.name[:4])]\n",
    "# Define a target directory for TRF estimates and make sure the directory is created\n",
    "TRF_DIR = DATA_ROOT / 'TRFs_Natives'\n",
    "TRF_DIR.mkdir(exist_ok=True)\n",
    "print(SUBJECTS)\n",
    "print(len(SUBJECTS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a31e8146-2195-473f-82b8-cec8f4056a3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load stimuli\n",
    "# ------------\n",
    "# Make sure to name the stimuli so that the TRFs can later be distinguished\n",
    "# Load the gammatone-spectrograms; use the time axis of these as reference\n",
    "gammatone = [eelbrain.load.unpickle(PREDICTOR_audio_DIR / f'{stimulus}~gammatone-8.pickle') for stimulus in STIMULI]\n",
    "\n",
    "# Resample the spectrograms to 100 Hz (time-step = 0.01 s), which we will use for TRFs\n",
    "gammatone = [x.bin(0.01, dim='time', label='start') for x in gammatone]\n",
    "\n",
    "# Pad onset with 100 ms and offset with 1 second; make sure to give the predictor a unique name as that will make it easier to identify the TRF later\n",
    "gammatone = [eelbrain.pad(x, tstart=-0.100, tstop=x.time.tstop + 1, name='gammatone') for x in gammatone]\n",
    "\n",
    "# Load the broad-band envelope and process it in the same way\n",
    "envelope = [eelbrain.load.unpickle(PREDICTOR_audio_DIR / f'{stimulus}~gammatone-1.pickle') for stimulus in STIMULI]  # Load in the data\n",
    "envelope = [x.bin(0.01, dim='time', label='start') for x in envelope]\n",
    "envelope = [eelbrain.pad(x, tstart=-0.100, tstop=x.time.tstop + 1, name='envelope') for x in envelope]\n",
    "onset_envelope = [eelbrain.load.unpickle(PREDICTOR_audio_DIR / f'{stimulus}~gammatone-on-1.pickle') for stimulus in STIMULI]\n",
    "onset_envelope = [x.bin(0.01, dim='time', label='start') for x in onset_envelope]\n",
    "onset_envelope = [eelbrain.pad(x, tstart=-0.100, tstop=x.time.tstop + 1, name='onset') for x in onset_envelope]\n",
    "\n",
    "# Load onset spectrograms and make sure the time dimension is equal to the gammatone spectrograms\n",
    "gammatone_onsets = [eelbrain.load.unpickle(PREDICTOR_audio_DIR / f'{stimulus}~gammatone-on-8.pickle') for stimulus in STIMULI]\n",
    "gammatone_onsets = [x.bin(0.01, dim='time', label='start') for x in gammatone_onsets]\n",
    "gammatone_onsets = [eelbrain.set_time(x, gt.time, name='gammatone_on') for x, gt in zip(gammatone_onsets, gammatone)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "905b472f-1749-48cb-8b3e-85b9c14126d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== WORD ONSET IS DOWN BELOW =====\n",
      "<NDVar 'word': 500 time>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\n# Estimate TRFs\\n# -------------\\n# Loop through subjects to estimate TRFs\\nfor subject in SUBJECTS:\\n    subject_trf_dir = TRF_DIR / subject[:3]\\n    subject_trf_dir.mkdir(exist_ok=True)\\n    # Generate all TRF paths so we can check whether any new TRFs need to be estimated\\n    trf_paths = {model: subject_trf_dir / f'{subject[:3]} {model}.pickle' for model in models}\\n    # Skip this subject if all files already exist\\n    #if all(path.exists() for path in trf_paths.values()):\\n        #continue\\n    # Load the EEG data\\n    raw = mne.io.read_raw_fif(EEG_DIR / f'{subject}', preload=True)  # subject /\\n    # Band-pass filter the raw data between 0.5 and 20 Hz\\n    raw.filter(0.5, 20)\\n    # Interpolate bad channels\\n    raw.interpolate_bads()\\n    # Extract the events marking the stimulus presentation from the EEG file\\n    events = eelbrain.load.fiff.events(raw)\\n    # Not all subjects have all trials; determine which stimuli are present\\n    trial_indexes = [STIMULI.index(stimulus) for stimulus in events['event']]\\n    # Extract the EEG data segments corresponding to the stimuli\\n    trial_durations = [durations[i] for i in trial_indexes]\\n    eeg = eelbrain.load.fiff.variable_length_epochs(events, -0.100, trial_durations, connectivity='auto')  #, decim=5 #decim=5 meaning to resample to sfreq=100Hz\\n    # Since trials are of unequal length, we will concatenate them for the TRF estimation.\\n    eeg_concatenated = eelbrain.concatenate(eeg)\\n    \\n    pprint(models.items)\\n    \""
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## This is the time point of every word onset time according to the Alice csv file ##\n",
    "\n",
    "# Load word tables and convert tables into continuous time-series with matching time dimension\n",
    "word_tables = [eelbrain.load.unpickle(PREDICTOR_word_DIR / f'{stimulus}~word.pickle') for stimulus in STIMULI]\n",
    "word_onsets = [eelbrain.event_impulse_predictor(gt.time, ds=ds, name='word') for gt, ds in zip(gammatone, word_tables)]\n",
    "\n",
    "#print(word_tables[-1]) #  the onset & offset of each tape\n",
    "print(\"===== WORD ONSET IS DOWN BELOW =====\")\n",
    "print(word_onsets[0][0:5])\n",
    "# This is the original Durations of 12 tapes based on gammatone\n",
    "# Extract the duration of the stimuli, so we can later match the EEG to the stimuli\n",
    "durations = [gt.time.tmax for stimulus, gt in zip(STIMULI, gammatone)]\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "# Estimate TRFs\n",
    "# -------------\n",
    "# Loop through subjects to estimate TRFs\n",
    "for subject in SUBJECTS:\n",
    "    subject_trf_dir = TRF_DIR / subject[:3]\n",
    "    subject_trf_dir.mkdir(exist_ok=True)\n",
    "    # Generate all TRF paths so we can check whether any new TRFs need to be estimated\n",
    "    trf_paths = {model: subject_trf_dir / f'{subject[:3]} {model}.pickle' for model in models}\n",
    "    # Skip this subject if all files already exist\n",
    "    #if all(path.exists() for path in trf_paths.values()):\n",
    "        #continue\n",
    "    # Load the EEG data\n",
    "    raw = mne.io.read_raw_fif(EEG_DIR / f'{subject}', preload=True)  # subject /\n",
    "    # Band-pass filter the raw data between 0.5 and 20 Hz\n",
    "    raw.filter(0.5, 20)\n",
    "    # Interpolate bad channels\n",
    "    raw.interpolate_bads()\n",
    "    # Extract the events marking the stimulus presentation from the EEG file\n",
    "    events = eelbrain.load.fiff.events(raw)\n",
    "    # Not all subjects have all trials; determine which stimuli are present\n",
    "    trial_indexes = [STIMULI.index(stimulus) for stimulus in events['event']]\n",
    "    # Extract the EEG data segments corresponding to the stimuli\n",
    "    trial_durations = [durations[i] for i in trial_indexes]\n",
    "    eeg = eelbrain.load.fiff.variable_length_epochs(events, -0.100, trial_durations, connectivity='auto')  #, decim=5 #decim=5 meaning to resample to sfreq=100Hz\n",
    "    # Since trials are of unequal length, we will concatenate them for the TRF estimation.\n",
    "    eeg_concatenated = eelbrain.concatenate(eeg)\n",
    "    \n",
    "    pprint(models.items)\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6973146b-a3bb-45c9-b959-46dfd49466ab",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'word_onsets' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 29\u001b[0m\n\u001b[1;32m     25\u001b[0m     tape_start \u001b[38;5;241m=\u001b[39m events[i][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mi_start\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;66;03m#['time']\u001b[39;00m\n\u001b[1;32m     27\u001b[0m     \u001b[38;5;66;03m# Get word onset times for this specific tape from your list\u001b[39;00m\n\u001b[1;32m     28\u001b[0m     \u001b[38;5;66;03m# word_onsets[stimulus_idx] is your impulse predictor\u001b[39;00m\n\u001b[0;32m---> 29\u001b[0m     onsets \u001b[38;5;241m=\u001b[39m word_onsets[stimulus_idx]\u001b[38;5;241m.\u001b[39mtime\u001b[38;5;241m.\u001b[39mtimes[word_onsets[stimulus_idx]\u001b[38;5;241m.\u001b[39mx \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     30\u001b[0m     \u001b[38;5;28mprint\u001b[39m(onsets, \u001b[38;5;28mlen\u001b[39m(onsets))\n\u001b[1;32m     32\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;124;03m    # Convert relative word times to absolute EEG times\u001b[39;00m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;124;03m    absolute_onsets = tape_start + onsets\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;124;03m# eeg_data = ds_all_words['eeg'].get_data()\u001b[39;00m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'word_onsets' is not defined"
     ]
    }
   ],
   "source": [
    "## Got to the wrong length of the word onset\n",
    "\n",
    "## Gemini-Produced\n",
    "## To segment the raw EEG based on word start time == word onset time ##\n",
    "# ... your loading code ...\n",
    "\n",
    "for subject in SUBJECTS:\n",
    "    # 1. Load Raw as an Eelbrain-compatible object\n",
    "    raw = mne.io.read_raw_fif(EEG_DIR / f'{subject}', preload=True)\n",
    "    raw_sfreq = raw.info['sfreq']\n",
    "    \n",
    "    # 2. Get the events for the 12 tapes\n",
    "    events = eelbrain.load.mne.events(raw)\n",
    "    trial_indexes = [STIMULI.index(stimulus) for stimulus in events['event']]\n",
    "    # 3. Define your epoch window\n",
    "    # We use a 1.5s window (including buffers for HHSA)\n",
    "    tmin, tmax = -0.3, 1.2 \n",
    "    \n",
    "    # 4. Extract segments for each tape\n",
    "    # This creates a list of NDVars, each containing the epochs for one tape\n",
    "    all_tapes_epochs = []\n",
    "    \n",
    "    for i, stimulus_idx in enumerate(trial_indexes):\n",
    "        # We find the start of the tape in the raw EEG\n",
    "        tape_start = events[i]['i_start']#['time']\n",
    "        \n",
    "        # Get word onset times for this specific tape from your list\n",
    "        # word_onsets[stimulus_idx] is your impulse predictor\n",
    "        onsets = word_onsets[stimulus_idx].time.times[word_onsets[stimulus_idx].x > 0]\n",
    "        print(onsets, len(onsets))\n",
    "\n",
    "        \"\"\"\n",
    "        # Convert relative word times to absolute EEG times\n",
    "        absolute_onsets = tape_start + onsets\n",
    "        \n",
    "        # Create segments (Epochs) directly in Eelbrain\n",
    "        # This is much faster and more accurate than manual padding/cropping\n",
    "        tape_word_epochs = eelbrain.load.mne.epochs(\n",
    "            raw, tmin=tmin, tmax=tmax, baseline=None, \n",
    "            events=absolute_onsets\n",
    "        )\n",
    "        all_tapes_epochs.append(tape_word_epochs)\n",
    "\n",
    "    # 5. Combine all words from all tapes into one Dataset\n",
    "    # This 'ds' will have a column for 'EEG' and can have a column for 'Subject'\n",
    "    ds_all_words = eelbrain.combine(all_tapes_epochs)\n",
    "    \n",
    "    # Now you can access the data for HHSA:\n",
    "    # eeg_data = ds_all_words['eeg'].get_data()\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94f36ef5-03af-4e7e-84fa-68e3009bf109",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import eelbrain\n",
    "from pathlib import Path\n",
    "import re\n",
    "import emd  # Ensure you ran: pip install EMD-signal\n",
    "from scipy.signal import hilbert\n",
    "\"\"\"\n",
    "\n",
    "## Conduct HHSA ##\n",
    "## Step one\n",
    "\n",
    "\n",
    "# ==========================================\n",
    "# 1. CORE ANALYSIS FUNCTIONS\n",
    "# ==========================================\n",
    "def get_inst_freq_amp(signal, fs):\n",
    "    \"\"\"\n",
    "    Calculates instantaneous amplitude and frequency using Hilbert Transform.\n",
    "    \"\"\"\n",
    "    analytic_signal = hilbert(signal)\n",
    "    amplitude = np.abs(analytic_signal)\n",
    "    instantaneous_phase = np.unwrap(np.angle(analytic_signal))\n",
    "    \n",
    "    # Derivative of phase for frequency\n",
    "    inst_freq = np.diff(instantaneous_phase) / (2.0 * np.pi) * fs\n",
    "    # Pad last point to match length\n",
    "    inst_freq = np.append(inst_freq, inst_freq[-1])\n",
    "    \n",
    "    return amplitude, inst_freq\n",
    "\n",
    "def run_hhsa(signal, fs):\n",
    "    \"\"\"\n",
    "    Performs Two-Layer EMD with Mirror Padding for short signals.\n",
    "    \"\"\"\n",
    "    if signal.ndim > 1: signal = signal.flatten()\n",
    "    \n",
    "    n_samples = len(signal)\n",
    "    \n",
    "    # Safety Check for empty/tiny signals\n",
    "    if n_samples < 10: return None\n",
    "\n",
    "    # --- A. MIRROR PADDING (Crucial for 114-point TRFs) ---\n",
    "    # We reflect the signal to make it 3x longer so EMD works\n",
    "    pad_width = n_samples\n",
    "    padded_signal = np.pad(signal, pad_width, mode='reflect')\n",
    "    \n",
    "    # --- B. LAYER 1: CARRIER DECOMPOSITION ---\n",
    "    try:\n",
    "        # Use emd.sift.sift (Quinn library)\n",
    "        # max_imfs=5 is enough for a simple TRF response\n",
    "        imfs_layer1 = emd.sift.sift(padded_signal, max_imfs=5)\n",
    "        imfs_layer1 = imfs_layer1.T  # Transpose to (N_IMFs, N_Time)\n",
    "    except Exception:\n",
    "        return None\n",
    "        \n",
    "    holo_points = []\n",
    "    \n",
    "    for imf_c in imfs_layer1:\n",
    "        # Un-pad: Extract the middle 'real' part\n",
    "        imf_c_real = imf_c[pad_width : pad_width + n_samples]\n",
    "        \n",
    "        # Get Carrier Frequency & Envelope\n",
    "        env_c, freq_c = get_inst_freq_amp(imf_c_real, fs)\n",
    "        \n",
    "        # Skip flat/empty IMFs\n",
    "        if np.sum(np.abs(env_c)) < 1e-10: continue\n",
    "\n",
    "        # --- C. LAYER 2: AM DECOMPOSITION ---\n",
    "        # Pad the envelope before sifting\n",
    "        padded_env = np.pad(env_c, pad_width, mode='reflect')\n",
    "        \n",
    "        try:\n",
    "            imfs_layer2 = emd.sift.sift(padded_env, max_imfs=5)\n",
    "            imfs_layer2 = imfs_layer2.T\n",
    "        except:\n",
    "            continue\n",
    "            \n",
    "        for imf_am in imfs_layer2:\n",
    "            # Un-pad AM result\n",
    "            imf_am_real = imf_am[pad_width : pad_width + n_samples]\n",
    "            \n",
    "            _, freq_am = get_inst_freq_amp(imf_am_real, fs)\n",
    "            power_am = imf_am_real**2\n",
    "            \n",
    "            # Filter for valid graph range\n",
    "            mask = (freq_c > 0) & (freq_c < fs/2) & (freq_am > 0) & (freq_am < fs/2)\n",
    "            idx = np.where(mask)[0]\n",
    "            \n",
    "            if len(idx) > 0:\n",
    "                # Store [Carrier_Freq, AM_Freq, Power]\n",
    "                points = np.vstack((freq_c[idx], freq_am[idx], power_am[idx])).T\n",
    "                holo_points.append(points)\n",
    "                \n",
    "    if not holo_points: return None\n",
    "    return np.vstack(holo_points)\n",
    "\n",
    "# ==========================================\n",
    "# 2. EXPERIMENT CONFIGURATION\n",
    "# ==========================================\n",
    "DATA_ROOT = Path(\"/Users/neuroling/Downloads/DINGHSIN_Results/Alice_Experiments_Results\")\n",
    "EEG_DIR = DATA_ROOT / 'EEG_ESLs' / 'Alice_ESL_ICAed_fif'\n",
    "TRF_DIR = DATA_ROOT / 'TRFs_ESLs'\n",
    "\n",
    "# Extract Subjects\n",
    "ESL_SUBJECTS = [path.name for path in EEG_DIR.iterdir() if re.match(r'n_2_S\\d*', path.name)]\n",
    "print(f\"Found {len(ESL_SUBJECTS)} subjects.\")\n",
    "\n",
    "# Settings\n",
    "TARGET_MODEL = 'Fzero'\n",
    "LIMIT_CARRIER = 5  # Hz\n",
    "LIMIT_AM = 5       # Hz\n",
    "NBINS = 50\n",
    "\n",
    "group_spectrum_sum = None\n",
    "n_subjects_processed = 0\n",
    "\n",
    "# ==========================================\n",
    "# 3. MAIN LOOP\n",
    "# ==========================================\n",
    "print(f\"Starting Group HHSA on Model: {TARGET_MODEL}\")\n",
    "\n",
    "for subject in ESL_SUBJECTS:\n",
    "    subject_id_short = subject[4:8] # 'S010'\n",
    "    file_path = TRF_DIR / subject_id_short / f'{subject_id_short} {TARGET_MODEL}.pickle'\n",
    "    \n",
    "    if not file_path.exists():\n",
    "        continue\n",
    "\n",
    "    try:\n",
    "        # --- LOAD DATA ---\n",
    "        trf_obj = eelbrain.load.unpickle(file_path)\n",
    "        \n",
    "        # Handle h vs h_scaled\n",
    "        if hasattr(trf_obj, 'h_scaled'):\n",
    "            data_ndvar = trf_obj.h_scaled\n",
    "        else:\n",
    "            data_ndvar = trf_obj.h\n",
    "\n",
    "        # Handle Tuple (Partitioned Data)\n",
    "        if isinstance(data_ndvar, tuple):\n",
    "            data_ndvar = data_ndvar[0]\n",
    "\n",
    "        # --- EXTRACT PREDICTOR ---\n",
    "        trf_final = None\n",
    "        \n",
    "        # Strategy 1: Try name 'envelope'\n",
    "        try:\n",
    "            trf_final = data_ndvar['Fzero']\n",
    "        except:\n",
    "            # Strategy 2: Try Index\n",
    "            # If dims are [predictor, time], we grab the 2nd predictor (index 1)\n",
    "            # Assuming the order is [F0, Envelope]\n",
    "            dims = data_ndvar.dimnames\n",
    "            non_time_dims = [d for d in dims if d != 'time' and d != 'sensor']\n",
    "            \n",
    "            if len(non_time_dims) > 0:\n",
    "                dim_name = non_time_dims[0]\n",
    "                # Index 1 = Envelope. Change to 0 if you want F0.\n",
    "                trf_final = data_ndvar.sub(**{dim_name: 1}) \n",
    "            else:\n",
    "                trf_final = data_ndvar\n",
    "\n",
    "        # Average Sensors\n",
    "        if 'sensor' in trf_final.dimnames:\n",
    "            trf_final = trf_final.mean('sensor')\n",
    "            \n",
    "        trf_vector = trf_final.x\n",
    "        fs = 1.0 / trf_final.time.tstep\n",
    "        \n",
    "        # --- RUN HHSA ---\n",
    "        # print(f\"  Processing {subject_id_short}...\")\n",
    "        holo_data = run_hhsa(trf_vector, fs)\n",
    "        \n",
    "        if holo_data is None: \n",
    "            continue\n",
    "            \n",
    "        # --- DEBUG PRINT ---\n",
    "        # Print the average frequencies found for this subject\n",
    "        avg_fc = np.mean(holo_data[:, 0])\n",
    "        avg_fam = np.mean(holo_data[:, 1])\n",
    "        print(f\"  Subject {subject_id_short}: Avg Carrier={avg_fc:.2f}Hz, Avg AM={avg_fam:.2f}Hz\")\n",
    "        # -------------------\n",
    "        \n",
    "\n",
    "        # --- BIN RESULTS ---\n",
    "        fc = holo_data[:, 0]\n",
    "        fam = holo_data[:, 1]\n",
    "        power = holo_data[:, 2]\n",
    "        \n",
    "        H_subj, xedges, yedges = np.histogram2d(fc, fam, bins=NBINS, weights=power,\n",
    "                                           range=[[0, LIMIT_CARRIER], [0, LIMIT_AM]])\n",
    "        \n",
    "        if group_spectrum_sum is None:\n",
    "            group_spectrum_sum = H_subj\n",
    "        else:\n",
    "            group_spectrum_sum += H_subj\n",
    "            \n",
    "        n_subjects_processed += 1\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"  [Error] Failed on {subject_id_short}: {e}\")\n",
    "        continue\n",
    "\n",
    "# ==========================================\n",
    "# 4. PLOT FINAL RESULT\n",
    "# ==========================================\n",
    "if n_subjects_processed > 0:\n",
    "    group_avg_spectrum = group_spectrum_sum / n_subjects_processed\n",
    "    \n",
    "    plt.figure(figsize=(10, 8))\n",
    "    # Note: .T is used because imshow expects [rows, cols] = [y, x]\n",
    "    plt.imshow(group_avg_spectrum.T, origin='lower', cmap='jet', aspect='auto',\n",
    "               extent=[0, LIMIT_CARRIER, 0, LIMIT_AM], interpolation='gaussian')\n",
    "    \n",
    "    plt.colorbar(label='Modulation Power (a.u.)')\n",
    "    plt.xlabel('Carrier Frequency (Hz)')\n",
    "    plt.ylabel('AM Frequency (Hz)')\n",
    "    plt.title(f'Group HHSA (N={n_subjects_processed})\\nModel: {TARGET_MODEL} | Predictor: Envelope')\n",
    "    \n",
    "    # Diagonal line (1:1 coupling)\n",
    "    plt.plot([0, LIMIT_AM], [0, LIMIT_AM], 'w--', alpha=0.5)\n",
    "    plt.savefig(TRF_DIR / 'ESLs_Fzero_HHSA_TRF.png')\n",
    "    plt.show()\n",
    "    print(\"Success!\")\n",
    "else:\n",
    "    print(\"No subjects processed. Please check if pickle files contain the expected data structure.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c8ada7a-18b9-46c9-9480-435c3278c2cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import eelbrain\n",
    "from pathlib import Path\n",
    "import emd\n",
    "from scipy.signal import hilbert\n",
    "\"\"\"\n",
    "# Version 1 of IMFs in each layers (=second EMD)\n",
    "\n",
    "# ==========================================\n",
    "# 1. CONFIGURATION\n",
    "# ==========================================\n",
    "DATA_ROOT = Path(\"/Users/neuroling/Downloads/DINGHSIN_Results/Alice_Experiments_Results\")\n",
    "TRF_DIR = DATA_ROOT / 'TRFs_ESLs'\n",
    "TARGET_MODEL = 'Fzero+envelope'\n",
    "TARGET_SUBJECT = 'S010'  # <--- Change this to look at different subjects\n",
    "\n",
    "# Which Layer 1 IMF do you want to decompose further?\n",
    "# 0 = First IMF (Fastest/Highest Freq), 1 = Second IMF, etc.\n",
    "TARGET_IMF_INDEX = 1 \n",
    "\n",
    "# ==========================================\n",
    "# 2. LOAD DATA (Robust Loading)\n",
    "# ==========================================\n",
    "file_path = TRF_DIR / TARGET_SUBJECT / f'{TARGET_SUBJECT} {TARGET_MODEL}.pickle'\n",
    "print(f\"Loading {TARGET_SUBJECT}...\")\n",
    "\n",
    "try:\n",
    "    trf_obj = eelbrain.load.unpickle(file_path)\n",
    "    \n",
    "    # Handle h vs h_scaled\n",
    "    if hasattr(trf_obj, 'h_scaled'):\n",
    "        data_ndvar = trf_obj.h_scaled\n",
    "    else:\n",
    "        data_ndvar = trf_obj.h\n",
    "        \n",
    "    # Handle Tuple\n",
    "    if isinstance(data_ndvar, tuple):\n",
    "        data_ndvar = data_ndvar[0]\n",
    "\n",
    "    # Extract Predictor (Strategy: Index)\n",
    "    # Assumes order is [F0, Envelope] -> Index 1 is Envelope\n",
    "    # If your model is just 'envelope', it might be Index 0.\n",
    "    try:\n",
    "        # Try finding 'envelope' by name\n",
    "        trf_final = data_ndvar['envelope']\n",
    "        pred_name = \"Envelope\"\n",
    "    except:\n",
    "        # Fallback to Index 1\n",
    "        dims = data_ndvar.dimnames\n",
    "        non_time_dims = [d for d in dims if d != 'time' and d != 'sensor']\n",
    "        if len(non_time_dims) > 0:\n",
    "            trf_final = data_ndvar.sub(**{non_time_dims[0]: 1})\n",
    "            pred_name = \"Predictor (Index 1)\"\n",
    "        else:\n",
    "            trf_final = data_ndvar\n",
    "            pred_name = \"Predictor\"\n",
    "\n",
    "    # Average Sensors\n",
    "    if 'sensor' in trf_final.dimnames:\n",
    "        trf_final = trf_final.mean('sensor')\n",
    "        \n",
    "    signal = trf_final.x\n",
    "    times = trf_final.time.times\n",
    "    fs = 1.0 / trf_final.time.tstep\n",
    "\n",
    "    if signal.ndim > 1: signal = signal.flatten()\n",
    "    print(f\"Data Loaded: {len(signal)} samples\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error loading: {e}\")\n",
    "    exit()\n",
    "\n",
    "# ==========================================\n",
    "# 3. PROCESSING (With Mirror Padding)\n",
    "# ==========================================\n",
    "\n",
    "# --- A. Layer 1 Decomposition ---\n",
    "pad_width = len(signal)\n",
    "padded_signal = np.pad(signal, pad_width, mode='reflect')\n",
    "\n",
    "# Run EMD (Sift)\n",
    "imfs_layer1_padded = emd.sift.sift(padded_signal, max_imfs=5)\n",
    "\n",
    "# Un-pad Layer 1\n",
    "# Note: emd output is (Samples, IMFs)\n",
    "imfs_layer1 = imfs_layer1_padded[pad_width : pad_width + len(signal), :]\n",
    "n_imfs1 = imfs_layer1.shape[1]\n",
    "\n",
    "# --- B. Layer 2 Decomposition (Target IMF) ---\n",
    "# Extract the target IMF (e.g., IMF 0)\n",
    "target_imf_padded = imfs_layer1_padded[:, TARGET_IMF_INDEX]\n",
    "\n",
    "# Get Envelope (using Hilbert)\n",
    "analytic = hilbert(target_imf_padded)\n",
    "envelope_padded = np.abs(analytic)\n",
    "\n",
    "# Run EMD on Envelope\n",
    "imfs_layer2_padded = emd.sift.sift(envelope_padded, max_imfs=4)\n",
    "\n",
    "# Un-pad Layer 2\n",
    "envelope_real = envelope_padded[pad_width : pad_width + len(signal)]\n",
    "imfs_layer2 = imfs_layer2_padded[pad_width : pad_width + len(signal), :]\n",
    "n_imfs2 = imfs_layer2.shape[1]\n",
    "\n",
    "# ==========================================\n",
    "# 4. PLOTTING\n",
    "# ==========================================\n",
    "\n",
    "# --- FIGURE 1: LAYER 1 (Carrier) ---\n",
    "fig1, axes1 = plt.subplots(n_imfs1 + 1, 1, figsize=(10, 8), sharex=True)\n",
    "fig1.suptitle(f\"Layer 1: Carrier Decomposition ({TARGET_SUBJECT})\", fontsize=14)\n",
    "\n",
    "# Plot Original Signal\n",
    "axes1[0].plot(times, signal, 'k', label='Original TRF')\n",
    "axes1[0].set_title(f\"Original Signal: {pred_name}\")\n",
    "axes1[0].legend(loc='upper right')\n",
    "\n",
    "# Plot IMFs\n",
    "for i in range(n_imfs1):\n",
    "    ax = axes1[i + 1]\n",
    "    ax.plot(times, imfs_layer1[:, i], 'b')\n",
    "    ax.set_ylabel(f\"IMF {i+1}\")\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "axes1[-1].set_xlabel(\"Time (s)\")\n",
    "plt.tight_layout()\n",
    "#plt.savefig(TRF_DIR / 'ESLs_S010_layer1-IMFs_HHSA_TRF.png')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# --- FIGURE 2: LAYER 2 (Amplitude Modulation) ---\n",
    "fig2, axes2 = plt.subplots(n_imfs2 + 1, 1, figsize=(10, 8), sharex=True)\n",
    "fig2.suptitle(f\"Layer 2: AM Decomposition of Carrier IMF {TARGET_IMF_INDEX+1}\", fontsize=14)\n",
    "\n",
    "# Plot Envelope\n",
    "axes2[0].plot(times, envelope_real, 'r', label=f'Envelope of IMF {TARGET_IMF_INDEX+1}')\n",
    "axes2[0].set_title(\"Amplitude Envelope (Input to Layer 2)\")\n",
    "axes2[0].legend(loc='upper right')\n",
    "\n",
    "# Plot AM IMFs\n",
    "for i in range(n_imfs2):\n",
    "    ax = axes2[i + 1]\n",
    "    ax.plot(times, imfs_layer2[:, i], 'g')\n",
    "    ax.set_ylabel(f\"AM IMF {i+1}\")\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "axes2[-1].set_xlabel(\"Time (s)\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(TRF_DIR / 'ESLs_S010_layer2-IMF2_HHSA_TRF.png')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
