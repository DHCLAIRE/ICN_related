{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7237917c-db70-442b-97d1-8d04eaee9bb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3d1c9c24-9a0f-450f-8360-dcb4186d8397",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/neuroling/anaconda3/envs/eelbrain/lib/python3.11/site-packages/eelbrain/mne_fixes/_interpolation.py:13: FutureWarning: mne.io.pick.pick_types is deprecated will be removed in 1.6, use documented public API instead. If no appropriate public API exists, please open an issue on GitHub.\n",
      "  from mne.io.pick import pick_types, pick_channels\n",
      "/Users/neuroling/anaconda3/envs/eelbrain/lib/python3.11/site-packages/eelbrain/mne_fixes/_interpolation.py:13: FutureWarning: mne.io.pick.pick_channels is deprecated will be removed in 1.6, use documented public API instead. If no appropriate public API exists, please open an issue on GitHub.\n",
      "  from mne.io.pick import pick_types, pick_channels\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import pyplot\n",
    "import eelbrain\n",
    "import mne\n",
    "#import trftools\n",
    "from pprint import pprint\n",
    "import numpy as np\n",
    "\n",
    "import emd  # Ensure you ran: pip install EMD-signal\n",
    "from scipy.signal import hilbert\n",
    "\n",
    "import csv\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "68a6da85-e566-4830-8c9d-40c93a8ef389",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['n_2_S030_ICAed_raw.fif', 'n_2_S027_ICAed_raw.fif', 'n_2_S023_ICAed_raw.fif', 'n_2_S034_ICAed_raw.fif', 'n_2_S024_ICAed_raw.fif', 'n_2_S019_ICAed_raw.fif', 'n_2_S020_ICAed_raw.fif', 'n_2_S013_ICAed_raw.fif', 'n_2_S017_ICAed_raw.fif', 'n_2_S039_ICAed_raw.fif', 'n_2_S010_ICAed_raw.fif', 'n_2_S029_ICAed_raw.fif', 'n_2_S015_ICAed_raw.fif', 'n_2_S028_ICAed_raw.fif', 'n_2_S011_ICAed_raw.fif', 'n_2_S038_ICAed_raw.fif', 'n_2_S016_ICAed_raw.fif', 'n_2_S012_ICAed_raw.fif', 'n_2_S021_ICAed_raw.fif', 'n_2_S036_ICAed_raw.fif', 'n_2_S032_ICAed_raw.fif', 'n_2_S025_ICAed_raw.fif', 'n_2_S035_ICAed_raw.fif', 'n_2_S022_ICAed_raw.fif', 'n_2_S026_ICAed_raw.fif', 'n_2_S031_ICAed_raw.fif']\n",
      "26\n"
     ]
    }
   ],
   "source": [
    "## ESLs ##\n",
    "## Import the raw EEG data of ESLs(Alice)\n",
    "\n",
    "STIMULI = [str(i) for i in range(1, 13)]\n",
    "DATA_ROOT = Path(\"/Users/neuroling/Downloads/DINGHSIN_Results/Alice_Experiments_Results\")\n",
    "#DATA_ROOT = Path(\"/Volumes/Neurolang_1/Master Program/New_Thesis_topic/Experiments_Results\")  #Path(\"~\").expanduser() / 'Data' / 'Alice'\n",
    "PREDICTOR_audio_DIR = DATA_ROOT / 'TRFs_pridictors/audio_predictors'\n",
    "PREDICTOR_word_DIR = DATA_ROOT / 'TRFs_pridictors/word_predictors'\n",
    "EEG_DIR = DATA_ROOT / 'EEG_ESLs' / 'Alice_ESL_ICAed_fif'\n",
    "ESL_SUBJECTS = [path.name for path in EEG_DIR.iterdir() if re.match(r'n_2_S\\d*', path.name)]  #S01_alice-raw.fif\n",
    "# Define a target directory for TRF estimates and make sure the directory is created\n",
    "TRF_DIR = DATA_ROOT / 'TRFs_ESLs'\n",
    "TRF_DIR.mkdir(exist_ok=True)\n",
    "print(ESL_SUBJECTS)\n",
    "print(len(ESL_SUBJECTS))  # 26\n",
    "\n",
    "DST = TRF_DIR / 'ESLs_figures'\n",
    "DST.mkdir(exist_ok=True)\n",
    "\n",
    "wOnset_DIR = DATA_ROOT / 'EEG_ESLs' / 'Alice_ESLs_wOnset_raw_epochs'\n",
    "wOnset_DIR .mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "45be25b7-0a68-4d75-a6f6-1b70a57e1918",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "         Word  Segment      onset\n",
      "174       but        2   0.479840\n",
      "175      when        2   0.592424\n",
      "176       the        2   0.810806\n",
      "177    Rabbit        2   0.912952\n",
      "178  actually        2   1.415810\n",
      "..        ...      ...        ...\n",
      "346       was        2  58.681660\n",
      "347     going        2  58.861252\n",
      "348        to        2  59.148599\n",
      "349    happen        2  59.251158\n",
      "350      next        2  59.687374\n",
      "\n",
      "[177 rows x 3 columns] <class 'pandas.core.frame.DataFrame'>\n",
      "174     0.479840\n",
      "175     0.592424\n",
      "176     0.810806\n",
      "177     0.912952\n",
      "178     1.415810\n",
      "         ...    \n",
      "346    58.681660\n",
      "347    58.861252\n",
      "348    59.148599\n",
      "349    59.251158\n",
      "350    59.687374\n",
      "Name: onset, Length: 177, dtype: float64\n",
      "2\n",
      "         Word  Segment      onset\n",
      "174       but        2   0.479840\n",
      "175      when        2   0.592424\n",
      "176       the        2   0.810806\n",
      "177    Rabbit        2   0.912952\n",
      "178  actually        2   1.415810\n",
      "..        ...      ...        ...\n",
      "346       was        2  58.681660\n",
      "347     going        2  58.861252\n",
      "348        to        2  59.148599\n",
      "349    happen        2  59.251158\n",
      "350      next        2  59.687374\n",
      "\n",
      "[177 rows x 3 columns] <class 'pandas.core.frame.DataFrame'>\n",
      "174     0.479840\n",
      "175     0.592424\n",
      "176     0.810806\n",
      "177     0.912952\n",
      "178     1.415810\n",
      "         ...    \n",
      "346    58.681660\n",
      "347    58.861252\n",
      "348    59.148599\n",
      "349    59.251158\n",
      "350    59.687374\n",
      "Name: onset, Length: 177, dtype: float64\n",
      "3\n",
      "         Word  Segment      onset\n",
      "174       but        2   0.479840\n",
      "175      when        2   0.592424\n",
      "176       the        2   0.810806\n",
      "177    Rabbit        2   0.912952\n",
      "178  actually        2   1.415810\n",
      "..        ...      ...        ...\n",
      "346       was        2  58.681660\n",
      "347     going        2  58.861252\n",
      "348        to        2  59.148599\n",
      "349    happen        2  59.251158\n",
      "350      next        2  59.687374\n",
      "\n",
      "[177 rows x 3 columns] <class 'pandas.core.frame.DataFrame'>\n",
      "174     0.479840\n",
      "175     0.592424\n",
      "176     0.810806\n",
      "177     0.912952\n",
      "178     1.415810\n",
      "         ...    \n",
      "346    58.681660\n",
      "347    58.861252\n",
      "348    59.148599\n",
      "349    59.251158\n",
      "350    59.687374\n",
      "Name: onset, Length: 177, dtype: float64\n",
      "4\n",
      "         Word  Segment      onset\n",
      "174       but        2   0.479840\n",
      "175      when        2   0.592424\n",
      "176       the        2   0.810806\n",
      "177    Rabbit        2   0.912952\n",
      "178  actually        2   1.415810\n",
      "..        ...      ...        ...\n",
      "346       was        2  58.681660\n",
      "347     going        2  58.861252\n",
      "348        to        2  59.148599\n",
      "349    happen        2  59.251158\n",
      "350      next        2  59.687374\n",
      "\n",
      "[177 rows x 3 columns] <class 'pandas.core.frame.DataFrame'>\n",
      "174     0.479840\n",
      "175     0.592424\n",
      "176     0.810806\n",
      "177     0.912952\n",
      "178     1.415810\n",
      "         ...    \n",
      "346    58.681660\n",
      "347    58.861252\n",
      "348    59.148599\n",
      "349    59.251158\n",
      "350    59.687374\n",
      "Name: onset, Length: 177, dtype: float64\n",
      "5\n",
      "         Word  Segment      onset\n",
      "174       but        2   0.479840\n",
      "175      when        2   0.592424\n",
      "176       the        2   0.810806\n",
      "177    Rabbit        2   0.912952\n",
      "178  actually        2   1.415810\n",
      "..        ...      ...        ...\n",
      "346       was        2  58.681660\n",
      "347     going        2  58.861252\n",
      "348        to        2  59.148599\n",
      "349    happen        2  59.251158\n",
      "350      next        2  59.687374\n",
      "\n",
      "[177 rows x 3 columns] <class 'pandas.core.frame.DataFrame'>\n",
      "174     0.479840\n",
      "175     0.592424\n",
      "176     0.810806\n",
      "177     0.912952\n",
      "178     1.415810\n",
      "         ...    \n",
      "346    58.681660\n",
      "347    58.861252\n",
      "348    59.148599\n",
      "349    59.251158\n",
      "350    59.687374\n",
      "Name: onset, Length: 177, dtype: float64\n",
      "6\n",
      "         Word  Segment      onset\n",
      "174       but        2   0.479840\n",
      "175      when        2   0.592424\n",
      "176       the        2   0.810806\n",
      "177    Rabbit        2   0.912952\n",
      "178  actually        2   1.415810\n",
      "..        ...      ...        ...\n",
      "346       was        2  58.681660\n",
      "347     going        2  58.861252\n",
      "348        to        2  59.148599\n",
      "349    happen        2  59.251158\n",
      "350      next        2  59.687374\n",
      "\n",
      "[177 rows x 3 columns] <class 'pandas.core.frame.DataFrame'>\n",
      "174     0.479840\n",
      "175     0.592424\n",
      "176     0.810806\n",
      "177     0.912952\n",
      "178     1.415810\n",
      "         ...    \n",
      "346    58.681660\n",
      "347    58.861252\n",
      "348    59.148599\n",
      "349    59.251158\n",
      "350    59.687374\n",
      "Name: onset, Length: 177, dtype: float64\n",
      "7\n",
      "         Word  Segment      onset\n",
      "174       but        2   0.479840\n",
      "175      when        2   0.592424\n",
      "176       the        2   0.810806\n",
      "177    Rabbit        2   0.912952\n",
      "178  actually        2   1.415810\n",
      "..        ...      ...        ...\n",
      "346       was        2  58.681660\n",
      "347     going        2  58.861252\n",
      "348        to        2  59.148599\n",
      "349    happen        2  59.251158\n",
      "350      next        2  59.687374\n",
      "\n",
      "[177 rows x 3 columns] <class 'pandas.core.frame.DataFrame'>\n",
      "174     0.479840\n",
      "175     0.592424\n",
      "176     0.810806\n",
      "177     0.912952\n",
      "178     1.415810\n",
      "         ...    \n",
      "346    58.681660\n",
      "347    58.861252\n",
      "348    59.148599\n",
      "349    59.251158\n",
      "350    59.687374\n",
      "Name: onset, Length: 177, dtype: float64\n",
      "8\n",
      "         Word  Segment      onset\n",
      "174       but        2   0.479840\n",
      "175      when        2   0.592424\n",
      "176       the        2   0.810806\n",
      "177    Rabbit        2   0.912952\n",
      "178  actually        2   1.415810\n",
      "..        ...      ...        ...\n",
      "346       was        2  58.681660\n",
      "347     going        2  58.861252\n",
      "348        to        2  59.148599\n",
      "349    happen        2  59.251158\n",
      "350      next        2  59.687374\n",
      "\n",
      "[177 rows x 3 columns] <class 'pandas.core.frame.DataFrame'>\n",
      "174     0.479840\n",
      "175     0.592424\n",
      "176     0.810806\n",
      "177     0.912952\n",
      "178     1.415810\n",
      "         ...    \n",
      "346    58.681660\n",
      "347    58.861252\n",
      "348    59.148599\n",
      "349    59.251158\n",
      "350    59.687374\n",
      "Name: onset, Length: 177, dtype: float64\n",
      "9\n",
      "         Word  Segment      onset\n",
      "174       but        2   0.479840\n",
      "175      when        2   0.592424\n",
      "176       the        2   0.810806\n",
      "177    Rabbit        2   0.912952\n",
      "178  actually        2   1.415810\n",
      "..        ...      ...        ...\n",
      "346       was        2  58.681660\n",
      "347     going        2  58.861252\n",
      "348        to        2  59.148599\n",
      "349    happen        2  59.251158\n",
      "350      next        2  59.687374\n",
      "\n",
      "[177 rows x 3 columns] <class 'pandas.core.frame.DataFrame'>\n",
      "174     0.479840\n",
      "175     0.592424\n",
      "176     0.810806\n",
      "177     0.912952\n",
      "178     1.415810\n",
      "         ...    \n",
      "346    58.681660\n",
      "347    58.861252\n",
      "348    59.148599\n",
      "349    59.251158\n",
      "350    59.687374\n",
      "Name: onset, Length: 177, dtype: float64\n",
      "10\n",
      "         Word  Segment      onset\n",
      "174       but        2   0.479840\n",
      "175      when        2   0.592424\n",
      "176       the        2   0.810806\n",
      "177    Rabbit        2   0.912952\n",
      "178  actually        2   1.415810\n",
      "..        ...      ...        ...\n",
      "346       was        2  58.681660\n",
      "347     going        2  58.861252\n",
      "348        to        2  59.148599\n",
      "349    happen        2  59.251158\n",
      "350      next        2  59.687374\n",
      "\n",
      "[177 rows x 3 columns] <class 'pandas.core.frame.DataFrame'>\n",
      "174     0.479840\n",
      "175     0.592424\n",
      "176     0.810806\n",
      "177     0.912952\n",
      "178     1.415810\n",
      "         ...    \n",
      "346    58.681660\n",
      "347    58.861252\n",
      "348    59.148599\n",
      "349    59.251158\n",
      "350    59.687374\n",
      "Name: onset, Length: 177, dtype: float64\n",
      "11\n",
      "         Word  Segment      onset\n",
      "174       but        2   0.479840\n",
      "175      when        2   0.592424\n",
      "176       the        2   0.810806\n",
      "177    Rabbit        2   0.912952\n",
      "178  actually        2   1.415810\n",
      "..        ...      ...        ...\n",
      "346       was        2  58.681660\n",
      "347     going        2  58.861252\n",
      "348        to        2  59.148599\n",
      "349    happen        2  59.251158\n",
      "350      next        2  59.687374\n",
      "\n",
      "[177 rows x 3 columns] <class 'pandas.core.frame.DataFrame'>\n",
      "174     0.479840\n",
      "175     0.592424\n",
      "176     0.810806\n",
      "177     0.912952\n",
      "178     1.415810\n",
      "         ...    \n",
      "346    58.681660\n",
      "347    58.861252\n",
      "348    59.148599\n",
      "349    59.251158\n",
      "350    59.687374\n",
      "Name: onset, Length: 177, dtype: float64\n",
      "12\n",
      "         Word  Segment      onset\n",
      "174       but        2   0.479840\n",
      "175      when        2   0.592424\n",
      "176       the        2   0.810806\n",
      "177    Rabbit        2   0.912952\n",
      "178  actually        2   1.415810\n",
      "..        ...      ...        ...\n",
      "346       was        2  58.681660\n",
      "347     going        2  58.861252\n",
      "348        to        2  59.148599\n",
      "349    happen        2  59.251158\n",
      "350      next        2  59.687374\n",
      "\n",
      "[177 rows x 3 columns] <class 'pandas.core.frame.DataFrame'>\n",
      "174     0.479840\n",
      "175     0.592424\n",
      "176     0.810806\n",
      "177     0.912952\n",
      "178     1.415810\n",
      "         ...    \n",
      "346    58.681660\n",
      "347    58.861252\n",
      "348    59.148599\n",
      "349    59.251158\n",
      "350    59.687374\n",
      "Name: onset, Length: 177, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Import the csv data\n",
    "csv_data = DATA_ROOT / \"Alice(EEG_mat_and stimuli)\" / \"AliceChapterOne-EEG.csv\"  # self-made LMM data form\n",
    "\n",
    "\n",
    "word_onset_LIST = []\n",
    "with open(csv_data, \"r\", encoding=\"UTF-8\") as f:\n",
    "    fileDF = pd.read_csv(f, sep=\",\")\n",
    "    #print(fileDF.columns)\n",
    "    # word_onset = fileDF[\"onset\"]\n",
    "    # print(word_onset, type(word_onset))\n",
    "\n",
    "    word_onset_essentials_DF = fileDF.iloc[:,[0, 1, 2] ]     # first column\n",
    "    #print(word_onset_essentials_DF[\"onset\"], word_onset_essentials_DF[\"onset\"])\n",
    "    #print()\n",
    "\n",
    "    for i in range(1, 13):\n",
    "        print(i)\n",
    "        #w_S = word_onset_essentials_DF.loc[:, [i][\"Word\"]]\n",
    "        #wOnset_F = word_onset_essentials_DF.loc[:, 2]\n",
    "        #print(w_S)\n",
    "\n",
    "        wOnset_DF = word_onset_essentials_DF.loc[word_onset_essentials_DF[\"Segment\"] == 2, :]\n",
    "        print(wOnset_DF, type(wOnset_DF))\n",
    "        print(wOnset_DF[\"onset\"])\n",
    "        \"\"\"\n",
    "        if \n",
    "        w_S = word_onset_essentials_DF.iloc[i, 0]\n",
    "        wOnset_F = word_onset_essentials_DF.iloc[i, 2]\n",
    "        print(w_S, wOnset_F)\n",
    "        \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "10ab0499-ecba-460c-97c7-93074b333aa4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "subject_num= n_2_S030_ICAed_raw.fif\n",
      "subject_num= n_2_S027_ICAed_raw.fif\n",
      "subject_num= n_2_S023_ICAed_raw.fif\n"
     ]
    }
   ],
   "source": [
    "for subject in ESL_SUBJECTS[0:3]:\n",
    "    print(\"subject_num=\", subject)\n",
    "    \n",
    "    # 1. Load Raw as an Eelbrain-compatible object\n",
    "    raw = mne.io.read_raw_fif(EEG_DIR / f'{subject}', preload=True)\n",
    "    raw_sfreq = raw.info['sfreq']\n",
    "    \n",
    "    # 2. Get the events for the 12 tapes\n",
    "    events_DICT = eelbrain.load.mne.events(raw)\n",
    "    #print(events_DICT[\"event\"])\n",
    "    \n",
    "    \"\"\"\n",
    "    if len(events_DICT[\"event\"])==12:\n",
    "        pass\n",
    "    else:\n",
    "        print(subject[:3], \"tape_length\", )\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b8b403a0-7674-47e9-a96f-8c1bb7e5793b",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "'99' is not in list",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m trial_indexes \u001b[38;5;241m=\u001b[39m [STIMULI\u001b[38;5;241m.\u001b[39mindex(stimulus) \u001b[38;5;28;01mfor\u001b[39;00m stimulus \u001b[38;5;129;01min\u001b[39;00m events_DICT[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mevent\u001b[39m\u001b[38;5;124m'\u001b[39m]]\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m stimulus \u001b[38;5;129;01min\u001b[39;00m events_DICT[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mevent\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m stimulus \u001b[38;5;129;01min\u001b[39;00m STIMULI:\n",
      "Cell \u001b[0;32mIn[19], line 1\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[0;32m----> 1\u001b[0m trial_indexes \u001b[38;5;241m=\u001b[39m [STIMULI\u001b[38;5;241m.\u001b[39mindex(stimulus) \u001b[38;5;28;01mfor\u001b[39;00m stimulus \u001b[38;5;129;01min\u001b[39;00m events_DICT[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mevent\u001b[39m\u001b[38;5;124m'\u001b[39m]]\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m stimulus \u001b[38;5;129;01min\u001b[39;00m events_DICT[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mevent\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m stimulus \u001b[38;5;129;01min\u001b[39;00m STIMULI:\n",
      "\u001b[0;31mValueError\u001b[0m: '99' is not in list"
     ]
    }
   ],
   "source": [
    "trial_indexes = [STIMULI.index(stimulus) for stimulus in events_DICT['event']]\n",
    "trial_indexes = [STIMULI.index(stimulus) for stimulus in events['event'] if stimulus in STIMULI]  # type(trial_indexes)==LIST\n",
    "for stimulus in events_DICT['event']:\n",
    "    if stimulus in STIMULI:\n",
    "        STIMULI.index(stimulus)\n",
    "    else:\n",
    "        pass\n",
    "for i, stimulus_idx in enumerate(trial_indexes[1:]):\n",
    "    print(\"i = \", i)\n",
    "    print(\"stimulus_idx\", stimulus_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c652718b-a322-4fed-be4a-18685a181144",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "subject_num= S030\n",
      "i_start   trigger   event\n",
      "-------------------------\n",
      "3130      1         1    \n",
      "8931      16        99   \n",
      "8982      9         51   \n",
      "9002      5         2    \n",
      "15103     16        99   \n",
      "15154     10        52   \n",
      "15174     6         3    \n",
      "21575     16        99   \n",
      "21646     7         4    \n",
      "28647     16        99   \n",
      "28718     8         5    \n",
      "35419     16        99   \n",
      "35470     11        55   \n",
      "35490     12        6    \n",
      "41891     16        99   \n",
      "41962     13        7    \n",
      "48263     16        99   \n",
      "48334     14        8    \n",
      "54135     16        99   \n",
      "54206     15        9    \n",
      "60007     16        99   \n",
      "60078     2         10   \n",
      "66279     16        99   \n",
      "66350     3         11   \n",
      "72051     16        99   \n",
      "72122     4         12   \n",
      "subject_num= S027\n",
      "i_start   trigger   event\n",
      "-------------------------\n",
      "3498      1         1    \n",
      "9299      19        99   \n",
      "9350      9         51   \n",
      "9370      5         2    \n",
      "15471     19        99   \n",
      "15542     6         3    \n",
      "21943     19        99   \n",
      "21994     10        53   \n",
      "22015     7         4    \n",
      "29016     19        99   \n",
      "29067     11        54   \n",
      "29087     8         5    \n",
      "35788     19        99   \n",
      "35859     14        6    \n",
      "42260     19        99   \n",
      "42311     12        56   \n",
      "42331     16        7    \n",
      "48632     19        99   \n",
      "48703     17        8    \n",
      "54504     19        99   \n",
      "54575     18        9    \n",
      "60376     19        99   \n",
      "60427     13        59   \n",
      "60447     2         10   \n",
      "66648     19        99   \n",
      "66719     3         11   \n",
      "72420     19        99   \n",
      "72471     15        61   \n",
      "72491     4         12   \n",
      "subject_num= S023\n",
      "i_start   trigger   event\n",
      "-------------------------\n",
      "1509      1         1    \n",
      "7310      19        99   \n",
      "7361      9         51   \n",
      "7381      5         2    \n",
      "13482     19        99   \n",
      "13553     6         3    \n",
      "19954     19        99   \n",
      "20005     10        53   \n",
      "20026     7         4    \n",
      "27027     19        99   \n",
      "27078     11        54   \n",
      "27098     8         5    \n",
      "33799     19        99   \n",
      "33870     13        6    \n",
      "40271     19        99   \n",
      "40322     12        56   \n",
      "40342     16        7    \n",
      "46643     19        99   \n",
      "46714     17        8    \n",
      "52515     19        99   \n",
      "52586     18        9    \n",
      "58387     19        99   \n",
      "58458     2         10   \n",
      "64659     19        99   \n",
      "64730     3         11   \n",
      "70431     19        99   \n",
      "70482     14        61   \n",
      "70502     4         12   \n",
      "75204     19        99   \n",
      "75255     15        62   \n"
     ]
    }
   ],
   "source": [
    "for subject in ESL_SUBJECTS[0:3]:\n",
    "    print(\"subject_num=\", subject[4:8])\n",
    "    \n",
    "    # 1. Load Raw as an Eelbrain-compatible object\n",
    "    raw = mne.io.read_raw_fif(EEG_DIR / f'{subject}', preload=True)\n",
    "    raw_sfreq = raw.info['sfreq']\n",
    "\n",
    "    # 2. Get the events for the 12 tapes\n",
    "    events_DICT = eelbrain.load.mne.events(raw)\n",
    "    #trial_indexes = [STIMULI.index(stimulus) for stimulus in events_DICT['event']]\n",
    "    trial_indexes = [STIMULI.index(stimulus) for stimulus in events_DICT['event'] if stimulus in STIMULI]  # type(trial_indexes)==LIST\n",
    "\n",
    "    print(events_DICT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bc4553ed-852e-47c9-be5b-c28dd2079f03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "subject_num= n_2_S030_ICAed_raw.fif\n",
      "tape_num= 2\n",
      "wOnset_perTape_DF=          Word  Segment      onset\n",
      "174       but        2   0.479840\n",
      "175      when        2   0.592424\n",
      "176       the        2   0.810806\n",
      "177    Rabbit        2   0.912952\n",
      "178  actually        2   1.415810\n",
      "..        ...      ...        ...\n",
      "346       was        2  58.681660\n",
      "347     going        2  58.861252\n",
      "348        to        2  59.148599\n",
      "349    happen        2  59.251158\n",
      "350      next        2  59.687374\n",
      "\n",
      "[177 rows x 3 columns]\n",
      "wOnset_datapoints_ndarray= [ 47.9839572  59.2424402  81.0806402  91.2952402 141.5810402 191.8667402\n",
      " 238.5605402 255.7777402 321.1728402 343.1803402 359.5218402 379.0771402\n",
      " 438.4907402 563.7331402 574.7717402] <class 'numpy.ndarray'>\n",
      "tape_start_datapoints_npINT64= 3130\n",
      "abs_wOnsets_dta_ndarray= [3177.9839572 3189.2424402 3211.0806402 3221.2952402 3271.5810402\n",
      " 3321.8667402 3368.5605402 3385.7777402 3451.1728402 3473.1803402\n",
      " 3489.5218402 3509.0771402 3568.4907402 3693.7331402 3704.7717402]\n",
      "rounded_abs_wOnsets_dta_ndarray= [3177 3189 3211 3221 3271 3321 3368 3385 3451 3473 3489 3509 3568 3693\n",
      " 3704]\n",
      "[[3177    0    2]\n",
      " [3189    0    2]\n",
      " [3211    0    2]\n",
      " [3221    0    2]\n",
      " [3271    0    2]\n",
      " [3321    0    2]\n",
      " [3368    0    2]\n",
      " [3385    0    2]\n",
      " [3451    0    2]\n",
      " [3473    0    2]\n",
      " [3489    0    2]\n",
      " [3509    0    2]\n",
      " [3568    0    2]\n",
      " [3693    0    2]\n",
      " [3704    0    2]\n",
      " [3737    0    2]\n",
      " [3758    0    2]\n",
      " [3818    0    2]\n",
      " [3829    0    2]\n",
      " [3845    0    2]\n",
      " [3884    0    2]\n",
      " [3976    0    2]\n",
      " [4024    0    2]\n",
      " [4066    0    2]\n",
      " [4085    0    2]\n",
      " [4099    0    2]\n",
      " [4140    0    2]\n",
      " [4162    0    2]\n",
      " [4174    0    2]\n",
      " [4215    0    2]\n",
      " [4260    0    2]\n",
      " [4267    0    2]\n",
      " [4349    0    2]\n",
      " [4361    0    2]\n",
      " [4372    0    2]\n",
      " [4383    0    2]\n",
      " [4420    0    2]\n",
      " [4462    0    2]\n",
      " [4505    0    2]\n",
      " [4513    0    2]\n",
      " [4550    0    2]\n",
      " [4567    0    2]\n",
      " [4605    0    2]\n",
      " [4615    0    2]\n",
      " [4659    0    2]\n",
      " [4714    0    2]\n",
      " [4742    0    2]\n",
      " [4747    0    2]\n",
      " [4788    0    2]\n",
      " [4800    0    2]\n",
      " [4828    0    2]\n",
      " [4848    0    2]\n",
      " [4861    0    2]\n",
      " [4931    0    2]\n",
      " [4957    0    2]\n",
      " [4995    0    2]\n",
      " [5011    0    2]\n",
      " [5138    0    2]\n",
      " [5159    0    2]\n",
      " [5184    0    2]\n",
      " [5224    0    2]\n",
      " [5233    0    2]\n",
      " [5271    0    2]\n",
      " [5316    0    2]\n",
      " [5370    0    2]\n",
      " [5389    0    2]\n",
      " [5488    0    2]\n",
      " [5516    0    2]\n",
      " [5554    0    2]\n",
      " [5567    0    2]\n",
      " [5598    0    2]\n",
      " [5608    0    2]\n",
      " [5627    0    2]\n",
      " [5643    0    2]\n",
      " [5676    0    2]\n",
      " [5699    0    2]\n",
      " [5709    0    2]\n",
      " [5748    0    2]\n",
      " [5782    0    2]\n",
      " [5812    0    2]\n",
      " [5840    0    2]\n",
      " [5850    0    2]\n",
      " [5995    0    2]\n",
      " [6015    0    2]\n",
      " [6057    0    2]\n",
      " [6113    0    2]\n",
      " [6147    0    2]\n",
      " [6165    0    2]\n",
      " [6206    0    2]\n",
      " [6248    0    2]\n",
      " [6300    0    2]\n",
      " [6328    0    2]\n",
      " [6367    0    2]\n",
      " [6449    0    2]\n",
      " [6476    0    2]\n",
      " [6488    0    2]\n",
      " [6497    0    2]\n",
      " [6537    0    2]\n",
      " [6554    0    2]\n",
      " [6577    0    2]\n",
      " [6586    0    2]\n",
      " [6602    0    2]\n",
      " [6623    0    2]\n",
      " [6779    0    2]\n",
      " [6788    0    2]\n",
      " [6826    0    2]\n",
      " [6845    0    2]\n",
      " [6860    0    2]\n",
      " [6898    0    2]\n",
      " [6917    0    2]\n",
      " [6935    0    2]\n",
      " [6942    0    2]\n",
      " [6983    0    2]\n",
      " [7001    0    2]\n",
      " [7031    0    2]\n",
      " [7090    0    2]\n",
      " [7108    0    2]\n",
      " [7130    0    2]\n",
      " [7155    0    2]\n",
      " [7214    0    2]\n",
      " [7275    0    2]\n",
      " [7309    0    2]\n",
      " [7402    0    2]\n",
      " [7414    0    2]\n",
      " [7456    0    2]\n",
      " [7474    0    2]\n",
      " [7491    0    2]\n",
      " [7496    0    2]\n",
      " [7550    0    2]\n",
      " [7559    0    2]\n",
      " [7585    0    2]\n",
      " [7614    0    2]\n",
      " [7664    0    2]\n",
      " [7715    0    2]\n",
      " [7749    0    2]\n",
      " [7772    0    2]\n",
      " [7797    0    2]\n",
      " [7840    0    2]\n",
      " [7876    0    2]\n",
      " [7897    0    2]\n",
      " [7906    0    2]\n",
      " [7949    0    2]\n",
      " [7982    0    2]\n",
      " [8151    0    2]\n",
      " [8186    0    2]\n",
      " [8199    0    2]\n",
      " [8229    0    2]\n",
      " [8247    0    2]\n",
      " [8283    0    2]\n",
      " [8343    0    2]\n",
      " [8348    0    2]\n",
      " [8374    0    2]\n",
      " [8395    0    2]\n",
      " [8424    0    2]\n",
      " [8538    0    2]\n",
      " [8553    0    2]\n",
      " [8569    0    2]\n",
      " [8589    0    2]\n",
      " [8645    0    2]\n",
      " [8660    0    2]\n",
      " [8692    0    2]\n",
      " [8706    0    2]\n",
      " [8723    0    2]\n",
      " [8747    0    2]\n",
      " [8816    0    2]\n",
      " [8829    0    2]\n",
      " [8854    0    2]\n",
      " [8891    0    2]\n",
      " [8917    0    2]\n",
      " [8931    0    2]\n",
      " [8946    0    2]\n",
      " [8981    0    2]\n",
      " [8998    0    2]\n",
      " [9016    0    2]\n",
      " [9044    0    2]\n",
      " [9055    0    2]\n",
      " [9098    0    2]]\n",
      "<Epochs |  173 events (all good), -0.3 – 1.2 s, baseline off, ~11.4 MB, data loaded,\n",
      " '2': 173>\n",
      "tape_num= 3\n",
      "wOnset_perTape_DF=       Word  Segment      onset\n",
      "351  First        3   0.478723\n",
      "352    she        3   0.986270\n",
      "353  tried        3   1.201781\n",
      "354     to        3   1.501100\n",
      "355   look        3   1.604643\n",
      "..     ...      ...        ...\n",
      "530   this        3  61.269264\n",
      "531   time        3  61.591394\n",
      "532    she        3  62.071440\n",
      "533   said        3  62.263005\n",
      "534  aloud        3  62.538379\n",
      "\n",
      "[184 rows x 3 columns]\n",
      "wOnset_datapoints_ndarray= [ 47.8723402  98.6269787 120.1780787 150.1099787 160.4642787 183.6337787\n",
      " 218.3548787 231.5249787 260.2596787 284.2052787 296.1780787 314.3827787\n",
      " 333.2936787 371.6065787 450.6269787] <class 'numpy.ndarray'>\n",
      "tape_start_datapoints_npINT64= 8931\n",
      "abs_wOnsets_dta_ndarray= [8978.8723402 9029.6269787 9051.1780787 9081.1099787 9091.4642787\n",
      " 9114.6337787 9149.3548787 9162.5249787 9191.2596787 9215.2052787\n",
      " 9227.1780787 9245.3827787 9264.2936787 9302.6065787 9381.6269787]\n",
      "rounded_abs_wOnsets_dta_ndarray= [8978 9029 9051 9081 9091 9114 9149 9162 9191 9215 9227 9245 9264 9302\n",
      " 9381]\n",
      "[[ 8978     0     3]\n",
      " [ 9029     0     3]\n",
      " [ 9051     0     3]\n",
      " [ 9081     0     3]\n",
      " [ 9091     0     3]\n",
      " [ 9114     0     3]\n",
      " [ 9149     0     3]\n",
      " [ 9162     0     3]\n",
      " [ 9191     0     3]\n",
      " [ 9215     0     3]\n",
      " [ 9227     0     3]\n",
      " [ 9245     0     3]\n",
      " [ 9264     0     3]\n",
      " [ 9302     0     3]\n",
      " [ 9381     0     3]\n",
      " [ 9392     0     3]\n",
      " [ 9403     0     3]\n",
      " [ 9419     0     3]\n",
      " [ 9436     0     3]\n",
      " [ 9461     0     3]\n",
      " [ 9475     0     3]\n",
      " [ 9500     0     3]\n",
      " [ 9651     0     3]\n",
      " [ 9671     0     3]\n",
      " [ 9697     0     3]\n",
      " [ 9722     0     3]\n",
      " [ 9733     0     3]\n",
      " [ 9742     0     3]\n",
      " [ 9779     0     3]\n",
      " [ 9787     0     3]\n",
      " [ 9797     0     3]\n",
      " [ 9883     0     3]\n",
      " [ 9898     0     3]\n",
      " [ 9938     0     3]\n",
      " [ 9951     0     3]\n",
      " [ 9964     0     3]\n",
      " [ 9977     0     3]\n",
      " [10011     0     3]\n",
      " [10028     0     3]\n",
      " [10086     0     3]\n",
      " [10107     0     3]\n",
      " [10338     0     3]\n",
      " [10363     0     3]\n",
      " [10378     0     3]\n",
      " [10406     0     3]\n",
      " [10431     0     3]\n",
      " [10455     0     3]\n",
      " [10509     0     3]\n",
      " [10521     0     3]\n",
      " [10568     0     3]\n",
      " [10585     0     3]\n",
      " [10603     0     3]\n",
      " [10622     0     3]\n",
      " [10758     0     3]\n",
      " [10776     0     3]\n",
      " [10800     0     3]\n",
      " [10827     0     3]\n",
      " [10836     0     3]\n",
      " [10878     0     3]\n",
      " [10894     0     3]\n",
      " [10911     0     3]\n",
      " [10920     0     3]\n",
      " [10929     0     3]\n",
      " [10976     0     3]\n",
      " [10983     0     3]\n",
      " [11003     0     3]\n",
      " [11097     0     3]\n",
      " [11111     0     3]\n",
      " [11131     0     3]\n",
      " [11188     0     3]\n",
      " [11242     0     3]\n",
      " [11364     0     3]\n",
      " [11377     0     3]\n",
      " [11385     0     3]\n",
      " [11400     0     3]\n",
      " [11435     0     3]\n",
      " [11509     0     3]\n",
      " [11521     0     3]\n",
      " [11541     0     3]\n",
      " [11655     0     3]\n",
      " [11673     0     3]\n",
      " [11688     0     3]\n",
      " [11707     0     3]\n",
      " [11724     0     3]\n",
      " [11734     0     3]\n",
      " [11766     0     3]\n",
      " [11776     0     3]\n",
      " [11801     0     3]\n",
      " [11818     0     3]\n",
      " [11848     0     3]\n",
      " [11855     0     3]\n",
      " [11892     0     3]\n",
      " [11972     0     3]\n",
      " [11988     0     3]\n",
      " [12006     0     3]\n",
      " [12051     0     3]\n",
      " [12059     0     3]\n",
      " [12079     0     3]\n",
      " [12091     0     3]\n",
      " [12125     0     3]\n",
      " [12142     0     3]\n",
      " [12152     0     3]\n",
      " [12161     0     3]\n",
      " [12211     0     3]\n",
      " [12220     0     3]\n",
      " [12240     0     3]\n",
      " [12262     0     3]\n",
      " [12305     0     3]\n",
      " [12505     0     3]\n",
      " [12584     0     3]\n",
      " [12600     0     3]\n",
      " [12643     0     3]\n",
      " [12656     0     3]\n",
      " [12722     0     3]\n",
      " [12756     0     3]\n",
      " [12783     0     3]\n",
      " [12789     0     3]\n",
      " [12816     0     3]\n",
      " [12836     0     3]\n",
      " [12865     0     3]\n",
      " [12871     0     3]\n",
      " [12892     0     3]\n",
      " [12919     0     3]\n",
      " [12978     0     3]\n",
      " [12986     0     3]\n",
      " [13033     0     3]\n",
      " [13058     0     3]\n",
      " [13198     0     3]\n",
      " [13231     0     3]\n",
      " [13283     0     3]\n",
      " [13297     0     3]\n",
      " [13307     0     3]\n",
      " [13326     0     3]\n",
      " [13356     0     3]\n",
      " [13368     0     3]\n",
      " [13382     0     3]\n",
      " [13473     0     3]\n",
      " [13503     0     3]\n",
      " [13512     0     3]\n",
      " [13531     0     3]\n",
      " [13542     0     3]\n",
      " [13563     0     3]\n",
      " [13612     0     3]\n",
      " [13641     0     3]\n",
      " [13655     0     3]\n",
      " [13683     0     3]\n",
      " [13699     0     3]\n",
      " [13713     0     3]\n",
      " [13738     0     3]\n",
      " [13756     0     3]\n",
      " [13767     0     3]\n",
      " [13797     0     3]\n",
      " [13805     0     3]\n",
      " [13817     0     3]\n",
      " [13932     0     3]\n",
      " [13955     0     3]\n",
      " [13973     0     3]\n",
      " [13999     0     3]\n",
      " [14039     0     3]\n",
      " [14206     0     3]\n",
      " [14307     0     3]\n",
      " [14420     0     3]\n",
      " [14529     0     3]\n",
      " [14539     0     3]\n",
      " [14546     0     3]\n",
      " [14574     0     3]\n",
      " [14631     0     3]\n",
      " [14659     0     3]\n",
      " [14676     0     3]\n",
      " [14690     0     3]\n",
      " [14812     0     3]\n",
      " [14830     0     3]\n",
      " [14873     0     3]\n",
      " [14902     0     3]\n",
      " [14925     0     3]\n",
      " [14976     0     3]\n",
      " [14987     0     3]\n",
      " [14995     0     3]\n",
      " [15036     0     3]\n",
      " [15057     0     3]\n",
      " [15090     0     3]\n",
      " [15138     0     3]\n",
      " [15157     0     3]\n",
      " [15184     0     3]]\n",
      "<Epochs |  178 events (all good), -0.3 – 1.2 s, baseline off, ~11.8 MB, data loaded,\n",
      " '3': 178>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/dt/yj00f34n5x52_p314tnwfjkw0000gn/T/ipykernel_30538/1641304678.py:107: RuntimeWarning: Concatenation of Annotations within Epochs is not supported yet. All annotations will be dropped.\n",
      "  wOnset_epochs = mne.concatenate_epochs(all_tapes_epochs_LIST)\n",
      "/var/folders/dt/yj00f34n5x52_p314tnwfjkw0000gn/T/ipykernel_30538/1641304678.py:107: RuntimeWarning: Concatenation of Annotations within Epochs is not supported yet. All annotations will be dropped.\n",
      "  wOnset_epochs = mne.concatenate_epochs(all_tapes_epochs_LIST)\n",
      "/var/folders/dt/yj00f34n5x52_p314tnwfjkw0000gn/T/ipykernel_30538/1641304678.py:107: RuntimeWarning: Concatenation of Annotations within Epochs is not supported yet. All annotations will be dropped.\n",
      "  wOnset_epochs = mne.concatenate_epochs(all_tapes_epochs_LIST)\n",
      "/var/folders/dt/yj00f34n5x52_p314tnwfjkw0000gn/T/ipykernel_30538/1641304678.py:107: RuntimeWarning: Concatenation of Annotations within Epochs is not supported yet. All annotations will be dropped.\n",
      "  wOnset_epochs = mne.concatenate_epochs(all_tapes_epochs_LIST)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tape_num= 4\n",
      "wOnset_perTape_DF=           Word  Segment      onset\n",
      "535       must        4   0.398386\n",
      "536         be        4   0.689428\n",
      "537    getting        4   0.840938\n",
      "538  somewhere        4   1.126350\n",
      "539       near        4   1.542892\n",
      "..         ...      ...        ...\n",
      "744      think        4  68.262788\n",
      "745        you        4  68.437370\n",
      "746      could        4  68.593016\n",
      "747     manage        4  68.760635\n",
      "748         it        4  69.129919\n",
      "\n",
      "[214 rows x 3 columns]\n",
      "wOnset_datapoints_ndarray= [ 39.8385787  68.9427631  84.0937631 112.6349631 154.2891631 177.2879631\n",
      " 184.4716631 225.1791631 234.7573631 248.5197631 312.5805631 335.3288631\n",
      " 347.3015631 380.8254631 399.0834631] <class 'numpy.ndarray'>\n",
      "tape_start_datapoints_npINT64= 8982\n",
      "abs_wOnsets_dta_ndarray= [9021.8385787 9050.9427631 9066.0937631 9094.6349631 9136.2891631\n",
      " 9159.2879631 9166.4716631 9207.1791631 9216.7573631 9230.5197631\n",
      " 9294.5805631 9317.3288631 9329.3015631 9362.8254631 9381.0834631]\n",
      "rounded_abs_wOnsets_dta_ndarray= [9021 9050 9066 9094 9136 9159 9166 9207 9216 9230 9294 9317 9329 9362\n",
      " 9381]\n",
      "[[ 9021     0     4]\n",
      " [ 9050     0     4]\n",
      " [ 9066     0     4]\n",
      " [ 9094     0     4]\n",
      " [ 9136     0     4]\n",
      " [ 9159     0     4]\n",
      " [ 9166     0     4]\n",
      " [ 9207     0     4]\n",
      " [ 9216     0     4]\n",
      " [ 9230     0     4]\n",
      " [ 9294     0     4]\n",
      " [ 9317     0     4]\n",
      " [ 9329     0     4]\n",
      " [ 9362     0     4]\n",
      " [ 9381     0     4]\n",
      " [ 9397     0     4]\n",
      " [ 9445     0     4]\n",
      " [ 9489     0     4]\n",
      " [ 9528     0     4]\n",
      " [ 9572     0     4]\n",
      " [ 9608     0     4]\n",
      " [ 9616     0     4]\n",
      " [ 9699     0     4]\n",
      " [ 9707     0     4]\n",
      " [ 9720     0     4]\n",
      " [ 9751     0     4]\n",
      " [ 9791     0     4]\n",
      " [ 9807     0     4]\n",
      " [ 9828     0     4]\n",
      " [ 9868     0     4]\n",
      " [ 9903     0     4]\n",
      " [ 9915     0     4]\n",
      " [ 9938     0     4]\n",
      " [ 9961     0     4]\n",
      " [ 9974     0     4]\n",
      " [ 9990     0     4]\n",
      " [10033     0     4]\n",
      " [10042     0     4]\n",
      " [10054     0     4]\n",
      " [10093     0     4]\n",
      " [10156     0     4]\n",
      " [10177     0     4]\n",
      " [10188     0     4]\n",
      " [10210     0     4]\n",
      " [10226     0     4]\n",
      " [10246     0     4]\n",
      " [10257     0     4]\n",
      " [10306     0     4]\n",
      " [10329     0     4]\n",
      " [10405     0     4]\n",
      " [10423     0     4]\n",
      " [10467     0     4]\n",
      " [10493     0     4]\n",
      " [10501     0     4]\n",
      " [10557     0     4]\n",
      " [10575     0     4]\n",
      " [10591     0     4]\n",
      " [10609     0     4]\n",
      " [10625     0     4]\n",
      " [10640     0     4]\n",
      " [10659     0     4]\n",
      " [10690     0     4]\n",
      " [10710     0     4]\n",
      " [10782     0     4]\n",
      " [10813     0     4]\n",
      " [10824     0     4]\n",
      " [10843     0     4]\n",
      " [10861     0     4]\n",
      " [10913     0     4]\n",
      " [10920     0     4]\n",
      " [10949     0     4]\n",
      " [10960     0     4]\n",
      " [11045     0     4]\n",
      " [11094     0     4]\n",
      " [11118     0     4]\n",
      " [11125     0     4]\n",
      " [11153     0     4]\n",
      " [11163     0     4]\n",
      " [11193     0     4]\n",
      " [11300     0     4]\n",
      " [11316     0     4]\n",
      " [11333     0     4]\n",
      " [11347     0     4]\n",
      " [11382     0     4]\n",
      " [11399     0     4]\n",
      " [11464     0     4]\n",
      " [11476     0     4]\n",
      " [11539     0     4]\n",
      " [11552     0     4]\n",
      " [11559     0     4]\n",
      " [11593     0     4]\n",
      " [11698     0     4]\n",
      " [11741     0     4]\n",
      " [11782     0     4]\n",
      " [11817     0     4]\n",
      " [11850     0     4]\n",
      " [11866     0     4]\n",
      " [11922     0     4]\n",
      " [11999     0     4]\n",
      " [12013     0     4]\n",
      " [12071     0     4]\n",
      " [12175     0     4]\n",
      " [12190     0     4]\n",
      " [12213     0     4]\n",
      " [12225     0     4]\n",
      " [12237     0     4]\n",
      " [12271     0     4]\n",
      " [12309     0     4]\n",
      " [12352     0     4]\n",
      " [12363     0     4]\n",
      " [12498     0     4]\n",
      " [12543     0     4]\n",
      " [12567     0     4]\n",
      " [12608     0     4]\n",
      " [12741     0     4]\n",
      " [12755     0     4]\n",
      " [12794     0     4]\n",
      " [12806     0     4]\n",
      " [12822     0     4]\n",
      " [12861     0     4]\n",
      " [12893     0     4]\n",
      " [12917     0     4]\n",
      " [12970     0     4]\n",
      " [12989     0     4]\n",
      " [13086     0     4]\n",
      " [13122     0     4]\n",
      " [13151     0     4]\n",
      " [13162     0     4]\n",
      " [13174     0     4]\n",
      " [13206     0     4]\n",
      " [13215     0     4]\n",
      " [13239     0     4]\n",
      " [13254     0     4]\n",
      " [13286     0     4]\n",
      " [13297     0     4]\n",
      " [13348     0     4]\n",
      " [13365     0     4]\n",
      " [13392     0     4]\n",
      " [13407     0     4]\n",
      " [13423     0     4]\n",
      " [13463     0     4]\n",
      " [13592     0     4]\n",
      " [13607     0     4]\n",
      " [13706     0     4]\n",
      " [13738     0     4]\n",
      " [13877     0     4]\n",
      " [13892     0     4]\n",
      " [13917     0     4]\n",
      " [13951     0     4]\n",
      " [13978     0     4]\n",
      " [13991     0     4]\n",
      " [14026     0     4]\n",
      " [14038     0     4]\n",
      " [14058     0     4]\n",
      " [14106     0     4]\n",
      " [14127     0     4]\n",
      " [14174     0     4]\n",
      " [14188     0     4]\n",
      " [14202     0     4]\n",
      " [14219     0     4]\n",
      " [14230     0     4]\n",
      " [14269     0     4]\n",
      " [14279     0     4]\n",
      " [14303     0     4]\n",
      " [14315     0     4]\n",
      " [14343     0     4]\n",
      " [14499     0     4]\n",
      " [14505     0     4]\n",
      " [14522     0     4]\n",
      " [14542     0     4]\n",
      " [14559     0     4]\n",
      " [14574     0     4]\n",
      " [14603     0     4]\n",
      " [14620     0     4]\n",
      " [14639     0     4]\n",
      " [14655     0     4]\n",
      " [14678     0     4]\n",
      " [14685     0     4]\n",
      " [14693     0     4]\n",
      " [14742     0     4]\n",
      " [14768     0     4]\n",
      " [14781     0     4]\n",
      " [14885     0     4]\n",
      " [14919     0     4]\n",
      " [14985     0     4]\n",
      " [15009     0     4]\n",
      " [15033     0     4]\n",
      " [15044     0     4]\n",
      " [15105     0     4]\n",
      " [15122     0     4]\n",
      " [15304     0     4]\n",
      " [15310     0     4]\n",
      " [15328     0     4]\n",
      " [15356     0     4]\n",
      " [15362     0     4]\n",
      " [15414     0     4]\n",
      " [15423     0     4]\n",
      " [15438     0     4]\n",
      " [15518     0     4]\n",
      " [15561     0     4]\n",
      " [15633     0     4]\n",
      " [15647     0     4]\n",
      " [15655     0     4]\n",
      " [15667     0     4]\n",
      " [15707     0     4]\n",
      " [15726     0     4]\n",
      " [15747     0     4]\n",
      " [15785     0     4]\n",
      " [15797     0     4]\n",
      " [15808     0     4]\n",
      " [15825     0     4]\n",
      " [15841     0     4]\n",
      " [15858     0     4]\n",
      " [15894     0     4]]\n",
      "<Epochs |  212 events (all good), -0.3 – 1.2 s, baseline off, ~14.0 MB, data loaded,\n",
      " '4': 212>\n",
      "tape_num= 5\n",
      "wOnset_perTape_DF=           Word  Segment      onset\n",
      "749        And        5   0.561146\n",
      "750       what        5   0.689847\n",
      "751         an        5   0.936113\n",
      "752   ignorant        5   1.115705\n",
      "753     little        5   1.618562\n",
      "..         ...      ...        ...\n",
      "937     saying        5  64.085883\n",
      "938         to        5  64.547542\n",
      "939        her        5  64.691215\n",
      "940       very        5  64.858834\n",
      "941  earnestly        5  65.313800\n",
      "\n",
      "[193 rows x 3 columns]\n",
      "wOnset_datapoints_ndarray= [ 56.1145631  68.9847173  93.6113173 111.5705173 161.8562173 185.8018173\n",
      " 210.7547173 222.0976173 231.2984173 252.8494173 264.8222173 284.7481173\n",
      " 410.8902173 452.7950173 466.6011173] <class 'numpy.ndarray'>\n",
      "tape_start_datapoints_npINT64= 9002\n",
      "abs_wOnsets_dta_ndarray= [9058.1145631 9070.9847173 9095.6113173 9113.5705173 9163.8562173\n",
      " 9187.8018173 9212.7547173 9224.0976173 9233.2984173 9254.8494173\n",
      " 9266.8222173 9286.7481173 9412.8902173 9454.7950173 9468.6011173]\n",
      "rounded_abs_wOnsets_dta_ndarray= [9058 9070 9095 9113 9163 9187 9212 9224 9233 9254 9266 9286 9412 9454\n",
      " 9468]\n",
      "[[ 9058     0     5]\n",
      " [ 9070     0     5]\n",
      " [ 9095     0     5]\n",
      " [ 9113     0     5]\n",
      " [ 9163     0     5]\n",
      " [ 9187     0     5]\n",
      " [ 9212     0     5]\n",
      " [ 9224     0     5]\n",
      " [ 9233     0     5]\n",
      " [ 9254     0     5]\n",
      " [ 9266     0     5]\n",
      " [ 9286     0     5]\n",
      " [ 9412     0     5]\n",
      " [ 9454     0     5]\n",
      " [ 9468     0     5]\n",
      " [ 9482     0     5]\n",
      " [ 9514     0     5]\n",
      " [ 9528     0     5]\n",
      " [ 9539     0     5]\n",
      " [ 9640     0     5]\n",
      " [ 9685     0     5]\n",
      " [ 9693     0     5]\n",
      " [ 9713     0     5]\n",
      " [ 9732     0     5]\n",
      " [ 9745     0     5]\n",
      " [ 9772     0     5]\n",
      " [ 9789     0     5]\n",
      " [ 9968     0     5]\n",
      " [10028     0     5]\n",
      " [10083     0     5]\n",
      " [10200     0     5]\n",
      " [10217     0     5]\n",
      " [10234     0     5]\n",
      " [10273     0     5]\n",
      " [10303     0     5]\n",
      " [10315     0     5]\n",
      " [10347     0     5]\n",
      " [10368     0     5]\n",
      " [10410     0     5]\n",
      " [10434     0     5]\n",
      " [10466     0     5]\n",
      " [10521     0     5]\n",
      " [10681     0     5]\n",
      " [10714     0     5]\n",
      " [10733     0     5]\n",
      " [10766     0     5]\n",
      " [10782     0     5]\n",
      " [10820     0     5]\n",
      " [10858     0     5]\n",
      " [10894     0     5]\n",
      " [10902     0     5]\n",
      " [10933     0     5]\n",
      " [11092     0     5]\n",
      " [11127     0     5]\n",
      " [11150     0     5]\n",
      " [11161     0     5]\n",
      " [11314     0     5]\n",
      " [11324     0     5]\n",
      " [11347     0     5]\n",
      " [11358     0     5]\n",
      " [11366     0     5]\n",
      " [11406     0     5]\n",
      " [11417     0     5]\n",
      " [11463     0     5]\n",
      " [11475     0     5]\n",
      " [11509     0     5]\n",
      " [11520     0     5]\n",
      " [11550     0     5]\n",
      " [11678     0     5]\n",
      " [11711     0     5]\n",
      " [11728     0     5]\n",
      " [11753     0     5]\n",
      " [11761     0     5]\n",
      " [11794     0     5]\n",
      " [11805     0     5]\n",
      " [11815     0     5]\n",
      " [11849     0     5]\n",
      " [11868     0     5]\n",
      " [11903     0     5]\n",
      " [11991     0     5]\n",
      " [12008     0     5]\n",
      " [12012     0     5]\n",
      " [12036     0     5]\n",
      " [12075     0     5]\n",
      " [12084     0     5]\n",
      " [12099     0     5]\n",
      " [12122     0     5]\n",
      " [12128     0     5]\n",
      " [12136     0     5]\n",
      " [12177     0     5]\n",
      " [12198     0     5]\n",
      " [12208     0     5]\n",
      " [12235     0     5]\n",
      " [12260     0     5]\n",
      " [12267     0     5]\n",
      " [12376     0     5]\n",
      " [12386     0     5]\n",
      " [12402     0     5]\n",
      " [12412     0     5]\n",
      " [12439     0     5]\n",
      " [12471     0     5]\n",
      " [12476     0     5]\n",
      " [12518     0     5]\n",
      " [12527     0     5]\n",
      " [12637     0     5]\n",
      " [12653     0     5]\n",
      " [12664     0     5]\n",
      " [12717     0     5]\n",
      " [12742     0     5]\n",
      " [12781     0     5]\n",
      " [12788     0     5]\n",
      " [12953     0     5]\n",
      " [12973     0     5]\n",
      " [12998     0     5]\n",
      " [13045     0     5]\n",
      " [13084     0     5]\n",
      " [13096     0     5]\n",
      " [13117     0     5]\n",
      " [13142     0     5]\n",
      " [13240     0     5]\n",
      " [13257     0     5]\n",
      " [13283     0     5]\n",
      " [13302     0     5]\n",
      " [13344     0     5]\n",
      " [13360     0     5]\n",
      " [13415     0     5]\n",
      " [13423     0     5]\n",
      " [13429     0     5]\n",
      " [13466     0     5]\n",
      " [13493     0     5]\n",
      " [13511     0     5]\n",
      " [13593     0     5]\n",
      " [13608     0     5]\n",
      " [13650     0     5]\n",
      " [13670     0     5]\n",
      " [13756     0     5]\n",
      " [13768     0     5]\n",
      " [13809     0     5]\n",
      " [13832     0     5]\n",
      " [13915     0     5]\n",
      " [13931     0     5]\n",
      " [14009     0     5]\n",
      " [14024     0     5]\n",
      " [14056     0     5]\n",
      " [14074     0     5]\n",
      " [14196     0     5]\n",
      " [14208     0     5]\n",
      " [14217     0     5]\n",
      " [14257     0     5]\n",
      " [14270     0     5]\n",
      " [14288     0     5]\n",
      " [14308     0     5]\n",
      " [14322     0     5]\n",
      " [14370     0     5]\n",
      " [14407     0     5]\n",
      " [14491     0     5]\n",
      " [14509     0     5]\n",
      " [14529     0     5]\n",
      " [14542     0     5]\n",
      " [14563     0     5]\n",
      " [14599     0     5]\n",
      " [14621     0     5]\n",
      " [14635     0     5]\n",
      " [14656     0     5]\n",
      " [14682     0     5]\n",
      " [14795     0     5]\n",
      " [14815     0     5]\n",
      " [14837     0     5]\n",
      " [14852     0     5]\n",
      " [14873     0     5]\n",
      " [14895     0     5]\n",
      " [14938     0     5]\n",
      " [14970     0     5]\n",
      " [14987     0     5]\n",
      " [15005     0     5]\n",
      " [15043     0     5]\n",
      " [15083     0     5]\n",
      " [15093     0     5]\n",
      " [15128     0     5]\n",
      " [15140     0     5]\n",
      " [15161     0     5]\n",
      " [15177     0     5]\n",
      " [15219     0     5]\n",
      " [15253     0     5]\n",
      " [15266     0     5]\n",
      " [15297     0     5]\n",
      " [15315     0     5]\n",
      " [15396     0     5]\n",
      " [15410     0     5]\n",
      " [15456     0     5]\n",
      " [15471     0     5]\n",
      " [15487     0     5]\n",
      " [15533     0     5]]\n",
      "<Epochs |  189 events (all good), -0.3 – 1.2 s, baseline off, ~12.5 MB, data loaded,\n",
      " '5': 189>\n",
      "tape_num= 6\n",
      "wOnset_perTape_DF=        Word  Segment      onset\n",
      "942     Now        6   0.323245\n",
      "943   Dinah        6   0.568709\n",
      "944    tell        6   1.039809\n",
      "945      me        6   1.422938\n",
      "946     the        6   1.590557\n",
      "...     ...      ...        ...\n",
      "1134   ever        6  61.825659\n",
      "1135     to        6  62.101034\n",
      "1136    get        6  62.268653\n",
      "1137    out        6  62.436272\n",
      "1138  again        6  62.663755\n",
      "\n",
      "[197 rows x 3 columns]\n",
      "wOnset_datapoints_ndarray= [ 32.3245298  56.8708743 103.9808743 142.2937743 159.0556743 173.0401743\n",
      " 238.0761743 260.0501743 284.7699743 320.6883743 337.9041743 353.4880743\n",
      " 473.9400743 496.7131743 597.2597743] <class 'numpy.ndarray'>\n",
      "tape_start_datapoints_npINT64= 15103\n",
      "abs_wOnsets_dta_ndarray= [15135.3245298 15159.8708743 15206.9808743 15245.2937743 15262.0556743\n",
      " 15276.0401743 15341.0761743 15363.0501743 15387.7699743 15423.6883743\n",
      " 15440.9041743 15456.4880743 15576.9400743 15599.7131743 15700.2597743]\n",
      "rounded_abs_wOnsets_dta_ndarray= [15135 15159 15206 15245 15262 15276 15341 15363 15387 15423 15440 15456\n",
      " 15576 15599 15700]\n",
      "[[15135     0     6]\n",
      " [15159     0     6]\n",
      " [15206     0     6]\n",
      " [15245     0     6]\n",
      " [15262     0     6]\n",
      " [15276     0     6]\n",
      " [15341     0     6]\n",
      " [15363     0     6]\n",
      " [15387     0     6]\n",
      " [15423     0     6]\n",
      " [15440     0     6]\n",
      " [15456     0     6]\n",
      " [15576     0     6]\n",
      " [15599     0     6]\n",
      " [15700     0     6]\n",
      " [15776     0     6]\n",
      " [15825     0     6]\n",
      " [15855     0     6]\n",
      " [15878     0     6]\n",
      " [15924     0     6]\n",
      " [15959     0     6]\n",
      " [15968     0     6]\n",
      " [15994     0     6]\n",
      " [16004     0     6]\n",
      " [16049     0     6]\n",
      " [16064     0     6]\n",
      " [16086     0     6]\n",
      " [16193     0     6]\n",
      " [16210     0     6]\n",
      " [16217     0     6]\n",
      " [16251     0     6]\n",
      " [16270     0     6]\n",
      " [16431     0     6]\n",
      " [16471     0     6]\n",
      " [16488     0     6]\n",
      " [16508     0     6]\n",
      " [16516     0     6]\n",
      " [16538     0     6]\n",
      " [16607     0     6]\n",
      " [16623     0     6]\n",
      " [16640     0     6]\n",
      " [16676     0     6]\n",
      " [16696     0     6]\n",
      " [16710     0     6]\n",
      " [16725     0     6]\n",
      " [16758     0     6]\n",
      " [16772     0     6]\n",
      " [16777     0     6]\n",
      " [16908     0     6]\n",
      " [16929     0     6]\n",
      " [16958     0     6]\n",
      " [16990     0     6]\n",
      " [17004     0     6]\n",
      " [17011     0     6]\n",
      " [17025     0     6]\n",
      " [17051     0     6]\n",
      " [17091     0     6]\n",
      " [17198     0     6]\n",
      " [17247     0     6]\n",
      " [17261     0     6]\n",
      " [17286     0     6]\n",
      " [17321     0     6]\n",
      " [17348     0     6]\n",
      " [17444     0     6]\n",
      " [17457     0     6]\n",
      " [17465     0     6]\n",
      " [17493     0     6]\n",
      " [17527     0     6]\n",
      " [17540     0     6]\n",
      " [17577     0     6]\n",
      " [17589     0     6]\n",
      " [17629     0     6]\n",
      " [17682     0     6]\n",
      " [17712     0     6]\n",
      " [17824     0     6]\n",
      " [17839     0     6]\n",
      " [17856     0     6]\n",
      " [17876     0     6]\n",
      " [17882     0     6]\n",
      " [17923     0     6]\n",
      " [17931     0     6]\n",
      " [17943     0     6]\n",
      " [18030     0     6]\n",
      " [18061     0     6]\n",
      " [18084     0     6]\n",
      " [18125     0     6]\n",
      " [18142     0     6]\n",
      " [18153     0     6]\n",
      " [18203     0     6]\n",
      " [18221     0     6]\n",
      " [18248     0     6]\n",
      " [18284     0     6]\n",
      " [18295     0     6]\n",
      " [18322     0     6]\n",
      " [18333     0     6]\n",
      " [18355     0     6]\n",
      " [18370     0     6]\n",
      " [18409     0     6]\n",
      " [18425     0     6]\n",
      " [18437     0     6]\n",
      " [18465     0     6]\n",
      " [18473     0     6]\n",
      " [18566     0     6]\n",
      " [18591     0     6]\n",
      " [18608     0     6]\n",
      " [18636     0     6]\n",
      " [18650     0     6]\n",
      " [18711     0     6]\n",
      " [18724     0     6]\n",
      " [18750     0     6]\n",
      " [18762     0     6]\n",
      " [18775     0     6]\n",
      " [18868     0     6]\n",
      " [18888     0     6]\n",
      " [18905     0     6]\n",
      " [18938     0     6]\n",
      " [18980     0     6]\n",
      " [18993     0     6]\n",
      " [19005     0     6]\n",
      " [19025     0     6]\n",
      " [19055     0     6]\n",
      " [19062     0     6]\n",
      " [19138     0     6]\n",
      " [19153     0     6]\n",
      " [19163     0     6]\n",
      " [19201     0     6]\n",
      " [19223     0     6]\n",
      " [19246     0     6]\n",
      " [19278     0     6]\n",
      " [19295     0     6]\n",
      " [19309     0     6]\n",
      " [19404     0     6]\n",
      " [19428     0     6]\n",
      " [19458     0     6]\n",
      " [19508     0     6]\n",
      " [19520     0     6]\n",
      " [19526     0     6]\n",
      " [19575     0     6]\n",
      " [19616     0     6]\n",
      " [19658     0     6]\n",
      " [19690     0     6]\n",
      " [19709     0     6]\n",
      " [19733     0     6]\n",
      " [19772     0     6]\n",
      " [19791     0     6]\n",
      " [19802     0     6]\n",
      " [19829     0     6]\n",
      " [19839     0     6]\n",
      " [19882     0     6]\n",
      " [19912     0     6]\n",
      " [19933     0     6]\n",
      " [19947     0     6]\n",
      " [20064     0     6]\n",
      " [20082     0     6]\n",
      " [20094     0     6]\n",
      " [20143     0     6]\n",
      " [20161     0     6]\n",
      " [20194     0     6]\n",
      " [20202     0     6]\n",
      " [20291     0     6]\n",
      " [20308     0     6]\n",
      " [20326     0     6]\n",
      " [20341     0     6]\n",
      " [20364     0     6]\n",
      " [20454     0     6]\n",
      " [20467     0     6]\n",
      " [20488     0     6]\n",
      " [20524     0     6]\n",
      " [20533     0     6]\n",
      " [20549     0     6]\n",
      " [20574     0     6]\n",
      " [20582     0     6]\n",
      " [20598     0     6]\n",
      " [20627     0     6]\n",
      " [20649     0     6]\n",
      " [20689     0     6]\n",
      " [20697     0     6]\n",
      " [20720     0     6]\n",
      " [20735     0     6]\n",
      " [20764     0     6]\n",
      " [20807     0     6]\n",
      " [20843     0     6]\n",
      " [20937     0     6]\n",
      " [20957     0     6]\n",
      " [20988     0     6]\n",
      " [21044     0     6]\n",
      " [21073     0     6]\n",
      " [21080     0     6]\n",
      " [21167     0     6]\n",
      " [21222     0     6]\n",
      " [21241     0     6]\n",
      " [21259     0     6]\n",
      " [21285     0     6]\n",
      " [21313     0     6]\n",
      " [21329     0     6]\n",
      " [21346     0     6]\n",
      " [21369     0     6]]\n",
      "<Epochs |  194 events (all good), -0.3 – 1.2 s, baseline off, ~12.8 MB, data loaded,\n",
      " '6': 194>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/dt/yj00f34n5x52_p314tnwfjkw0000gn/T/ipykernel_30538/1641304678.py:107: RuntimeWarning: Concatenation of Annotations within Epochs is not supported yet. All annotations will be dropped.\n",
      "  wOnset_epochs = mne.concatenate_epochs(all_tapes_epochs_LIST)\n",
      "/var/folders/dt/yj00f34n5x52_p314tnwfjkw0000gn/T/ipykernel_30538/1641304678.py:107: RuntimeWarning: Concatenation of Annotations within Epochs is not supported yet. All annotations will be dropped.\n",
      "  wOnset_epochs = mne.concatenate_epochs(all_tapes_epochs_LIST)\n",
      "/var/folders/dt/yj00f34n5x52_p314tnwfjkw0000gn/T/ipykernel_30538/1641304678.py:107: RuntimeWarning: Concatenation of Annotations within Epochs is not supported yet. All annotations will be dropped.\n",
      "  wOnset_epochs = mne.concatenate_epochs(all_tapes_epochs_LIST)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tape_num= 7\n",
      "wOnset_perTape_DF=           Word  Segment      onset\n",
      "1139  Suddenly        7   0.586736\n",
      "1140       she        7   1.179532\n",
      "1141      came        7   1.418988\n",
      "1142      upon        7   1.694362\n",
      "1143         a        7   2.051148\n",
      "...        ...      ...        ...\n",
      "1312       her        7  61.175179\n",
      "1313      head        7  61.294906\n",
      "1314    though        7  61.675837\n",
      "1315       the        7  61.845655\n",
      "1316   doorway        7  61.965383\n",
      "\n",
      "[178 rows x 3 columns]\n",
      "wOnset_datapoints_ndarray= [ 58.6736359 117.9532195 141.8988195 169.4362195 205.1148195 230.4974195\n",
      " 274.7968195 299.9396195 337.0553195 425.6539195 446.0076195 471.1505195\n",
      " 479.5315195 527.4226195 650.7423195] <class 'numpy.ndarray'>\n",
      "tape_start_datapoints_npINT64= 15154\n",
      "abs_wOnsets_dta_ndarray= [15212.6736359 15271.9532195 15295.8988195 15323.4362195 15359.1148195\n",
      " 15384.4974195 15428.7968195 15453.9396195 15491.0553195 15579.6539195\n",
      " 15600.0076195 15625.1505195 15633.5315195 15681.4226195 15804.7423195]\n",
      "rounded_abs_wOnsets_dta_ndarray= [15212 15271 15295 15323 15359 15384 15428 15453 15491 15579 15600 15625\n",
      " 15633 15681 15804]\n",
      "[[15212     0     7]\n",
      " [15271     0     7]\n",
      " [15295     0     7]\n",
      " [15323     0     7]\n",
      " [15359     0     7]\n",
      " [15384     0     7]\n",
      " [15428     0     7]\n",
      " [15453     0     7]\n",
      " [15491     0     7]\n",
      " [15579     0     7]\n",
      " [15600     0     7]\n",
      " [15625     0     7]\n",
      " [15633     0     7]\n",
      " [15681     0     7]\n",
      " [15804     0     7]\n",
      " [15817     0     7]\n",
      " [15834     0     7]\n",
      " [15874     0     7]\n",
      " [15898     0     7]\n",
      " [15920     0     7]\n",
      " [15951     0     7]\n",
      " [15960     0     7]\n",
      " [16003     0     7]\n",
      " [16047     0     7]\n",
      " [16137     0     7]\n",
      " [16157     0     7]\n",
      " [16210     0     7]\n",
      " [16256     0     7]\n",
      " [16314     0     7]\n",
      " [16329     0     7]\n",
      " [16346     0     7]\n",
      " [16359     0     7]\n",
      " [16384     0     7]\n",
      " [16423     0     7]\n",
      " [16440     0     7]\n",
      " [16457     0     7]\n",
      " [16466     0     7]\n",
      " [16474     0     7]\n",
      " [16509     0     7]\n",
      " [16519     0     7]\n",
      " [16529     0     7]\n",
      " [16670     0     7]\n",
      " [16683     0     7]\n",
      " [16741     0     7]\n",
      " [16775     0     7]\n",
      " [16786     0     7]\n",
      " [16833     0     7]\n",
      " [16846     0     7]\n",
      " [16867     0     7]\n",
      " [16904     0     7]\n",
      " [16913     0     7]\n",
      " [16923     0     7]\n",
      " [16950     0     7]\n",
      " [16972     0     7]\n",
      " [16987     0     7]\n",
      " [17083     0     7]\n",
      " [17097     0     7]\n",
      " [17111     0     7]\n",
      " [17142     0     7]\n",
      " [17168     0     7]\n",
      " [17179     0     7]\n",
      " [17194     0     7]\n",
      " [17214     0     7]\n",
      " [17246     0     7]\n",
      " [17273     0     7]\n",
      " [17286     0     7]\n",
      " [17396     0     7]\n",
      " [17452     0     7]\n",
      " [17467     0     7]\n",
      " [17476     0     7]\n",
      " [17519     0     7]\n",
      " [17551     0     7]\n",
      " [17587     0     7]\n",
      " [17610     0     7]\n",
      " [17640     0     7]\n",
      " [17676     0     7]\n",
      " [17686     0     7]\n",
      " [17717     0     7]\n",
      " [17771     0     7]\n",
      " [17794     0     7]\n",
      " [17818     0     7]\n",
      " [17837     0     7]\n",
      " [17880     0     7]\n",
      " [17986     0     7]\n",
      " [18006     0     7]\n",
      " [18051     0     7]\n",
      " [18068     0     7]\n",
      " [18082     0     7]\n",
      " [18091     0     7]\n",
      " [18125     0     7]\n",
      " [18177     0     7]\n",
      " [18211     0     7]\n",
      " [18262     0     7]\n",
      " [18301     0     7]\n",
      " [18411     0     7]\n",
      " [18431     0     7]\n",
      " [18469     0     7]\n",
      " [18478     0     7]\n",
      " [18510     0     7]\n",
      " [18548     0     7]\n",
      " [18574     0     7]\n",
      " [18586     0     7]\n",
      " [18593     0     7]\n",
      " [18660     0     7]\n",
      " [18678     0     7]\n",
      " [18691     0     7]\n",
      " [18709     0     7]\n",
      " [18769     0     7]\n",
      " [18814     0     7]\n",
      " [18835     0     7]\n",
      " [19037     0     7]\n",
      " [19082     0     7]\n",
      " [19125     0     7]\n",
      " [19134     0     7]\n",
      " [19185     0     7]\n",
      " [19209     0     7]\n",
      " [19237     0     7]\n",
      " [19247     0     7]\n",
      " [19273     0     7]\n",
      " [19308     0     7]\n",
      " [19313     0     7]\n",
      " [19358     0     7]\n",
      " [19495     0     7]\n",
      " [19518     0     7]\n",
      " [19545     0     7]\n",
      " [19579     0     7]\n",
      " [19596     0     7]\n",
      " [19607     0     7]\n",
      " [19639     0     7]\n",
      " [19743     0     7]\n",
      " [19767     0     7]\n",
      " [19804     0     7]\n",
      " [19850     0     7]\n",
      " [19867     0     7]\n",
      " [19894     0     7]\n",
      " [19922     0     7]\n",
      " [19929     0     7]\n",
      " [20019     0     7]\n",
      " [20049     0     7]\n",
      " [20066     0     7]\n",
      " [20152     0     7]\n",
      " [20187     0     7]\n",
      " [20211     0     7]\n",
      " [20240     0     7]\n",
      " [20374     0     7]\n",
      " [20389     0     7]\n",
      " [20412     0     7]\n",
      " [20459     0     7]\n",
      " [20469     0     7]\n",
      " [20488     0     7]\n",
      " [20504     0     7]\n",
      " [20516     0     7]\n",
      " [20533     0     7]\n",
      " [20573     0     7]\n",
      " [20620     0     7]\n",
      " [20638     0     7]\n",
      " [20681     0     7]\n",
      " [20721     0     7]\n",
      " [20755     0     7]\n",
      " [20786     0     7]\n",
      " [20822     0     7]\n",
      " [20836     0     7]\n",
      " [20871     0     7]\n",
      " [20933     0     7]\n",
      " [20944     0     7]\n",
      " [20976     0     7]\n",
      " [21005     0     7]\n",
      " [21152     0     7]\n",
      " [21166     0     7]\n",
      " [21184     0     7]\n",
      " [21209     0     7]\n",
      " [21228     0     7]\n",
      " [21255     0     7]\n",
      " [21271     0     7]\n",
      " [21283     0     7]\n",
      " [21321     0     7]\n",
      " [21338     0     7]\n",
      " [21350     0     7]]\n",
      "<Epochs |  175 events (all good), -0.3 – 1.2 s, baseline off, ~11.6 MB, data loaded,\n",
      " '7': 175>\n",
      "tape_num= 8\n",
      "wOnset_perTape_DF=        Word  Segment      onset\n",
      "1317    and        8   0.342000\n",
      "1318   even        8   0.453317\n",
      "1319     if        8   0.696699\n",
      "1320     my        8   0.960100\n",
      "1321   head        8   1.067855\n",
      "...     ...      ...        ...\n",
      "1487     do        8  55.663774\n",
      "1488   that        8  55.855338\n",
      "1489     in        8  56.190576\n",
      "1490      a        8  56.366154\n",
      "1491  hurry        8  56.444074\n",
      "\n",
      "[175 rows x 3 columns]\n",
      "wOnset_datapoints_ndarray= [ 34.2        45.3316684  69.6698684  96.0099684 106.7854684 139.1120684\n",
      " 158.2684684 178.5899684 250.4589684 277.9963684 304.3431684 420.4725684\n",
      " 428.9338684 448.0099684 467.1664684] <class 'numpy.ndarray'>\n",
      "tape_start_datapoints_npINT64= 15174\n",
      "abs_wOnsets_dta_ndarray= [15208.2       15219.3316684 15243.6698684 15270.0099684 15280.7854684\n",
      " 15313.1120684 15332.2684684 15352.5899684 15424.4589684 15451.9963684\n",
      " 15478.3431684 15594.4725684 15602.9338684 15622.0099684 15641.1664684]\n",
      "rounded_abs_wOnsets_dta_ndarray= [15208 15219 15243 15270 15280 15313 15332 15352 15424 15451 15478 15594\n",
      " 15602 15622 15641]\n",
      "[[15208     0     8]\n",
      " [15219     0     8]\n",
      " [15243     0     8]\n",
      " [15270     0     8]\n",
      " [15280     0     8]\n",
      " [15313     0     8]\n",
      " [15332     0     8]\n",
      " [15352     0     8]\n",
      " [15424     0     8]\n",
      " [15451     0     8]\n",
      " [15478     0     8]\n",
      " [15594     0     8]\n",
      " [15602     0     8]\n",
      " [15622     0     8]\n",
      " [15641     0     8]\n",
      " [15657     0     8]\n",
      " [15701     0     8]\n",
      " [15736     0     8]\n",
      " [15766     0     8]\n",
      " [15798     0     8]\n",
      " [15805     0     8]\n",
      " [15928     0     8]\n",
      " [15941     0     8]\n",
      " [15959     0     8]\n",
      " [15970     0     8]\n",
      " [15999     0     8]\n",
      " [16007     0     8]\n",
      " [16022     0     8]\n",
      " [16052     0     8]\n",
      " [16069     0     8]\n",
      " [16082     0     8]\n",
      " [16087     0     8]\n",
      " [16227     0     8]\n",
      " [16238     0     8]\n",
      " [16270     0     8]\n",
      " [16284     0     8]\n",
      " [16348     0     8]\n",
      " [16368     0     8]\n",
      " [16383     0     8]\n",
      " [16414     0     8]\n",
      " [16431     0     8]\n",
      " [16449     0     8]\n",
      " [16464     0     8]\n",
      " [16614     0     8]\n",
      " [16631     0     8]\n",
      " [16644     0     8]\n",
      " [16703     0     8]\n",
      " [16734     0     8]\n",
      " [16767     0     8]\n",
      " [16783     0     8]\n",
      " [16797     0     8]\n",
      " [16807     0     8]\n",
      " [16832     0     8]\n",
      " [16865     0     8]\n",
      " [16877     0     8]\n",
      " [16928     0     8]\n",
      " [17010     0     8]\n",
      " [17023     0     8]\n",
      " [17064     0     8]\n",
      " [17077     0     8]\n",
      " [17115     0     8]\n",
      " [17122     0     8]\n",
      " [17150     0     8]\n",
      " [17166     0     8]\n",
      " [17198     0     8]\n",
      " [17229     0     8]\n",
      " [17267     0     8]\n",
      " [17318     0     8]\n",
      " [17332     0     8]\n",
      " [17371     0     8]\n",
      " [17552     0     8]\n",
      " [17574     0     8]\n",
      " [17614     0     8]\n",
      " [17621     0     8]\n",
      " [17638     0     8]\n",
      " [17654     0     8]\n",
      " [17693     0     8]\n",
      " [17707     0     8]\n",
      " [17741     0     8]\n",
      " [17760     0     8]\n",
      " [17772     0     8]\n",
      " [17801     0     8]\n",
      " [17878     0     8]\n",
      " [17890     0     8]\n",
      " [17908     0     8]\n",
      " [17933     0     8]\n",
      " [17961     0     8]\n",
      " [17971     0     8]\n",
      " [17981     0     8]\n",
      " [18065     0     8]\n",
      " [18089     0     8]\n",
      " [18126     0     8]\n",
      " [18144     0     8]\n",
      " [18171     0     8]\n",
      " [18197     0     8]\n",
      " [18234     0     8]\n",
      " [18261     0     8]\n",
      " [18281     0     8]\n",
      " [18330     0     8]\n",
      " [18350     0     8]\n",
      " [18358     0     8]\n",
      " [18388     0     8]\n",
      " [18420     0     8]\n",
      " [18429     0     8]\n",
      " [18453     0     8]\n",
      " [18469     0     8]\n",
      " [18511     0     8]\n",
      " [18520     0     8]\n",
      " [18562     0     8]\n",
      " [18598     0     8]\n",
      " [18616     0     8]\n",
      " [18636     0     8]\n",
      " [18824     0     8]\n",
      " [18852     0     8]\n",
      " [18892     0     8]\n",
      " [18912     0     8]\n",
      " [18943     0     8]\n",
      " [18956     0     8]\n",
      " [18994     0     8]\n",
      " [19037     0     8]\n",
      " [19058     0     8]\n",
      " [19163     0     8]\n",
      " [19179     0     8]\n",
      " [19241     0     8]\n",
      " [19263     0     8]\n",
      " [19312     0     8]\n",
      " [19338     0     8]\n",
      " [19422     0     8]\n",
      " [19443     0     8]\n",
      " [19539     0     8]\n",
      " [19552     0     8]\n",
      " [19576     0     8]\n",
      " [19583     0     8]\n",
      " [19611     0     8]\n",
      " [19624     0     8]\n",
      " [19634     0     8]\n",
      " [19672     0     8]\n",
      " [19688     0     8]\n",
      " [19693     0     8]\n",
      " [19735     0     8]\n",
      " [19795     0     8]\n",
      " [19811     0     8]\n",
      " [19820     0     8]\n",
      " [19883     0     8]\n",
      " [19921     0     8]\n",
      " [19987     0     8]\n",
      " [20055     0     8]\n",
      " [20093     0     8]\n",
      " [20115     0     8]\n",
      " [20124     0     8]\n",
      " [20142     0     8]\n",
      " [20183     0     8]\n",
      " [20279     0     8]\n",
      " [20299     0     8]\n",
      " [20316     0     8]\n",
      " [20345     0     8]\n",
      " [20381     0     8]\n",
      " [20406     0     8]\n",
      " [20412     0     8]\n",
      " [20441     0     8]\n",
      " [20481     0     8]\n",
      " [20518     0     8]\n",
      " [20532     0     8]\n",
      " [20542     0     8]\n",
      " [20594     0     8]\n",
      " [20618     0     8]\n",
      " [20664     0     8]\n",
      " [20680     0     8]\n",
      " [20703     0     8]\n",
      " [20728     0     8]\n",
      " [20740     0     8]\n",
      " [20759     0     8]\n",
      " [20793     0     8]\n",
      " [20810     0     8]\n",
      " [20818     0     8]]\n",
      "<Epochs |  172 events (all good), -0.3 – 1.2 s, baseline off, ~11.4 MB, data loaded,\n",
      " '8': 172>\n",
      "tape_num= 9\n",
      "wOnset_perTape_DF=           Word  Segment      onset\n",
      "1492        No        9   0.432017\n",
      "1493         I        9   1.046815\n",
      "1494        ll        9   1.198494\n",
      "1495      look        9   1.394026\n",
      "1496     first        9   1.753210\n",
      "...        ...      ...        ...\n",
      "1643      very        9  54.086271\n",
      "1644      soon        9  54.397564\n",
      "1645  finished        9  55.044094\n",
      "1646        it        9  55.423901\n",
      "1647       off        9  55.536451\n",
      "\n",
      "[156 rows x 3 columns]\n",
      "wOnset_datapoints_ndarray= [ 43.2017422 104.6814784 119.8493784 139.4025784 175.3209784 213.3840784\n",
      " 235.1848784 270.9578784 278.9662784 311.8107784 344.1372784 353.1518784\n",
      " 362.0964784 398.0148784 447.0263784] <class 'numpy.ndarray'>\n",
      "tape_start_datapoints_npINT64= 21575\n",
      "abs_wOnsets_dta_ndarray= [21618.2017422 21679.6814784 21694.8493784 21714.4025784 21750.3209784\n",
      " 21788.3840784 21810.1848784 21845.9578784 21853.9662784 21886.8107784\n",
      " 21919.1372784 21928.1518784 21937.0964784 21973.0148784 22022.0263784]\n",
      "rounded_abs_wOnsets_dta_ndarray= [21618 21679 21694 21714 21750 21788 21810 21845 21853 21886 21919 21928\n",
      " 21937 21973 22022]\n",
      "[[21618     0     9]\n",
      " [21679     0     9]\n",
      " [21694     0     9]\n",
      " [21714     0     9]\n",
      " [21750     0     9]\n",
      " [21788     0     9]\n",
      " [21810     0     9]\n",
      " [21845     0     9]\n",
      " [21853     0     9]\n",
      " [21886     0     9]\n",
      " [21919     0     9]\n",
      " [21928     0     9]\n",
      " [21937     0     9]\n",
      " [21973     0     9]\n",
      " [22022     0     9]\n",
      " [22034     0     9]\n",
      " [22123     0     9]\n",
      " [22133     0     9]\n",
      " [22155     0     9]\n",
      " [22174     0     9]\n",
      " [22196     0     9]\n",
      " [22249     0     9]\n",
      " [22281     0     9]\n",
      " [22305     0     9]\n",
      " [22370     0     9]\n",
      " [22401     0     9]\n",
      " [22446     0     9]\n",
      " [22456     0     9]\n",
      " [22462     0     9]\n",
      " [22507     0     9]\n",
      " [22590     0     9]\n",
      " [22607     0     9]\n",
      " [22636     0     9]\n",
      " [22657     0     9]\n",
      " [22675     0     9]\n",
      " [22716     0     9]\n",
      " [22770     0     9]\n",
      " [22778     0     9]\n",
      " [22805     0     9]\n",
      " [22864     0     9]\n",
      " [22945     0     9]\n",
      " [22967     0     9]\n",
      " [23006     0     9]\n",
      " [23023     0     9]\n",
      " [23066     0     9]\n",
      " [23088     0     9]\n",
      " [23133     0     9]\n",
      " [23142     0     9]\n",
      " [23202     0     9]\n",
      " [23245     0     9]\n",
      " [23260     0     9]\n",
      " [23294     0     9]\n",
      " [23305     0     9]\n",
      " [23340     0     9]\n",
      " [23412     0     9]\n",
      " [23445     0     9]\n",
      " [23527     0     9]\n",
      " [23540     0     9]\n",
      " [23548     0     9]\n",
      " [23577     0     9]\n",
      " [23614     0     9]\n",
      " [23652     0     9]\n",
      " [23676     0     9]\n",
      " [23717     0     9]\n",
      " [23735     0     9]\n",
      " [23750     0     9]\n",
      " [23767     0     9]\n",
      " [23793     0     9]\n",
      " [23808     0     9]\n",
      " [23829     0     9]\n",
      " [23898     0     9]\n",
      " [23917     0     9]\n",
      " [23930     0     9]\n",
      " [23942     0     9]\n",
      " [23954     0     9]\n",
      " [23982     0     9]\n",
      " [23996     0     9]\n",
      " [24033     0     9]\n",
      " [24082     0     9]\n",
      " [24124     0     9]\n",
      " [24144     0     9]\n",
      " [24149     0     9]\n",
      " [24187     0     9]\n",
      " [24198     0     9]\n",
      " [24243     0     9]\n",
      " [24362     0     9]\n",
      " [24373     0     9]\n",
      " [24391     0     9]\n",
      " [24403     0     9]\n",
      " [24439     0     9]\n",
      " [24500     0     9]\n",
      " [24520     0     9]\n",
      " [24535     0     9]\n",
      " [24549     0     9]\n",
      " [24589     0     9]\n",
      " [24621     0     9]\n",
      " [24635     0     9]\n",
      " [24641     0     9]\n",
      " [24680     0     9]\n",
      " [24719     0     9]\n",
      " [24809     0     9]\n",
      " [24819     0     9]\n",
      " [24827     0     9]\n",
      " [24872     0     9]\n",
      " [24911     0     9]\n",
      " [24924     0     9]\n",
      " [24979     0     9]\n",
      " [24996     0     9]\n",
      " [25012     0     9]\n",
      " [25053     0     9]\n",
      " [25063     0     9]\n",
      " [25258     0     9]\n",
      " [25302     0     9]\n",
      " [25328     0     9]\n",
      " [25361     0     9]\n",
      " [25380     0     9]\n",
      " [25415     0     9]\n",
      " [25451     0     9]\n",
      " [25526     0     9]\n",
      " [25546     0     9]\n",
      " [25591     0     9]\n",
      " [25627     0     9]\n",
      " [25637     0     9]\n",
      " [25682     0     9]\n",
      " [25740     0     9]\n",
      " [25758     0     9]\n",
      " [25803     0     9]\n",
      " [25823     0     9]\n",
      " [25867     0     9]\n",
      " [25952     0     9]\n",
      " [25967     0     9]\n",
      " [26006     0     9]\n",
      " [26024     0     9]\n",
      " [26080     0     9]\n",
      " [26087     0     9]\n",
      " [26116     0     9]\n",
      " [26134     0     9]\n",
      " [26174     0     9]\n",
      " [26227     0     9]\n",
      " [26244     0     9]\n",
      " [26297     0     9]\n",
      " [26396     0     9]\n",
      " [26472     0     9]\n",
      " [26570     0     9]\n",
      " [26610     0     9]\n",
      " [26659     0     9]\n",
      " [26715     0     9]\n",
      " [26732     0     9]\n",
      " [26758     0     9]\n",
      " [26795     0     9]\n",
      " [26958     0     9]\n",
      " [26983     0     9]\n",
      " [27014     0     9]\n",
      " [27079     0     9]\n",
      " [27117     0     9]\n",
      " [27128     0     9]]\n",
      "<Epochs |  153 events (all good), -0.3 – 1.2 s, baseline off, ~10.1 MB, data loaded,\n",
      " '9': 153>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/dt/yj00f34n5x52_p314tnwfjkw0000gn/T/ipykernel_30538/1641304678.py:107: RuntimeWarning: Concatenation of Annotations within Epochs is not supported yet. All annotations will be dropped.\n",
      "  wOnset_epochs = mne.concatenate_epochs(all_tapes_epochs_LIST)\n",
      "/var/folders/dt/yj00f34n5x52_p314tnwfjkw0000gn/T/ipykernel_30538/1641304678.py:107: RuntimeWarning: Concatenation of Annotations within Epochs is not supported yet. All annotations will be dropped.\n",
      "  wOnset_epochs = mne.concatenate_epochs(all_tapes_epochs_LIST)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tape_num= 10\n",
      "wOnset_perTape_DF=           Word  Segment      onset\n",
      "1648      What       10   1.051981\n",
      "1649         a       10   1.160767\n",
      "1650   curious       10   1.308375\n",
      "1651   feeling       10   2.146470\n",
      "1652      said       10   2.787119\n",
      "...        ...      ...        ...\n",
      "1830     could       10  59.244701\n",
      "1831       not       10  59.448239\n",
      "1832  possibly       10  59.855313\n",
      "1833     reach       10  60.430007\n",
      "1834        it       10  60.784961\n",
      "\n",
      "[187 rows x 3 columns]\n",
      "wOnset_datapoints_ndarray= [105.1980798 116.0767    130.8375    214.647     278.7119    306.9088\n",
      " 367.0205    381.0893    411.0007    419.3817    460.2269    478.0483\n",
      " 490.7454    500.4853    645.6674   ] <class 'numpy.ndarray'>\n",
      "tape_start_datapoints_npINT64= 21646\n",
      "abs_wOnsets_dta_ndarray= [21751.1980798 21762.0767    21776.8375    21860.647     21924.7119\n",
      " 21952.9088    22013.0205    22027.0893    22057.0007    22065.3817\n",
      " 22106.2269    22124.0483    22136.7454    22146.4853    22291.6674   ]\n",
      "rounded_abs_wOnsets_dta_ndarray= [21751 21762 21776 21860 21924 21952 22013 22027 22057 22065 22106 22124\n",
      " 22136 22146 22291]\n",
      "[[21751     0    10]\n",
      " [21762     0    10]\n",
      " [21776     0    10]\n",
      " [21860     0    10]\n",
      " [21924     0    10]\n",
      " [21952     0    10]\n",
      " [22013     0    10]\n",
      " [22027     0    10]\n",
      " [22057     0    10]\n",
      " [22065     0    10]\n",
      " [22106     0    10]\n",
      " [22124     0    10]\n",
      " [22136     0    10]\n",
      " [22146     0    10]\n",
      " [22291     0    10]\n",
      " [22307     0    10]\n",
      " [22335     0    10]\n",
      " [22346     0    10]\n",
      " [22370     0    10]\n",
      " [22470     0    10]\n",
      " [22485     0    10]\n",
      " [22503     0    10]\n",
      " [22531     0    10]\n",
      " [22553     0    10]\n",
      " [22581     0    10]\n",
      " [22619     0    10]\n",
      " [22683     0    10]\n",
      " [22698     0    10]\n",
      " [22708     0    10]\n",
      " [22750     0    10]\n",
      " [22785     0    10]\n",
      " [22804     0    10]\n",
      " [22814     0    10]\n",
      " [22831     0    10]\n",
      " [22862     0    10]\n",
      " [22879     0    10]\n",
      " [22897     0    10]\n",
      " [22920     0    10]\n",
      " [22942     0    10]\n",
      " [22959     0    10]\n",
      " [22982     0    10]\n",
      " [23023     0    10]\n",
      " [23035     0    10]\n",
      " [23074     0    10]\n",
      " [23097     0    10]\n",
      " [23105     0    10]\n",
      " [23139     0    10]\n",
      " [23183     0    10]\n",
      " [23213     0    10]\n",
      " [23235     0    10]\n",
      " [23267     0    10]\n",
      " [23424     0    10]\n",
      " [23462     0    10]\n",
      " [23497     0    10]\n",
      " [23518     0    10]\n",
      " [23553     0    10]\n",
      " [23582     0    10]\n",
      " [23585     0    10]\n",
      " [23613     0    10]\n",
      " [23693     0    10]\n",
      " [23705     0    10]\n",
      " [23724     0    10]\n",
      " [23739     0    10]\n",
      " [23758     0    10]\n",
      " [23776     0    10]\n",
      " [23802     0    10]\n",
      " [23809     0    10]\n",
      " [23843     0    10]\n",
      " [23866     0    10]\n",
      " [23964     0    10]\n",
      " [23983     0    10]\n",
      " [24015     0    10]\n",
      " [24022     0    10]\n",
      " [24052     0    10]\n",
      " [24094     0    10]\n",
      " [24124     0    10]\n",
      " [24233     0    10]\n",
      " [24252     0    10]\n",
      " [24258     0    10]\n",
      " [24297     0    10]\n",
      " [24335     0    10]\n",
      " [24352     0    10]\n",
      " [24398     0    10]\n",
      " [24421     0    10]\n",
      " [24458     0    10]\n",
      " [24470     0    10]\n",
      " [24562     0    10]\n",
      " [24575     0    10]\n",
      " [24590     0    10]\n",
      " [24634     0    10]\n",
      " [24650     0    10]\n",
      " [24710     0    10]\n",
      " [24737     0    10]\n",
      " [24743     0    10]\n",
      " [24880     0    10]\n",
      " [24893     0    10]\n",
      " [24930     0    10]\n",
      " [24946     0    10]\n",
      " [24955     0    10]\n",
      " [24980     0    10]\n",
      " [24993     0    10]\n",
      " [25026     0    10]\n",
      " [25166     0    10]\n",
      " [25175     0    10]\n",
      " [25190     0    10]\n",
      " [25211     0    10]\n",
      " [25227     0    10]\n",
      " [25275     0    10]\n",
      " [25294     0    10]\n",
      " [25302     0    10]\n",
      " [25337     0    10]\n",
      " [25349     0    10]\n",
      " [25355     0    10]\n",
      " [25402     0    10]\n",
      " [25421     0    10]\n",
      " [25459     0    10]\n",
      " [25490     0    10]\n",
      " [25503     0    10]\n",
      " [25548     0    10]\n",
      " [25566     0    10]\n",
      " [25592     0    10]\n",
      " [25666     0    10]\n",
      " [25678     0    10]\n",
      " [25695     0    10]\n",
      " [25713     0    10]\n",
      " [25738     0    10]\n",
      " [25781     0    10]\n",
      " [25823     0    10]\n",
      " [25857     0    10]\n",
      " [25890     0    10]\n",
      " [25914     0    10]\n",
      " [25921     0    10]\n",
      " [26029     0    10]\n",
      " [26072     0    10]\n",
      " [26082     0    10]\n",
      " [26130     0    10]\n",
      " [26169     0    10]\n",
      " [26186     0    10]\n",
      " [26223     0    10]\n",
      " [26243     0    10]\n",
      " [26327     0    10]\n",
      " [26345     0    10]\n",
      " [26399     0    10]\n",
      " [26419     0    10]\n",
      " [26451     0    10]\n",
      " [26477     0    10]\n",
      " [26489     0    10]\n",
      " [26525     0    10]\n",
      " [26540     0    10]\n",
      " [26660     0    10]\n",
      " [26672     0    10]\n",
      " [26721     0    10]\n",
      " [26729     0    10]\n",
      " [26759     0    10]\n",
      " [26806     0    10]\n",
      " [26819     0    10]\n",
      " [26836     0    10]\n",
      " [26866     0    10]\n",
      " [26878     0    10]\n",
      " [26892     0    10]\n",
      " [26979     0    10]\n",
      " [26999     0    10]\n",
      " [27032     0    10]\n",
      " [27049     0    10]\n",
      " [27056     0    10]\n",
      " [27105     0    10]\n",
      " [27115     0    10]\n",
      " [27149     0    10]\n",
      " [27187     0    10]\n",
      " [27280     0    10]\n",
      " [27295     0    10]\n",
      " [27310     0    10]\n",
      " [27326     0    10]\n",
      " [27345     0    10]\n",
      " [27370     0    10]\n",
      " [27381     0    10]\n",
      " [27392     0    10]\n",
      " [27430     0    10]\n",
      " [27466     0    10]\n",
      " [27513     0    10]\n",
      " [27533     0    10]\n",
      " [27558     0    10]\n",
      " [27570     0    10]\n",
      " [27590     0    10]\n",
      " [27631     0    10]\n",
      " [27689     0    10]\n",
      " [27724     0    10]]\n",
      "<Epochs |  181 events (all good), -0.3 – 1.2 s, baseline off, ~12.0 MB, data loaded,\n",
      " '10': 181>\n",
      "tape_num= 11\n",
      "wOnset_perTape_DF=              Word  Segment      onset\n",
      "1835          she       11   0.274485\n",
      "1836        could       11   0.489783\n",
      "1837          see       11   0.701863\n",
      "1838           it       11   1.064477\n",
      "1839        quite       11   1.279987\n",
      "...           ...      ...        ...\n",
      "1987           to       11  53.797174\n",
      "1988         make       11  53.890245\n",
      "1989          one       11  54.211688\n",
      "1990  respectable       11  54.517325\n",
      "1991       person       11  55.331149\n",
      "\n",
      "[157 rows x 3 columns]\n",
      "wOnset_datapoints_ndarray= [ 27.448538   48.9783265  70.1863265 106.4477265 127.9987265 161.5225265\n",
      " 213.0055265 236.9511265 245.3320265 357.8762265 369.5823265 386.6109265\n",
      " 420.1347265 433.3048265 489.5769265] <class 'numpy.ndarray'>\n",
      "tape_start_datapoints_npINT64= 28647\n",
      "abs_wOnsets_dta_ndarray= [28674.448538  28695.9783265 28717.1863265 28753.4477265 28774.9987265\n",
      " 28808.5225265 28860.0055265 28883.9511265 28892.3320265 29004.8762265\n",
      " 29016.5823265 29033.6109265 29067.1347265 29080.3048265 29136.5769265]\n",
      "rounded_abs_wOnsets_dta_ndarray= [28674 28695 28717 28753 28774 28808 28860 28883 28892 29004 29016 29033\n",
      " 29067 29080 29136]\n",
      "[[28674     0    11]\n",
      " [28695     0    11]\n",
      " [28717     0    11]\n",
      " [28753     0    11]\n",
      " [28774     0    11]\n",
      " [28808     0    11]\n",
      " [28860     0    11]\n",
      " [28883     0    11]\n",
      " [28892     0    11]\n",
      " [29004     0    11]\n",
      " [29016     0    11]\n",
      " [29033     0    11]\n",
      " [29067     0    11]\n",
      " [29080     0    11]\n",
      " [29136     0    11]\n",
      " [29144     0    11]\n",
      " [29177     0    11]\n",
      " [29196     0    11]\n",
      " [29212     0    11]\n",
      " [29220     0    11]\n",
      " [29233     0    11]\n",
      " [29265     0    11]\n",
      " [29274     0    11]\n",
      " [29282     0    11]\n",
      " [29374     0    11]\n",
      " [29386     0    11]\n",
      " [29397     0    11]\n",
      " [29415     0    11]\n",
      " [29434     0    11]\n",
      " [29566     0    11]\n",
      " [29579     0    11]\n",
      " [29593     0    11]\n",
      " [29613     0    11]\n",
      " [29629     0    11]\n",
      " [29676     0    11]\n",
      " [29721     0    11]\n",
      " [29741     0    11]\n",
      " [29759     0    11]\n",
      " [29863     0    11]\n",
      " [29872     0    11]\n",
      " [29903     0    11]\n",
      " [29931     0    11]\n",
      " [29961     0    11]\n",
      " [29993     0    11]\n",
      " [30019     0    11]\n",
      " [30034     0    11]\n",
      " [30275     0    11]\n",
      " [30301     0    11]\n",
      " [30312     0    11]\n",
      " [30347     0    11]\n",
      " [30380     0    11]\n",
      " [30416     0    11]\n",
      " [30467     0    11]\n",
      " [30489     0    11]\n",
      " [30555     0    11]\n",
      " [30577     0    11]\n",
      " [30623     0    11]\n",
      " [30637     0    11]\n",
      " [30685     0    11]\n",
      " [30713     0    11]\n",
      " [30827     0    11]\n",
      " [30842     0    11]\n",
      " [30902     0    11]\n",
      " [30915     0    11]\n",
      " [30927     0    11]\n",
      " [30952     0    11]\n",
      " [30985     0    11]\n",
      " [31024     0    11]\n",
      " [31193     0    11]\n",
      " [31214     0    11]\n",
      " [31259     0    11]\n",
      " [31285     0    11]\n",
      " [31326     0    11]\n",
      " [31362     0    11]\n",
      " [31381     0    11]\n",
      " [31451     0    11]\n",
      " [31460     0    11]\n",
      " [31482     0    11]\n",
      " [31514     0    11]\n",
      " [31561     0    11]\n",
      " [31604     0    11]\n",
      " [31683     0    11]\n",
      " [31697     0    11]\n",
      " [31756     0    11]\n",
      " [31767     0    11]\n",
      " [31814     0    11]\n",
      " [31859     0    11]\n",
      " [31891     0    11]\n",
      " [31960     0    11]\n",
      " [31977     0    11]\n",
      " [31988     0    11]\n",
      " [32014     0    11]\n",
      " [32056     0    11]\n",
      " [32078     0    11]\n",
      " [32101     0    11]\n",
      " [32193     0    11]\n",
      " [32209     0    11]\n",
      " [32245     0    11]\n",
      " [32290     0    11]\n",
      " [32321     0    11]\n",
      " [32329     0    11]\n",
      " [32376     0    11]\n",
      " [32387     0    11]\n",
      " [32411     0    11]\n",
      " [32450     0    11]\n",
      " [32461     0    11]\n",
      " [32491     0    11]\n",
      " [32533     0    11]\n",
      " [32583     0    11]\n",
      " [32594     0    11]\n",
      " [32600     0    11]\n",
      " [32628     0    11]\n",
      " [32642     0    11]\n",
      " [32688     0    11]\n",
      " [32709     0    11]\n",
      " [32728     0    11]\n",
      " [32762     0    11]\n",
      " [32809     0    11]\n",
      " [32927     0    11]\n",
      " [32940     0    11]\n",
      " [32966     0    11]\n",
      " [33020     0    11]\n",
      " [33062     0    11]\n",
      " [33089     0    11]\n",
      " [33125     0    11]\n",
      " [33139     0    11]\n",
      " [33191     0    11]\n",
      " [33200     0    11]\n",
      " [33220     0    11]\n",
      " [33243     0    11]\n",
      " [33400     0    11]\n",
      " [33408     0    11]\n",
      " [33420     0    11]\n",
      " [33434     0    11]\n",
      " [33468     0    11]\n",
      " [33503     0    11]\n",
      " [33589     0    11]\n",
      " [33606     0    11]\n",
      " [33639     0    11]\n",
      " [33678     0    11]\n",
      " [33691     0    11]\n",
      " [33734     0    11]\n",
      " [33741     0    11]\n",
      " [33762     0    11]\n",
      " [33789     0    11]\n",
      " [33831     0    11]\n",
      " [33884     0    11]\n",
      " [33898     0    11]\n",
      " [33912     0    11]\n",
      " [33952     0    11]\n",
      " [33989     0    11]\n",
      " [34011     0    11]\n",
      " [34026     0    11]\n",
      " [34036     0    11]\n",
      " [34068     0    11]\n",
      " [34098     0    11]\n",
      " [34180     0    11]]\n",
      "<Epochs |  153 events (all good), -0.3 – 1.2 s, baseline off, ~10.1 MB, data loaded,\n",
      " '11': 153>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/dt/yj00f34n5x52_p314tnwfjkw0000gn/T/ipykernel_30538/1641304678.py:107: RuntimeWarning: Concatenation of Annotations within Epochs is not supported yet. All annotations will be dropped.\n",
      "  wOnset_epochs = mne.concatenate_epochs(all_tapes_epochs_LIST)\n",
      "/var/folders/dt/yj00f34n5x52_p314tnwfjkw0000gn/T/ipykernel_30538/1641304678.py:107: RuntimeWarning: Concatenation of Annotations within Epochs is not supported yet. All annotations will be dropped.\n",
      "  wOnset_epochs = mne.concatenate_epochs(all_tapes_epochs_LIST)\n",
      "/var/folders/dt/yj00f34n5x52_p314tnwfjkw0000gn/T/ipykernel_30538/1641304678.py:108: RuntimeWarning: This filename (/Users/neuroling/Downloads/DINGHSIN_Results/Alice_Experiments_Results/EEG_ESLs/Alice_ESLs_wOnset_raw_epochs/S030_ESLs_wOnset_epochs_11Tapes_raw.fif) does not conform to MNE naming conventions. All epochs files should end with -epo.fif, -epo.fif.gz, _epo.fif or _epo.fif.gz\n",
      "  wOnset_epochs.save(wOnset_DIR / Path('%s_ESLs_wOnset_epochs_11Tapes_raw.fif' %subject[4:8]), overwrite=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tape_num= 12\n",
      "wOnset_perTape_DF=          Word  Segment      onset\n",
      "1992     Soon       12   0.229476\n",
      "1993      her       12   0.504358\n",
      "1994      eye       12   0.658032\n",
      "1995     fell       12   0.974924\n",
      "1996       on       12   1.266236\n",
      "...       ...      ...        ...\n",
      "2124  happens       12  45.226353\n",
      "2125     when       12  45.677924\n",
      "2126      one       12  45.896829\n",
      "2127     eats       12  46.064448\n",
      "2128     cake       12  46.327849\n",
      "\n",
      "[137 rows x 3 columns]\n",
      "wOnset_datapoints_ndarray= [ 22.9476225  50.4358225  65.8032225  97.4924225 126.6236225 144.1863225\n",
      " 151.5146225 180.1046225 222.0094225 268.7033225 279.4788225 292.6489225\n",
      " 329.3501225 356.1046225 364.4856225] <class 'numpy.ndarray'>\n",
      "tape_start_datapoints_npINT64= 28718\n",
      "abs_wOnsets_dta_ndarray= [28740.9476225 28768.4358225 28783.8032225 28815.4924225 28844.6236225\n",
      " 28862.1863225 28869.5146225 28898.1046225 28940.0094225 28986.7033225\n",
      " 28997.4788225 29010.6489225 29047.3501225 29074.1046225 29082.4856225]\n",
      "rounded_abs_wOnsets_dta_ndarray= [28740 28768 28783 28815 28844 28862 28869 28898 28940 28986 28997 29010\n",
      " 29047 29074 29082]\n",
      "[[28740     0    12]\n",
      " [28768     0    12]\n",
      " [28783     0    12]\n",
      " [28815     0    12]\n",
      " [28844     0    12]\n",
      " [28862     0    12]\n",
      " [28869     0    12]\n",
      " [28898     0    12]\n",
      " [28940     0    12]\n",
      " [28986     0    12]\n",
      " [28997     0    12]\n",
      " [29010     0    12]\n",
      " [29047     0    12]\n",
      " [29074     0    12]\n",
      " [29082     0    12]\n",
      " [29187     0    12]\n",
      " [29210     0    12]\n",
      " [29248     0    12]\n",
      " [29306     0    12]\n",
      " [29331     0    12]\n",
      " [29364     0    12]\n",
      " [29378     0    12]\n",
      " [29393     0    12]\n",
      " [29402     0    12]\n",
      " [29439     0    12]\n",
      " [29482     0    12]\n",
      " [29579     0    12]\n",
      " [29591     0    12]\n",
      " [29618     0    12]\n",
      " [29629     0    12]\n",
      " [29686     0    12]\n",
      " [29717     0    12]\n",
      " [29794     0    12]\n",
      " [29820     0    12]\n",
      " [29876     0    12]\n",
      " [29911     0    12]\n",
      " [29924     0    12]\n",
      " [30121     0    12]\n",
      " [30203     0    12]\n",
      " [30215     0    12]\n",
      " [30230     0    12]\n",
      " [30254     0    12]\n",
      " [30302     0    12]\n",
      " [30327     0    12]\n",
      " [30369     0    12]\n",
      " [30380     0    12]\n",
      " [30397     0    12]\n",
      " [30410     0    12]\n",
      " [30436     0    12]\n",
      " [30453     0    12]\n",
      " [30476     0    12]\n",
      " [30524     0    12]\n",
      " [30535     0    12]\n",
      " [30554     0    12]\n",
      " [30583     0    12]\n",
      " [30594     0    12]\n",
      " [30684     0    12]\n",
      " [30697     0    12]\n",
      " [30710     0    12]\n",
      " [30723     0    12]\n",
      " [30749     0    12]\n",
      " [30763     0    12]\n",
      " [30781     0    12]\n",
      " [30879     0    12]\n",
      " [30893     0    12]\n",
      " [30914     0    12]\n",
      " [30945     0    12]\n",
      " [30968     0    12]\n",
      " [30978     0    12]\n",
      " [31066     0    12]\n",
      " [31087     0    12]\n",
      " [31119     0    12]\n",
      " [31141     0    12]\n",
      " [31147     0    12]\n",
      " [31153     0    12]\n",
      " [31170     0    12]\n",
      " [31195     0    12]\n",
      " [31205     0    12]\n",
      " [31278     0    12]\n",
      " [31291     0    12]\n",
      " [31306     0    12]\n",
      " [31322     0    12]\n",
      " [31345     0    12]\n",
      " [31370     0    12]\n",
      " [31527     0    12]\n",
      " [31554     0    12]\n",
      " [31580     0    12]\n",
      " [31591     0    12]\n",
      " [31641     0    12]\n",
      " [31747     0    12]\n",
      " [31756     0    12]\n",
      " [31777     0    12]\n",
      " [31838     0    12]\n",
      " [31853     0    12]\n",
      " [31977     0    12]\n",
      " [32006     0    12]\n",
      " [32108     0    12]\n",
      " [32138     0    12]\n",
      " [32259     0    12]\n",
      " [32289     0    12]\n",
      " [32299     0    12]\n",
      " [32334     0    12]\n",
      " [32346     0    12]\n",
      " [32353     0    12]\n",
      " [32382     0    12]\n",
      " [32389     0    12]\n",
      " [32403     0    12]\n",
      " [32432     0    12]\n",
      " [32446     0    12]\n",
      " [32480     0    12]\n",
      " [32502     0    12]\n",
      " [32522     0    12]\n",
      " [32537     0    12]\n",
      " [32554     0    12]\n",
      " [32670     0    12]\n",
      " [32680     0    12]\n",
      " [32697     0    12]\n",
      " [32715     0    12]\n",
      " [32740     0    12]\n",
      " [32814     0    12]\n",
      " [32821     0    12]\n",
      " [32852     0    12]\n",
      " [32863     0    12]\n",
      " [32882     0    12]\n",
      " [32923     0    12]\n",
      " [32930     0    12]\n",
      " [32962     0    12]\n",
      " [33089     0    12]\n",
      " [33105     0    12]\n",
      " [33117     0    12]\n",
      " [33152     0    12]\n",
      " [33183     0    12]\n",
      " [33240     0    12]\n",
      " [33285     0    12]\n",
      " [33307     0    12]\n",
      " [33324     0    12]\n",
      " [33350     0    12]]\n",
      "<Epochs |  137 events (all good), -0.3 – 1.2 s, baseline off, ~9.1 MB, data loaded,\n",
      " '12': 137>\n",
      "subject_num= n_2_ wOnset epoch saved.\n",
      "subject_num= n_2_S027_ICAed_raw.fif\n",
      "tape_num= 2\n",
      "wOnset_perTape_DF=          Word  Segment      onset\n",
      "174       but        2   0.479840\n",
      "175      when        2   0.592424\n",
      "176       the        2   0.810806\n",
      "177    Rabbit        2   0.912952\n",
      "178  actually        2   1.415810\n",
      "..        ...      ...        ...\n",
      "346       was        2  58.681660\n",
      "347     going        2  58.861252\n",
      "348        to        2  59.148599\n",
      "349    happen        2  59.251158\n",
      "350      next        2  59.687374\n",
      "\n",
      "[177 rows x 3 columns]\n",
      "wOnset_datapoints_ndarray= [ 47.9839572  59.2424402  81.0806402  91.2952402 141.5810402 191.8667402\n",
      " 238.5605402 255.7777402 321.1728402 343.1803402 359.5218402 379.0771402\n",
      " 438.4907402 563.7331402 574.7717402] <class 'numpy.ndarray'>\n",
      "tape_start_datapoints_npINT64= 3498\n",
      "abs_wOnsets_dta_ndarray= [3545.9839572 3557.2424402 3579.0806402 3589.2952402 3639.5810402\n",
      " 3689.8667402 3736.5605402 3753.7777402 3819.1728402 3841.1803402\n",
      " 3857.5218402 3877.0771402 3936.4907402 4061.7331402 4072.7717402]\n",
      "rounded_abs_wOnsets_dta_ndarray= [3545 3557 3579 3589 3639 3689 3736 3753 3819 3841 3857 3877 3936 4061\n",
      " 4072]\n",
      "[[3545    0    2]\n",
      " [3557    0    2]\n",
      " [3579    0    2]\n",
      " [3589    0    2]\n",
      " [3639    0    2]\n",
      " [3689    0    2]\n",
      " [3736    0    2]\n",
      " [3753    0    2]\n",
      " [3819    0    2]\n",
      " [3841    0    2]\n",
      " [3857    0    2]\n",
      " [3877    0    2]\n",
      " [3936    0    2]\n",
      " [4061    0    2]\n",
      " [4072    0    2]\n",
      " [4105    0    2]\n",
      " [4126    0    2]\n",
      " [4186    0    2]\n",
      " [4197    0    2]\n",
      " [4213    0    2]\n",
      " [4252    0    2]\n",
      " [4344    0    2]\n",
      " [4392    0    2]\n",
      " [4434    0    2]\n",
      " [4453    0    2]\n",
      " [4467    0    2]\n",
      " [4508    0    2]\n",
      " [4530    0    2]\n",
      " [4542    0    2]\n",
      " [4583    0    2]\n",
      " [4628    0    2]\n",
      " [4635    0    2]\n",
      " [4717    0    2]\n",
      " [4729    0    2]\n",
      " [4740    0    2]\n",
      " [4751    0    2]\n",
      " [4788    0    2]\n",
      " [4830    0    2]\n",
      " [4873    0    2]\n",
      " [4881    0    2]\n",
      " [4918    0    2]\n",
      " [4935    0    2]\n",
      " [4973    0    2]\n",
      " [4983    0    2]\n",
      " [5027    0    2]\n",
      " [5082    0    2]\n",
      " [5110    0    2]\n",
      " [5115    0    2]\n",
      " [5156    0    2]\n",
      " [5168    0    2]\n",
      " [5196    0    2]\n",
      " [5216    0    2]\n",
      " [5229    0    2]\n",
      " [5299    0    2]\n",
      " [5325    0    2]\n",
      " [5363    0    2]\n",
      " [5379    0    2]\n",
      " [5506    0    2]\n",
      " [5527    0    2]\n",
      " [5552    0    2]\n",
      " [5592    0    2]\n",
      " [5601    0    2]\n",
      " [5639    0    2]\n",
      " [5684    0    2]\n",
      " [5738    0    2]\n",
      " [5757    0    2]\n",
      " [5856    0    2]\n",
      " [5884    0    2]\n",
      " [5922    0    2]\n",
      " [5935    0    2]\n",
      " [5966    0    2]\n",
      " [5976    0    2]\n",
      " [5995    0    2]\n",
      " [6011    0    2]\n",
      " [6044    0    2]\n",
      " [6067    0    2]\n",
      " [6077    0    2]\n",
      " [6116    0    2]\n",
      " [6150    0    2]\n",
      " [6180    0    2]\n",
      " [6208    0    2]\n",
      " [6218    0    2]\n",
      " [6363    0    2]\n",
      " [6383    0    2]\n",
      " [6425    0    2]\n",
      " [6481    0    2]\n",
      " [6515    0    2]\n",
      " [6533    0    2]\n",
      " [6574    0    2]\n",
      " [6616    0    2]\n",
      " [6668    0    2]\n",
      " [6696    0    2]\n",
      " [6735    0    2]\n",
      " [6817    0    2]\n",
      " [6844    0    2]\n",
      " [6856    0    2]\n",
      " [6865    0    2]\n",
      " [6905    0    2]\n",
      " [6922    0    2]\n",
      " [6945    0    2]\n",
      " [6954    0    2]\n",
      " [6970    0    2]\n",
      " [6991    0    2]\n",
      " [7147    0    2]\n",
      " [7156    0    2]\n",
      " [7194    0    2]\n",
      " [7213    0    2]\n",
      " [7228    0    2]\n",
      " [7266    0    2]\n",
      " [7285    0    2]\n",
      " [7303    0    2]\n",
      " [7310    0    2]\n",
      " [7351    0    2]\n",
      " [7369    0    2]\n",
      " [7399    0    2]\n",
      " [7458    0    2]\n",
      " [7476    0    2]\n",
      " [7498    0    2]\n",
      " [7523    0    2]\n",
      " [7582    0    2]\n",
      " [7643    0    2]\n",
      " [7677    0    2]\n",
      " [7770    0    2]\n",
      " [7782    0    2]\n",
      " [7824    0    2]\n",
      " [7842    0    2]\n",
      " [7859    0    2]\n",
      " [7864    0    2]\n",
      " [7918    0    2]\n",
      " [7927    0    2]\n",
      " [7953    0    2]\n",
      " [7982    0    2]\n",
      " [8032    0    2]\n",
      " [8083    0    2]\n",
      " [8117    0    2]\n",
      " [8140    0    2]\n",
      " [8165    0    2]\n",
      " [8208    0    2]\n",
      " [8244    0    2]\n",
      " [8265    0    2]\n",
      " [8274    0    2]\n",
      " [8317    0    2]\n",
      " [8350    0    2]\n",
      " [8519    0    2]\n",
      " [8554    0    2]\n",
      " [8567    0    2]\n",
      " [8597    0    2]\n",
      " [8615    0    2]\n",
      " [8651    0    2]\n",
      " [8711    0    2]\n",
      " [8716    0    2]\n",
      " [8742    0    2]\n",
      " [8763    0    2]\n",
      " [8792    0    2]\n",
      " [8906    0    2]\n",
      " [8921    0    2]\n",
      " [8937    0    2]\n",
      " [8957    0    2]\n",
      " [9013    0    2]\n",
      " [9028    0    2]\n",
      " [9060    0    2]\n",
      " [9074    0    2]\n",
      " [9091    0    2]\n",
      " [9115    0    2]\n",
      " [9184    0    2]\n",
      " [9197    0    2]\n",
      " [9222    0    2]\n",
      " [9259    0    2]\n",
      " [9285    0    2]\n",
      " [9299    0    2]\n",
      " [9314    0    2]\n",
      " [9349    0    2]\n",
      " [9366    0    2]\n",
      " [9384    0    2]\n",
      " [9412    0    2]\n",
      " [9423    0    2]\n",
      " [9466    0    2]]\n",
      "<Epochs |  174 events (all good), -0.3 – 1.2 s, baseline off, ~11.5 MB, data loaded,\n",
      " '2': 174>\n",
      "tape_num= 3\n",
      "wOnset_perTape_DF=       Word  Segment      onset\n",
      "351  First        3   0.478723\n",
      "352    she        3   0.986270\n",
      "353  tried        3   1.201781\n",
      "354     to        3   1.501100\n",
      "355   look        3   1.604643\n",
      "..     ...      ...        ...\n",
      "530   this        3  61.269264\n",
      "531   time        3  61.591394\n",
      "532    she        3  62.071440\n",
      "533   said        3  62.263005\n",
      "534  aloud        3  62.538379\n",
      "\n",
      "[184 rows x 3 columns]\n",
      "wOnset_datapoints_ndarray= [ 47.8723402  98.6269787 120.1780787 150.1099787 160.4642787 183.6337787\n",
      " 218.3548787 231.5249787 260.2596787 284.2052787 296.1780787 314.3827787\n",
      " 333.2936787 371.6065787 450.6269787] <class 'numpy.ndarray'>\n",
      "tape_start_datapoints_npINT64= 9299\n",
      "abs_wOnsets_dta_ndarray= [9346.8723402 9397.6269787 9419.1780787 9449.1099787 9459.4642787\n",
      " 9482.6337787 9517.3548787 9530.5249787 9559.2596787 9583.2052787\n",
      " 9595.1780787 9613.3827787 9632.2936787 9670.6065787 9749.6269787]\n",
      "rounded_abs_wOnsets_dta_ndarray= [9346 9397 9419 9449 9459 9482 9517 9530 9559 9583 9595 9613 9632 9670\n",
      " 9749]\n",
      "[[ 9346     0     3]\n",
      " [ 9397     0     3]\n",
      " [ 9419     0     3]\n",
      " [ 9449     0     3]\n",
      " [ 9459     0     3]\n",
      " [ 9482     0     3]\n",
      " [ 9517     0     3]\n",
      " [ 9530     0     3]\n",
      " [ 9559     0     3]\n",
      " [ 9583     0     3]\n",
      " [ 9595     0     3]\n",
      " [ 9613     0     3]\n",
      " [ 9632     0     3]\n",
      " [ 9670     0     3]\n",
      " [ 9749     0     3]\n",
      " [ 9760     0     3]\n",
      " [ 9771     0     3]\n",
      " [ 9787     0     3]\n",
      " [ 9804     0     3]\n",
      " [ 9829     0     3]\n",
      " [ 9843     0     3]\n",
      " [ 9868     0     3]\n",
      " [10019     0     3]\n",
      " [10039     0     3]\n",
      " [10065     0     3]\n",
      " [10090     0     3]\n",
      " [10101     0     3]\n",
      " [10110     0     3]\n",
      " [10147     0     3]\n",
      " [10155     0     3]\n",
      " [10165     0     3]\n",
      " [10251     0     3]\n",
      " [10266     0     3]\n",
      " [10306     0     3]\n",
      " [10319     0     3]\n",
      " [10332     0     3]\n",
      " [10345     0     3]\n",
      " [10379     0     3]\n",
      " [10396     0     3]\n",
      " [10454     0     3]\n",
      " [10475     0     3]\n",
      " [10706     0     3]\n",
      " [10731     0     3]\n",
      " [10746     0     3]\n",
      " [10774     0     3]\n",
      " [10799     0     3]\n",
      " [10823     0     3]\n",
      " [10877     0     3]\n",
      " [10889     0     3]\n",
      " [10936     0     3]\n",
      " [10953     0     3]\n",
      " [10971     0     3]\n",
      " [10990     0     3]\n",
      " [11126     0     3]\n",
      " [11144     0     3]\n",
      " [11168     0     3]\n",
      " [11195     0     3]\n",
      " [11204     0     3]\n",
      " [11246     0     3]\n",
      " [11262     0     3]\n",
      " [11279     0     3]\n",
      " [11288     0     3]\n",
      " [11297     0     3]\n",
      " [11344     0     3]\n",
      " [11351     0     3]\n",
      " [11371     0     3]\n",
      " [11465     0     3]\n",
      " [11479     0     3]\n",
      " [11499     0     3]\n",
      " [11556     0     3]\n",
      " [11610     0     3]\n",
      " [11732     0     3]\n",
      " [11745     0     3]\n",
      " [11753     0     3]\n",
      " [11768     0     3]\n",
      " [11803     0     3]\n",
      " [11877     0     3]\n",
      " [11889     0     3]\n",
      " [11909     0     3]\n",
      " [12023     0     3]\n",
      " [12041     0     3]\n",
      " [12056     0     3]\n",
      " [12075     0     3]\n",
      " [12092     0     3]\n",
      " [12102     0     3]\n",
      " [12134     0     3]\n",
      " [12144     0     3]\n",
      " [12169     0     3]\n",
      " [12186     0     3]\n",
      " [12216     0     3]\n",
      " [12223     0     3]\n",
      " [12260     0     3]\n",
      " [12340     0     3]\n",
      " [12356     0     3]\n",
      " [12374     0     3]\n",
      " [12419     0     3]\n",
      " [12427     0     3]\n",
      " [12447     0     3]\n",
      " [12459     0     3]\n",
      " [12493     0     3]\n",
      " [12510     0     3]\n",
      " [12520     0     3]\n",
      " [12529     0     3]\n",
      " [12579     0     3]\n",
      " [12588     0     3]\n",
      " [12608     0     3]\n",
      " [12630     0     3]\n",
      " [12673     0     3]\n",
      " [12873     0     3]\n",
      " [12952     0     3]\n",
      " [12968     0     3]\n",
      " [13011     0     3]\n",
      " [13024     0     3]\n",
      " [13090     0     3]\n",
      " [13124     0     3]\n",
      " [13151     0     3]\n",
      " [13157     0     3]\n",
      " [13184     0     3]\n",
      " [13204     0     3]\n",
      " [13233     0     3]\n",
      " [13239     0     3]\n",
      " [13260     0     3]\n",
      " [13287     0     3]\n",
      " [13346     0     3]\n",
      " [13354     0     3]\n",
      " [13401     0     3]\n",
      " [13426     0     3]\n",
      " [13566     0     3]\n",
      " [13599     0     3]\n",
      " [13651     0     3]\n",
      " [13665     0     3]\n",
      " [13675     0     3]\n",
      " [13694     0     3]\n",
      " [13724     0     3]\n",
      " [13736     0     3]\n",
      " [13750     0     3]\n",
      " [13841     0     3]\n",
      " [13871     0     3]\n",
      " [13880     0     3]\n",
      " [13899     0     3]\n",
      " [13910     0     3]\n",
      " [13931     0     3]\n",
      " [13980     0     3]\n",
      " [14009     0     3]\n",
      " [14023     0     3]\n",
      " [14051     0     3]\n",
      " [14067     0     3]\n",
      " [14081     0     3]\n",
      " [14106     0     3]\n",
      " [14124     0     3]\n",
      " [14135     0     3]\n",
      " [14165     0     3]\n",
      " [14173     0     3]\n",
      " [14185     0     3]\n",
      " [14300     0     3]\n",
      " [14323     0     3]\n",
      " [14341     0     3]\n",
      " [14367     0     3]\n",
      " [14407     0     3]\n",
      " [14574     0     3]\n",
      " [14675     0     3]\n",
      " [14788     0     3]\n",
      " [14897     0     3]\n",
      " [14907     0     3]\n",
      " [14914     0     3]\n",
      " [14942     0     3]\n",
      " [14999     0     3]\n",
      " [15027     0     3]\n",
      " [15044     0     3]\n",
      " [15058     0     3]\n",
      " [15180     0     3]\n",
      " [15198     0     3]\n",
      " [15241     0     3]\n",
      " [15270     0     3]\n",
      " [15293     0     3]\n",
      " [15344     0     3]\n",
      " [15355     0     3]\n",
      " [15363     0     3]\n",
      " [15404     0     3]\n",
      " [15425     0     3]\n",
      " [15458     0     3]\n",
      " [15506     0     3]\n",
      " [15525     0     3]\n",
      " [15552     0     3]]\n",
      "<Epochs |  178 events (all good), -0.3 – 1.2 s, baseline off, ~11.8 MB, data loaded,\n",
      " '3': 178>\n",
      "tape_num= 4\n",
      "wOnset_perTape_DF=           Word  Segment      onset\n",
      "535       must        4   0.398386\n",
      "536         be        4   0.689428\n",
      "537    getting        4   0.840938\n",
      "538  somewhere        4   1.126350\n",
      "539       near        4   1.542892\n",
      "..         ...      ...        ...\n",
      "744      think        4  68.262788\n",
      "745        you        4  68.437370\n",
      "746      could        4  68.593016\n",
      "747     manage        4  68.760635\n",
      "748         it        4  69.129919\n",
      "\n",
      "[214 rows x 3 columns]\n",
      "wOnset_datapoints_ndarray= [ 39.8385787  68.9427631  84.0937631 112.6349631 154.2891631 177.2879631\n",
      " 184.4716631 225.1791631 234.7573631 248.5197631 312.5805631 335.3288631\n",
      " 347.3015631 380.8254631 399.0834631] <class 'numpy.ndarray'>\n",
      "tape_start_datapoints_npINT64= 9350\n",
      "abs_wOnsets_dta_ndarray= [9389.8385787 9418.9427631 9434.0937631 9462.6349631 9504.2891631\n",
      " 9527.2879631 9534.4716631 9575.1791631 9584.7573631 9598.5197631\n",
      " 9662.5805631 9685.3288631 9697.3015631 9730.8254631 9749.0834631]\n",
      "rounded_abs_wOnsets_dta_ndarray= [9389 9418 9434 9462 9504 9527 9534 9575 9584 9598 9662 9685 9697 9730\n",
      " 9749]\n",
      "[[ 9389     0     4]\n",
      " [ 9418     0     4]\n",
      " [ 9434     0     4]\n",
      " [ 9462     0     4]\n",
      " [ 9504     0     4]\n",
      " [ 9527     0     4]\n",
      " [ 9534     0     4]\n",
      " [ 9575     0     4]\n",
      " [ 9584     0     4]\n",
      " [ 9598     0     4]\n",
      " [ 9662     0     4]\n",
      " [ 9685     0     4]\n",
      " [ 9697     0     4]\n",
      " [ 9730     0     4]\n",
      " [ 9749     0     4]\n",
      " [ 9765     0     4]\n",
      " [ 9813     0     4]\n",
      " [ 9857     0     4]\n",
      " [ 9896     0     4]\n",
      " [ 9940     0     4]\n",
      " [ 9976     0     4]\n",
      " [ 9984     0     4]\n",
      " [10067     0     4]\n",
      " [10075     0     4]\n",
      " [10088     0     4]\n",
      " [10119     0     4]\n",
      " [10159     0     4]\n",
      " [10175     0     4]\n",
      " [10196     0     4]\n",
      " [10236     0     4]\n",
      " [10271     0     4]\n",
      " [10283     0     4]\n",
      " [10306     0     4]\n",
      " [10329     0     4]\n",
      " [10342     0     4]\n",
      " [10358     0     4]\n",
      " [10401     0     4]\n",
      " [10410     0     4]\n",
      " [10422     0     4]\n",
      " [10461     0     4]\n",
      " [10524     0     4]\n",
      " [10545     0     4]\n",
      " [10556     0     4]\n",
      " [10578     0     4]\n",
      " [10594     0     4]\n",
      " [10614     0     4]\n",
      " [10625     0     4]\n",
      " [10674     0     4]\n",
      " [10697     0     4]\n",
      " [10773     0     4]\n",
      " [10791     0     4]\n",
      " [10835     0     4]\n",
      " [10861     0     4]\n",
      " [10869     0     4]\n",
      " [10925     0     4]\n",
      " [10943     0     4]\n",
      " [10959     0     4]\n",
      " [10977     0     4]\n",
      " [10993     0     4]\n",
      " [11008     0     4]\n",
      " [11027     0     4]\n",
      " [11058     0     4]\n",
      " [11078     0     4]\n",
      " [11150     0     4]\n",
      " [11181     0     4]\n",
      " [11192     0     4]\n",
      " [11211     0     4]\n",
      " [11229     0     4]\n",
      " [11281     0     4]\n",
      " [11288     0     4]\n",
      " [11317     0     4]\n",
      " [11328     0     4]\n",
      " [11413     0     4]\n",
      " [11462     0     4]\n",
      " [11486     0     4]\n",
      " [11493     0     4]\n",
      " [11521     0     4]\n",
      " [11531     0     4]\n",
      " [11561     0     4]\n",
      " [11668     0     4]\n",
      " [11684     0     4]\n",
      " [11701     0     4]\n",
      " [11715     0     4]\n",
      " [11750     0     4]\n",
      " [11767     0     4]\n",
      " [11832     0     4]\n",
      " [11844     0     4]\n",
      " [11907     0     4]\n",
      " [11920     0     4]\n",
      " [11927     0     4]\n",
      " [11961     0     4]\n",
      " [12066     0     4]\n",
      " [12109     0     4]\n",
      " [12150     0     4]\n",
      " [12185     0     4]\n",
      " [12218     0     4]\n",
      " [12234     0     4]\n",
      " [12290     0     4]\n",
      " [12367     0     4]\n",
      " [12381     0     4]\n",
      " [12439     0     4]\n",
      " [12543     0     4]\n",
      " [12558     0     4]\n",
      " [12581     0     4]\n",
      " [12593     0     4]\n",
      " [12605     0     4]\n",
      " [12639     0     4]\n",
      " [12677     0     4]\n",
      " [12720     0     4]\n",
      " [12731     0     4]\n",
      " [12866     0     4]\n",
      " [12911     0     4]\n",
      " [12935     0     4]\n",
      " [12976     0     4]\n",
      " [13109     0     4]\n",
      " [13123     0     4]\n",
      " [13162     0     4]\n",
      " [13174     0     4]\n",
      " [13190     0     4]\n",
      " [13229     0     4]\n",
      " [13261     0     4]\n",
      " [13285     0     4]\n",
      " [13338     0     4]\n",
      " [13357     0     4]\n",
      " [13454     0     4]\n",
      " [13490     0     4]\n",
      " [13519     0     4]\n",
      " [13530     0     4]\n",
      " [13542     0     4]\n",
      " [13574     0     4]\n",
      " [13583     0     4]\n",
      " [13607     0     4]\n",
      " [13622     0     4]\n",
      " [13654     0     4]\n",
      " [13665     0     4]\n",
      " [13716     0     4]\n",
      " [13733     0     4]\n",
      " [13760     0     4]\n",
      " [13775     0     4]\n",
      " [13791     0     4]\n",
      " [13831     0     4]\n",
      " [13960     0     4]\n",
      " [13975     0     4]\n",
      " [14074     0     4]\n",
      " [14106     0     4]\n",
      " [14245     0     4]\n",
      " [14260     0     4]\n",
      " [14285     0     4]\n",
      " [14319     0     4]\n",
      " [14346     0     4]\n",
      " [14359     0     4]\n",
      " [14394     0     4]\n",
      " [14406     0     4]\n",
      " [14426     0     4]\n",
      " [14474     0     4]\n",
      " [14495     0     4]\n",
      " [14542     0     4]\n",
      " [14556     0     4]\n",
      " [14570     0     4]\n",
      " [14587     0     4]\n",
      " [14598     0     4]\n",
      " [14637     0     4]\n",
      " [14647     0     4]\n",
      " [14671     0     4]\n",
      " [14683     0     4]\n",
      " [14711     0     4]\n",
      " [14867     0     4]\n",
      " [14873     0     4]\n",
      " [14890     0     4]\n",
      " [14910     0     4]\n",
      " [14927     0     4]\n",
      " [14942     0     4]\n",
      " [14971     0     4]\n",
      " [14988     0     4]\n",
      " [15007     0     4]\n",
      " [15023     0     4]\n",
      " [15046     0     4]\n",
      " [15053     0     4]\n",
      " [15061     0     4]\n",
      " [15110     0     4]\n",
      " [15136     0     4]\n",
      " [15149     0     4]\n",
      " [15253     0     4]\n",
      " [15287     0     4]\n",
      " [15353     0     4]\n",
      " [15377     0     4]\n",
      " [15401     0     4]\n",
      " [15412     0     4]\n",
      " [15473     0     4]\n",
      " [15490     0     4]\n",
      " [15672     0     4]\n",
      " [15678     0     4]\n",
      " [15696     0     4]\n",
      " [15724     0     4]\n",
      " [15730     0     4]\n",
      " [15782     0     4]\n",
      " [15791     0     4]\n",
      " [15806     0     4]\n",
      " [15886     0     4]\n",
      " [15929     0     4]\n",
      " [16001     0     4]\n",
      " [16015     0     4]\n",
      " [16023     0     4]\n",
      " [16035     0     4]\n",
      " [16075     0     4]\n",
      " [16094     0     4]\n",
      " [16115     0     4]\n",
      " [16153     0     4]\n",
      " [16165     0     4]\n",
      " [16176     0     4]\n",
      " [16193     0     4]\n",
      " [16209     0     4]\n",
      " [16226     0     4]\n",
      " [16262     0     4]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/dt/yj00f34n5x52_p314tnwfjkw0000gn/T/ipykernel_30538/1641304678.py:107: RuntimeWarning: Concatenation of Annotations within Epochs is not supported yet. All annotations will be dropped.\n",
      "  wOnset_epochs = mne.concatenate_epochs(all_tapes_epochs_LIST)\n",
      "/var/folders/dt/yj00f34n5x52_p314tnwfjkw0000gn/T/ipykernel_30538/1641304678.py:107: RuntimeWarning: Concatenation of Annotations within Epochs is not supported yet. All annotations will be dropped.\n",
      "  wOnset_epochs = mne.concatenate_epochs(all_tapes_epochs_LIST)\n",
      "/var/folders/dt/yj00f34n5x52_p314tnwfjkw0000gn/T/ipykernel_30538/1641304678.py:107: RuntimeWarning: Concatenation of Annotations within Epochs is not supported yet. All annotations will be dropped.\n",
      "  wOnset_epochs = mne.concatenate_epochs(all_tapes_epochs_LIST)\n",
      "/var/folders/dt/yj00f34n5x52_p314tnwfjkw0000gn/T/ipykernel_30538/1641304678.py:107: RuntimeWarning: Concatenation of Annotations within Epochs is not supported yet. All annotations will be dropped.\n",
      "  wOnset_epochs = mne.concatenate_epochs(all_tapes_epochs_LIST)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Epochs |  208 events (all good), -0.3 – 1.2 s, baseline off, ~13.7 MB, data loaded,\n",
      " '4': 208>\n",
      "tape_num= 5\n",
      "wOnset_perTape_DF=           Word  Segment      onset\n",
      "749        And        5   0.561146\n",
      "750       what        5   0.689847\n",
      "751         an        5   0.936113\n",
      "752   ignorant        5   1.115705\n",
      "753     little        5   1.618562\n",
      "..         ...      ...        ...\n",
      "937     saying        5  64.085883\n",
      "938         to        5  64.547542\n",
      "939        her        5  64.691215\n",
      "940       very        5  64.858834\n",
      "941  earnestly        5  65.313800\n",
      "\n",
      "[193 rows x 3 columns]\n",
      "wOnset_datapoints_ndarray= [ 56.1145631  68.9847173  93.6113173 111.5705173 161.8562173 185.8018173\n",
      " 210.7547173 222.0976173 231.2984173 252.8494173 264.8222173 284.7481173\n",
      " 410.8902173 452.7950173 466.6011173] <class 'numpy.ndarray'>\n",
      "tape_start_datapoints_npINT64= 9370\n",
      "abs_wOnsets_dta_ndarray= [9426.1145631 9438.9847173 9463.6113173 9481.5705173 9531.8562173\n",
      " 9555.8018173 9580.7547173 9592.0976173 9601.2984173 9622.8494173\n",
      " 9634.8222173 9654.7481173 9780.8902173 9822.7950173 9836.6011173]\n",
      "rounded_abs_wOnsets_dta_ndarray= [9426 9438 9463 9481 9531 9555 9580 9592 9601 9622 9634 9654 9780 9822\n",
      " 9836]\n",
      "[[ 9426     0     5]\n",
      " [ 9438     0     5]\n",
      " [ 9463     0     5]\n",
      " [ 9481     0     5]\n",
      " [ 9531     0     5]\n",
      " [ 9555     0     5]\n",
      " [ 9580     0     5]\n",
      " [ 9592     0     5]\n",
      " [ 9601     0     5]\n",
      " [ 9622     0     5]\n",
      " [ 9634     0     5]\n",
      " [ 9654     0     5]\n",
      " [ 9780     0     5]\n",
      " [ 9822     0     5]\n",
      " [ 9836     0     5]\n",
      " [ 9850     0     5]\n",
      " [ 9882     0     5]\n",
      " [ 9896     0     5]\n",
      " [ 9907     0     5]\n",
      " [10008     0     5]\n",
      " [10053     0     5]\n",
      " [10061     0     5]\n",
      " [10081     0     5]\n",
      " [10100     0     5]\n",
      " [10113     0     5]\n",
      " [10140     0     5]\n",
      " [10157     0     5]\n",
      " [10336     0     5]\n",
      " [10396     0     5]\n",
      " [10451     0     5]\n",
      " [10568     0     5]\n",
      " [10585     0     5]\n",
      " [10602     0     5]\n",
      " [10641     0     5]\n",
      " [10671     0     5]\n",
      " [10683     0     5]\n",
      " [10715     0     5]\n",
      " [10736     0     5]\n",
      " [10778     0     5]\n",
      " [10802     0     5]\n",
      " [10834     0     5]\n",
      " [10889     0     5]\n",
      " [11049     0     5]\n",
      " [11082     0     5]\n",
      " [11101     0     5]\n",
      " [11134     0     5]\n",
      " [11150     0     5]\n",
      " [11188     0     5]\n",
      " [11226     0     5]\n",
      " [11262     0     5]\n",
      " [11270     0     5]\n",
      " [11301     0     5]\n",
      " [11460     0     5]\n",
      " [11495     0     5]\n",
      " [11518     0     5]\n",
      " [11529     0     5]\n",
      " [11682     0     5]\n",
      " [11692     0     5]\n",
      " [11715     0     5]\n",
      " [11726     0     5]\n",
      " [11734     0     5]\n",
      " [11774     0     5]\n",
      " [11785     0     5]\n",
      " [11831     0     5]\n",
      " [11843     0     5]\n",
      " [11877     0     5]\n",
      " [11888     0     5]\n",
      " [11918     0     5]\n",
      " [12046     0     5]\n",
      " [12079     0     5]\n",
      " [12096     0     5]\n",
      " [12121     0     5]\n",
      " [12129     0     5]\n",
      " [12162     0     5]\n",
      " [12173     0     5]\n",
      " [12183     0     5]\n",
      " [12217     0     5]\n",
      " [12236     0     5]\n",
      " [12271     0     5]\n",
      " [12359     0     5]\n",
      " [12376     0     5]\n",
      " [12380     0     5]\n",
      " [12404     0     5]\n",
      " [12443     0     5]\n",
      " [12452     0     5]\n",
      " [12467     0     5]\n",
      " [12490     0     5]\n",
      " [12496     0     5]\n",
      " [12504     0     5]\n",
      " [12545     0     5]\n",
      " [12566     0     5]\n",
      " [12576     0     5]\n",
      " [12603     0     5]\n",
      " [12628     0     5]\n",
      " [12635     0     5]\n",
      " [12744     0     5]\n",
      " [12754     0     5]\n",
      " [12770     0     5]\n",
      " [12780     0     5]\n",
      " [12807     0     5]\n",
      " [12839     0     5]\n",
      " [12844     0     5]\n",
      " [12886     0     5]\n",
      " [12895     0     5]\n",
      " [13005     0     5]\n",
      " [13021     0     5]\n",
      " [13032     0     5]\n",
      " [13085     0     5]\n",
      " [13110     0     5]\n",
      " [13149     0     5]\n",
      " [13156     0     5]\n",
      " [13321     0     5]\n",
      " [13341     0     5]\n",
      " [13366     0     5]\n",
      " [13413     0     5]\n",
      " [13452     0     5]\n",
      " [13464     0     5]\n",
      " [13485     0     5]\n",
      " [13510     0     5]\n",
      " [13608     0     5]\n",
      " [13625     0     5]\n",
      " [13651     0     5]\n",
      " [13670     0     5]\n",
      " [13712     0     5]\n",
      " [13728     0     5]\n",
      " [13783     0     5]\n",
      " [13791     0     5]\n",
      " [13797     0     5]\n",
      " [13834     0     5]\n",
      " [13861     0     5]\n",
      " [13879     0     5]\n",
      " [13961     0     5]\n",
      " [13976     0     5]\n",
      " [14018     0     5]\n",
      " [14038     0     5]\n",
      " [14124     0     5]\n",
      " [14136     0     5]\n",
      " [14177     0     5]\n",
      " [14200     0     5]\n",
      " [14283     0     5]\n",
      " [14299     0     5]\n",
      " [14377     0     5]\n",
      " [14392     0     5]\n",
      " [14424     0     5]\n",
      " [14442     0     5]\n",
      " [14564     0     5]\n",
      " [14576     0     5]\n",
      " [14585     0     5]\n",
      " [14625     0     5]\n",
      " [14638     0     5]\n",
      " [14656     0     5]\n",
      " [14676     0     5]\n",
      " [14690     0     5]\n",
      " [14738     0     5]\n",
      " [14775     0     5]\n",
      " [14859     0     5]\n",
      " [14877     0     5]\n",
      " [14897     0     5]\n",
      " [14910     0     5]\n",
      " [14931     0     5]\n",
      " [14967     0     5]\n",
      " [14989     0     5]\n",
      " [15003     0     5]\n",
      " [15024     0     5]\n",
      " [15050     0     5]\n",
      " [15163     0     5]\n",
      " [15183     0     5]\n",
      " [15205     0     5]\n",
      " [15220     0     5]\n",
      " [15241     0     5]\n",
      " [15263     0     5]\n",
      " [15306     0     5]\n",
      " [15338     0     5]\n",
      " [15355     0     5]\n",
      " [15373     0     5]\n",
      " [15411     0     5]\n",
      " [15451     0     5]\n",
      " [15461     0     5]\n",
      " [15496     0     5]\n",
      " [15508     0     5]\n",
      " [15529     0     5]\n",
      " [15545     0     5]\n",
      " [15587     0     5]\n",
      " [15621     0     5]\n",
      " [15634     0     5]\n",
      " [15665     0     5]\n",
      " [15683     0     5]\n",
      " [15764     0     5]\n",
      " [15778     0     5]\n",
      " [15824     0     5]\n",
      " [15839     0     5]\n",
      " [15855     0     5]\n",
      " [15901     0     5]]\n",
      "<Epochs |  187 events (all good), -0.3 – 1.2 s, baseline off, ~12.4 MB, data loaded,\n",
      " '5': 187>\n",
      "tape_num= 6\n",
      "wOnset_perTape_DF=        Word  Segment      onset\n",
      "942     Now        6   0.323245\n",
      "943   Dinah        6   0.568709\n",
      "944    tell        6   1.039809\n",
      "945      me        6   1.422938\n",
      "946     the        6   1.590557\n",
      "...     ...      ...        ...\n",
      "1134   ever        6  61.825659\n",
      "1135     to        6  62.101034\n",
      "1136    get        6  62.268653\n",
      "1137    out        6  62.436272\n",
      "1138  again        6  62.663755\n",
      "\n",
      "[197 rows x 3 columns]\n",
      "wOnset_datapoints_ndarray= [ 32.3245298  56.8708743 103.9808743 142.2937743 159.0556743 173.0401743\n",
      " 238.0761743 260.0501743 284.7699743 320.6883743 337.9041743 353.4880743\n",
      " 473.9400743 496.7131743 597.2597743] <class 'numpy.ndarray'>\n",
      "tape_start_datapoints_npINT64= 15471\n",
      "abs_wOnsets_dta_ndarray= [15503.3245298 15527.8708743 15574.9808743 15613.2937743 15630.0556743\n",
      " 15644.0401743 15709.0761743 15731.0501743 15755.7699743 15791.6883743\n",
      " 15808.9041743 15824.4880743 15944.9400743 15967.7131743 16068.2597743]\n",
      "rounded_abs_wOnsets_dta_ndarray= [15503 15527 15574 15613 15630 15644 15709 15731 15755 15791 15808 15824\n",
      " 15944 15967 16068]\n",
      "[[15503     0     6]\n",
      " [15527     0     6]\n",
      " [15574     0     6]\n",
      " [15613     0     6]\n",
      " [15630     0     6]\n",
      " [15644     0     6]\n",
      " [15709     0     6]\n",
      " [15731     0     6]\n",
      " [15755     0     6]\n",
      " [15791     0     6]\n",
      " [15808     0     6]\n",
      " [15824     0     6]\n",
      " [15944     0     6]\n",
      " [15967     0     6]\n",
      " [16068     0     6]\n",
      " [16144     0     6]\n",
      " [16193     0     6]\n",
      " [16223     0     6]\n",
      " [16246     0     6]\n",
      " [16292     0     6]\n",
      " [16327     0     6]\n",
      " [16336     0     6]\n",
      " [16362     0     6]\n",
      " [16372     0     6]\n",
      " [16417     0     6]\n",
      " [16432     0     6]\n",
      " [16454     0     6]\n",
      " [16561     0     6]\n",
      " [16578     0     6]\n",
      " [16585     0     6]\n",
      " [16619     0     6]\n",
      " [16638     0     6]\n",
      " [16799     0     6]\n",
      " [16839     0     6]\n",
      " [16856     0     6]\n",
      " [16876     0     6]\n",
      " [16884     0     6]\n",
      " [16906     0     6]\n",
      " [16975     0     6]\n",
      " [16991     0     6]\n",
      " [17008     0     6]\n",
      " [17044     0     6]\n",
      " [17064     0     6]\n",
      " [17078     0     6]\n",
      " [17093     0     6]\n",
      " [17126     0     6]\n",
      " [17140     0     6]\n",
      " [17145     0     6]\n",
      " [17276     0     6]\n",
      " [17297     0     6]\n",
      " [17326     0     6]\n",
      " [17358     0     6]\n",
      " [17372     0     6]\n",
      " [17379     0     6]\n",
      " [17393     0     6]\n",
      " [17419     0     6]\n",
      " [17459     0     6]\n",
      " [17566     0     6]\n",
      " [17615     0     6]\n",
      " [17629     0     6]\n",
      " [17654     0     6]\n",
      " [17689     0     6]\n",
      " [17716     0     6]\n",
      " [17812     0     6]\n",
      " [17825     0     6]\n",
      " [17833     0     6]\n",
      " [17861     0     6]\n",
      " [17895     0     6]\n",
      " [17908     0     6]\n",
      " [17945     0     6]\n",
      " [17957     0     6]\n",
      " [17997     0     6]\n",
      " [18050     0     6]\n",
      " [18080     0     6]\n",
      " [18192     0     6]\n",
      " [18207     0     6]\n",
      " [18224     0     6]\n",
      " [18244     0     6]\n",
      " [18250     0     6]\n",
      " [18291     0     6]\n",
      " [18299     0     6]\n",
      " [18311     0     6]\n",
      " [18398     0     6]\n",
      " [18429     0     6]\n",
      " [18452     0     6]\n",
      " [18493     0     6]\n",
      " [18510     0     6]\n",
      " [18521     0     6]\n",
      " [18571     0     6]\n",
      " [18589     0     6]\n",
      " [18616     0     6]\n",
      " [18652     0     6]\n",
      " [18663     0     6]\n",
      " [18690     0     6]\n",
      " [18701     0     6]\n",
      " [18723     0     6]\n",
      " [18738     0     6]\n",
      " [18777     0     6]\n",
      " [18793     0     6]\n",
      " [18805     0     6]\n",
      " [18833     0     6]\n",
      " [18841     0     6]\n",
      " [18934     0     6]\n",
      " [18959     0     6]\n",
      " [18976     0     6]\n",
      " [19004     0     6]\n",
      " [19018     0     6]\n",
      " [19079     0     6]\n",
      " [19092     0     6]\n",
      " [19118     0     6]\n",
      " [19130     0     6]\n",
      " [19143     0     6]\n",
      " [19236     0     6]\n",
      " [19256     0     6]\n",
      " [19273     0     6]\n",
      " [19306     0     6]\n",
      " [19348     0     6]\n",
      " [19361     0     6]\n",
      " [19373     0     6]\n",
      " [19393     0     6]\n",
      " [19423     0     6]\n",
      " [19430     0     6]\n",
      " [19506     0     6]\n",
      " [19521     0     6]\n",
      " [19531     0     6]\n",
      " [19569     0     6]\n",
      " [19591     0     6]\n",
      " [19614     0     6]\n",
      " [19646     0     6]\n",
      " [19663     0     6]\n",
      " [19677     0     6]\n",
      " [19772     0     6]\n",
      " [19796     0     6]\n",
      " [19826     0     6]\n",
      " [19876     0     6]\n",
      " [19888     0     6]\n",
      " [19894     0     6]\n",
      " [19943     0     6]\n",
      " [19984     0     6]\n",
      " [20026     0     6]\n",
      " [20058     0     6]\n",
      " [20077     0     6]\n",
      " [20101     0     6]\n",
      " [20140     0     6]\n",
      " [20159     0     6]\n",
      " [20170     0     6]\n",
      " [20197     0     6]\n",
      " [20207     0     6]\n",
      " [20250     0     6]\n",
      " [20280     0     6]\n",
      " [20301     0     6]\n",
      " [20315     0     6]\n",
      " [20432     0     6]\n",
      " [20450     0     6]\n",
      " [20462     0     6]\n",
      " [20511     0     6]\n",
      " [20529     0     6]\n",
      " [20562     0     6]\n",
      " [20570     0     6]\n",
      " [20659     0     6]\n",
      " [20676     0     6]\n",
      " [20694     0     6]\n",
      " [20709     0     6]\n",
      " [20732     0     6]\n",
      " [20822     0     6]\n",
      " [20835     0     6]\n",
      " [20856     0     6]\n",
      " [20892     0     6]\n",
      " [20901     0     6]\n",
      " [20917     0     6]\n",
      " [20942     0     6]\n",
      " [20950     0     6]\n",
      " [20966     0     6]\n",
      " [20995     0     6]\n",
      " [21017     0     6]\n",
      " [21057     0     6]\n",
      " [21065     0     6]\n",
      " [21088     0     6]\n",
      " [21103     0     6]\n",
      " [21132     0     6]\n",
      " [21175     0     6]\n",
      " [21211     0     6]\n",
      " [21305     0     6]\n",
      " [21325     0     6]\n",
      " [21356     0     6]\n",
      " [21412     0     6]\n",
      " [21441     0     6]\n",
      " [21448     0     6]\n",
      " [21535     0     6]\n",
      " [21590     0     6]\n",
      " [21609     0     6]\n",
      " [21627     0     6]\n",
      " [21653     0     6]\n",
      " [21681     0     6]\n",
      " [21697     0     6]\n",
      " [21714     0     6]\n",
      " [21737     0     6]]\n",
      "<Epochs |  190 events (all good), -0.3 – 1.2 s, baseline off, ~12.5 MB, data loaded,\n",
      " '6': 190>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/dt/yj00f34n5x52_p314tnwfjkw0000gn/T/ipykernel_30538/1641304678.py:107: RuntimeWarning: Concatenation of Annotations within Epochs is not supported yet. All annotations will be dropped.\n",
      "  wOnset_epochs = mne.concatenate_epochs(all_tapes_epochs_LIST)\n",
      "/var/folders/dt/yj00f34n5x52_p314tnwfjkw0000gn/T/ipykernel_30538/1641304678.py:107: RuntimeWarning: Concatenation of Annotations within Epochs is not supported yet. All annotations will be dropped.\n",
      "  wOnset_epochs = mne.concatenate_epochs(all_tapes_epochs_LIST)\n",
      "/var/folders/dt/yj00f34n5x52_p314tnwfjkw0000gn/T/ipykernel_30538/1641304678.py:107: RuntimeWarning: Concatenation of Annotations within Epochs is not supported yet. All annotations will be dropped.\n",
      "  wOnset_epochs = mne.concatenate_epochs(all_tapes_epochs_LIST)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tape_num= 7\n",
      "wOnset_perTape_DF=           Word  Segment      onset\n",
      "1139  Suddenly        7   0.586736\n",
      "1140       she        7   1.179532\n",
      "1141      came        7   1.418988\n",
      "1142      upon        7   1.694362\n",
      "1143         a        7   2.051148\n",
      "...        ...      ...        ...\n",
      "1312       her        7  61.175179\n",
      "1313      head        7  61.294906\n",
      "1314    though        7  61.675837\n",
      "1315       the        7  61.845655\n",
      "1316   doorway        7  61.965383\n",
      "\n",
      "[178 rows x 3 columns]\n",
      "wOnset_datapoints_ndarray= [ 58.6736359 117.9532195 141.8988195 169.4362195 205.1148195 230.4974195\n",
      " 274.7968195 299.9396195 337.0553195 425.6539195 446.0076195 471.1505195\n",
      " 479.5315195 527.4226195 650.7423195] <class 'numpy.ndarray'>\n",
      "tape_start_datapoints_npINT64= 15542\n",
      "abs_wOnsets_dta_ndarray= [15600.6736359 15659.9532195 15683.8988195 15711.4362195 15747.1148195\n",
      " 15772.4974195 15816.7968195 15841.9396195 15879.0553195 15967.6539195\n",
      " 15988.0076195 16013.1505195 16021.5315195 16069.4226195 16192.7423195]\n",
      "rounded_abs_wOnsets_dta_ndarray= [15600 15659 15683 15711 15747 15772 15816 15841 15879 15967 15988 16013\n",
      " 16021 16069 16192]\n",
      "[[15600     0     7]\n",
      " [15659     0     7]\n",
      " [15683     0     7]\n",
      " [15711     0     7]\n",
      " [15747     0     7]\n",
      " [15772     0     7]\n",
      " [15816     0     7]\n",
      " [15841     0     7]\n",
      " [15879     0     7]\n",
      " [15967     0     7]\n",
      " [15988     0     7]\n",
      " [16013     0     7]\n",
      " [16021     0     7]\n",
      " [16069     0     7]\n",
      " [16192     0     7]\n",
      " [16205     0     7]\n",
      " [16222     0     7]\n",
      " [16262     0     7]\n",
      " [16286     0     7]\n",
      " [16308     0     7]\n",
      " [16339     0     7]\n",
      " [16348     0     7]\n",
      " [16391     0     7]\n",
      " [16435     0     7]\n",
      " [16525     0     7]\n",
      " [16545     0     7]\n",
      " [16598     0     7]\n",
      " [16644     0     7]\n",
      " [16702     0     7]\n",
      " [16717     0     7]\n",
      " [16734     0     7]\n",
      " [16747     0     7]\n",
      " [16772     0     7]\n",
      " [16811     0     7]\n",
      " [16828     0     7]\n",
      " [16845     0     7]\n",
      " [16854     0     7]\n",
      " [16862     0     7]\n",
      " [16897     0     7]\n",
      " [16907     0     7]\n",
      " [16917     0     7]\n",
      " [17058     0     7]\n",
      " [17071     0     7]\n",
      " [17129     0     7]\n",
      " [17163     0     7]\n",
      " [17174     0     7]\n",
      " [17221     0     7]\n",
      " [17234     0     7]\n",
      " [17255     0     7]\n",
      " [17292     0     7]\n",
      " [17301     0     7]\n",
      " [17311     0     7]\n",
      " [17338     0     7]\n",
      " [17360     0     7]\n",
      " [17375     0     7]\n",
      " [17471     0     7]\n",
      " [17485     0     7]\n",
      " [17499     0     7]\n",
      " [17530     0     7]\n",
      " [17556     0     7]\n",
      " [17567     0     7]\n",
      " [17582     0     7]\n",
      " [17602     0     7]\n",
      " [17634     0     7]\n",
      " [17661     0     7]\n",
      " [17674     0     7]\n",
      " [17784     0     7]\n",
      " [17840     0     7]\n",
      " [17855     0     7]\n",
      " [17864     0     7]\n",
      " [17907     0     7]\n",
      " [17939     0     7]\n",
      " [17975     0     7]\n",
      " [17998     0     7]\n",
      " [18028     0     7]\n",
      " [18064     0     7]\n",
      " [18074     0     7]\n",
      " [18105     0     7]\n",
      " [18159     0     7]\n",
      " [18182     0     7]\n",
      " [18206     0     7]\n",
      " [18225     0     7]\n",
      " [18268     0     7]\n",
      " [18374     0     7]\n",
      " [18394     0     7]\n",
      " [18439     0     7]\n",
      " [18456     0     7]\n",
      " [18470     0     7]\n",
      " [18479     0     7]\n",
      " [18513     0     7]\n",
      " [18565     0     7]\n",
      " [18599     0     7]\n",
      " [18650     0     7]\n",
      " [18689     0     7]\n",
      " [18799     0     7]\n",
      " [18819     0     7]\n",
      " [18857     0     7]\n",
      " [18866     0     7]\n",
      " [18898     0     7]\n",
      " [18936     0     7]\n",
      " [18962     0     7]\n",
      " [18974     0     7]\n",
      " [18981     0     7]\n",
      " [19048     0     7]\n",
      " [19066     0     7]\n",
      " [19079     0     7]\n",
      " [19097     0     7]\n",
      " [19157     0     7]\n",
      " [19202     0     7]\n",
      " [19223     0     7]\n",
      " [19425     0     7]\n",
      " [19470     0     7]\n",
      " [19513     0     7]\n",
      " [19522     0     7]\n",
      " [19573     0     7]\n",
      " [19597     0     7]\n",
      " [19625     0     7]\n",
      " [19635     0     7]\n",
      " [19661     0     7]\n",
      " [19696     0     7]\n",
      " [19701     0     7]\n",
      " [19746     0     7]\n",
      " [19883     0     7]\n",
      " [19906     0     7]\n",
      " [19933     0     7]\n",
      " [19967     0     7]\n",
      " [19984     0     7]\n",
      " [19995     0     7]\n",
      " [20027     0     7]\n",
      " [20131     0     7]\n",
      " [20155     0     7]\n",
      " [20192     0     7]\n",
      " [20238     0     7]\n",
      " [20255     0     7]\n",
      " [20282     0     7]\n",
      " [20310     0     7]\n",
      " [20317     0     7]\n",
      " [20407     0     7]\n",
      " [20437     0     7]\n",
      " [20454     0     7]\n",
      " [20540     0     7]\n",
      " [20575     0     7]\n",
      " [20599     0     7]\n",
      " [20628     0     7]\n",
      " [20762     0     7]\n",
      " [20777     0     7]\n",
      " [20800     0     7]\n",
      " [20847     0     7]\n",
      " [20857     0     7]\n",
      " [20876     0     7]\n",
      " [20892     0     7]\n",
      " [20904     0     7]\n",
      " [20921     0     7]\n",
      " [20961     0     7]\n",
      " [21008     0     7]\n",
      " [21026     0     7]\n",
      " [21069     0     7]\n",
      " [21109     0     7]\n",
      " [21143     0     7]\n",
      " [21174     0     7]\n",
      " [21210     0     7]\n",
      " [21224     0     7]\n",
      " [21259     0     7]\n",
      " [21321     0     7]\n",
      " [21332     0     7]\n",
      " [21364     0     7]\n",
      " [21393     0     7]\n",
      " [21540     0     7]\n",
      " [21554     0     7]\n",
      " [21572     0     7]\n",
      " [21597     0     7]\n",
      " [21616     0     7]\n",
      " [21643     0     7]\n",
      " [21659     0     7]\n",
      " [21671     0     7]\n",
      " [21709     0     7]\n",
      " [21726     0     7]\n",
      " [21738     0     7]]\n",
      "<Epochs |  173 events (all good), -0.3 – 1.2 s, baseline off, ~11.4 MB, data loaded,\n",
      " '7': 173>\n",
      "tape_num= 8\n",
      "wOnset_perTape_DF=        Word  Segment      onset\n",
      "1317    and        8   0.342000\n",
      "1318   even        8   0.453317\n",
      "1319     if        8   0.696699\n",
      "1320     my        8   0.960100\n",
      "1321   head        8   1.067855\n",
      "...     ...      ...        ...\n",
      "1487     do        8  55.663774\n",
      "1488   that        8  55.855338\n",
      "1489     in        8  56.190576\n",
      "1490      a        8  56.366154\n",
      "1491  hurry        8  56.444074\n",
      "\n",
      "[175 rows x 3 columns]\n",
      "wOnset_datapoints_ndarray= [ 34.2        45.3316684  69.6698684  96.0099684 106.7854684 139.1120684\n",
      " 158.2684684 178.5899684 250.4589684 277.9963684 304.3431684 420.4725684\n",
      " 428.9338684 448.0099684 467.1664684] <class 'numpy.ndarray'>\n",
      "tape_start_datapoints_npINT64= 21943\n",
      "abs_wOnsets_dta_ndarray= [21977.2       21988.3316684 22012.6698684 22039.0099684 22049.7854684\n",
      " 22082.1120684 22101.2684684 22121.5899684 22193.4589684 22220.9963684\n",
      " 22247.3431684 22363.4725684 22371.9338684 22391.0099684 22410.1664684]\n",
      "rounded_abs_wOnsets_dta_ndarray= [21977 21988 22012 22039 22049 22082 22101 22121 22193 22220 22247 22363\n",
      " 22371 22391 22410]\n",
      "[[21977     0     8]\n",
      " [21988     0     8]\n",
      " [22012     0     8]\n",
      " [22039     0     8]\n",
      " [22049     0     8]\n",
      " [22082     0     8]\n",
      " [22101     0     8]\n",
      " [22121     0     8]\n",
      " [22193     0     8]\n",
      " [22220     0     8]\n",
      " [22247     0     8]\n",
      " [22363     0     8]\n",
      " [22371     0     8]\n",
      " [22391     0     8]\n",
      " [22410     0     8]\n",
      " [22426     0     8]\n",
      " [22470     0     8]\n",
      " [22505     0     8]\n",
      " [22535     0     8]\n",
      " [22567     0     8]\n",
      " [22574     0     8]\n",
      " [22697     0     8]\n",
      " [22710     0     8]\n",
      " [22728     0     8]\n",
      " [22739     0     8]\n",
      " [22768     0     8]\n",
      " [22776     0     8]\n",
      " [22791     0     8]\n",
      " [22821     0     8]\n",
      " [22838     0     8]\n",
      " [22851     0     8]\n",
      " [22856     0     8]\n",
      " [22996     0     8]\n",
      " [23007     0     8]\n",
      " [23039     0     8]\n",
      " [23053     0     8]\n",
      " [23117     0     8]\n",
      " [23137     0     8]\n",
      " [23152     0     8]\n",
      " [23183     0     8]\n",
      " [23200     0     8]\n",
      " [23218     0     8]\n",
      " [23233     0     8]\n",
      " [23383     0     8]\n",
      " [23400     0     8]\n",
      " [23413     0     8]\n",
      " [23472     0     8]\n",
      " [23503     0     8]\n",
      " [23536     0     8]\n",
      " [23552     0     8]\n",
      " [23566     0     8]\n",
      " [23576     0     8]\n",
      " [23601     0     8]\n",
      " [23634     0     8]\n",
      " [23646     0     8]\n",
      " [23697     0     8]\n",
      " [23779     0     8]\n",
      " [23792     0     8]\n",
      " [23833     0     8]\n",
      " [23846     0     8]\n",
      " [23884     0     8]\n",
      " [23891     0     8]\n",
      " [23919     0     8]\n",
      " [23935     0     8]\n",
      " [23967     0     8]\n",
      " [23998     0     8]\n",
      " [24036     0     8]\n",
      " [24087     0     8]\n",
      " [24101     0     8]\n",
      " [24140     0     8]\n",
      " [24321     0     8]\n",
      " [24343     0     8]\n",
      " [24383     0     8]\n",
      " [24390     0     8]\n",
      " [24407     0     8]\n",
      " [24423     0     8]\n",
      " [24462     0     8]\n",
      " [24476     0     8]\n",
      " [24510     0     8]\n",
      " [24529     0     8]\n",
      " [24541     0     8]\n",
      " [24570     0     8]\n",
      " [24647     0     8]\n",
      " [24659     0     8]\n",
      " [24677     0     8]\n",
      " [24702     0     8]\n",
      " [24730     0     8]\n",
      " [24740     0     8]\n",
      " [24750     0     8]\n",
      " [24834     0     8]\n",
      " [24858     0     8]\n",
      " [24895     0     8]\n",
      " [24913     0     8]\n",
      " [24940     0     8]\n",
      " [24966     0     8]\n",
      " [25003     0     8]\n",
      " [25030     0     8]\n",
      " [25050     0     8]\n",
      " [25099     0     8]\n",
      " [25119     0     8]\n",
      " [25127     0     8]\n",
      " [25157     0     8]\n",
      " [25189     0     8]\n",
      " [25198     0     8]\n",
      " [25222     0     8]\n",
      " [25238     0     8]\n",
      " [25280     0     8]\n",
      " [25289     0     8]\n",
      " [25331     0     8]\n",
      " [25367     0     8]\n",
      " [25385     0     8]\n",
      " [25405     0     8]\n",
      " [25593     0     8]\n",
      " [25621     0     8]\n",
      " [25661     0     8]\n",
      " [25681     0     8]\n",
      " [25712     0     8]\n",
      " [25725     0     8]\n",
      " [25763     0     8]\n",
      " [25806     0     8]\n",
      " [25827     0     8]\n",
      " [25932     0     8]\n",
      " [25948     0     8]\n",
      " [26010     0     8]\n",
      " [26032     0     8]\n",
      " [26081     0     8]\n",
      " [26107     0     8]\n",
      " [26191     0     8]\n",
      " [26212     0     8]\n",
      " [26308     0     8]\n",
      " [26321     0     8]\n",
      " [26345     0     8]\n",
      " [26352     0     8]\n",
      " [26380     0     8]\n",
      " [26393     0     8]\n",
      " [26403     0     8]\n",
      " [26441     0     8]\n",
      " [26457     0     8]\n",
      " [26462     0     8]\n",
      " [26504     0     8]\n",
      " [26564     0     8]\n",
      " [26580     0     8]\n",
      " [26589     0     8]\n",
      " [26652     0     8]\n",
      " [26690     0     8]\n",
      " [26756     0     8]\n",
      " [26824     0     8]\n",
      " [26862     0     8]\n",
      " [26884     0     8]\n",
      " [26893     0     8]\n",
      " [26911     0     8]\n",
      " [26952     0     8]\n",
      " [27048     0     8]\n",
      " [27068     0     8]\n",
      " [27085     0     8]\n",
      " [27114     0     8]\n",
      " [27150     0     8]\n",
      " [27175     0     8]\n",
      " [27181     0     8]\n",
      " [27210     0     8]\n",
      " [27250     0     8]\n",
      " [27287     0     8]\n",
      " [27301     0     8]\n",
      " [27311     0     8]\n",
      " [27363     0     8]\n",
      " [27387     0     8]\n",
      " [27433     0     8]\n",
      " [27449     0     8]\n",
      " [27472     0     8]\n",
      " [27497     0     8]\n",
      " [27509     0     8]\n",
      " [27528     0     8]\n",
      " [27562     0     8]\n",
      " [27579     0     8]\n",
      " [27587     0     8]]\n",
      "<Epochs |  170 events (all good), -0.3 – 1.2 s, baseline off, ~11.2 MB, data loaded,\n",
      " '8': 170>\n",
      "tape_num= 9\n",
      "wOnset_perTape_DF=           Word  Segment      onset\n",
      "1492        No        9   0.432017\n",
      "1493         I        9   1.046815\n",
      "1494        ll        9   1.198494\n",
      "1495      look        9   1.394026\n",
      "1496     first        9   1.753210\n",
      "...        ...      ...        ...\n",
      "1643      very        9  54.086271\n",
      "1644      soon        9  54.397564\n",
      "1645  finished        9  55.044094\n",
      "1646        it        9  55.423901\n",
      "1647       off        9  55.536451\n",
      "\n",
      "[156 rows x 3 columns]\n",
      "wOnset_datapoints_ndarray= [ 43.2017422 104.6814784 119.8493784 139.4025784 175.3209784 213.3840784\n",
      " 235.1848784 270.9578784 278.9662784 311.8107784 344.1372784 353.1518784\n",
      " 362.0964784 398.0148784 447.0263784] <class 'numpy.ndarray'>\n",
      "tape_start_datapoints_npINT64= 21994\n",
      "abs_wOnsets_dta_ndarray= [22037.2017422 22098.6814784 22113.8493784 22133.4025784 22169.3209784\n",
      " 22207.3840784 22229.1848784 22264.9578784 22272.9662784 22305.8107784\n",
      " 22338.1372784 22347.1518784 22356.0964784 22392.0148784 22441.0263784]\n",
      "rounded_abs_wOnsets_dta_ndarray= [22037 22098 22113 22133 22169 22207 22229 22264 22272 22305 22338 22347\n",
      " 22356 22392 22441]\n",
      "[[22037     0     9]\n",
      " [22098     0     9]\n",
      " [22113     0     9]\n",
      " [22133     0     9]\n",
      " [22169     0     9]\n",
      " [22207     0     9]\n",
      " [22229     0     9]\n",
      " [22264     0     9]\n",
      " [22272     0     9]\n",
      " [22305     0     9]\n",
      " [22338     0     9]\n",
      " [22347     0     9]\n",
      " [22356     0     9]\n",
      " [22392     0     9]\n",
      " [22441     0     9]\n",
      " [22453     0     9]\n",
      " [22542     0     9]\n",
      " [22552     0     9]\n",
      " [22574     0     9]\n",
      " [22593     0     9]\n",
      " [22615     0     9]\n",
      " [22668     0     9]\n",
      " [22700     0     9]\n",
      " [22724     0     9]\n",
      " [22789     0     9]\n",
      " [22820     0     9]\n",
      " [22865     0     9]\n",
      " [22875     0     9]\n",
      " [22881     0     9]\n",
      " [22926     0     9]\n",
      " [23009     0     9]\n",
      " [23026     0     9]\n",
      " [23055     0     9]\n",
      " [23076     0     9]\n",
      " [23094     0     9]\n",
      " [23135     0     9]\n",
      " [23189     0     9]\n",
      " [23197     0     9]\n",
      " [23224     0     9]\n",
      " [23283     0     9]\n",
      " [23364     0     9]\n",
      " [23386     0     9]\n",
      " [23425     0     9]\n",
      " [23442     0     9]\n",
      " [23485     0     9]\n",
      " [23507     0     9]\n",
      " [23552     0     9]\n",
      " [23561     0     9]\n",
      " [23621     0     9]\n",
      " [23664     0     9]\n",
      " [23679     0     9]\n",
      " [23713     0     9]\n",
      " [23724     0     9]\n",
      " [23759     0     9]\n",
      " [23831     0     9]\n",
      " [23864     0     9]\n",
      " [23946     0     9]\n",
      " [23959     0     9]\n",
      " [23967     0     9]\n",
      " [23996     0     9]\n",
      " [24033     0     9]\n",
      " [24071     0     9]\n",
      " [24095     0     9]\n",
      " [24136     0     9]\n",
      " [24154     0     9]\n",
      " [24169     0     9]\n",
      " [24186     0     9]\n",
      " [24212     0     9]\n",
      " [24227     0     9]\n",
      " [24248     0     9]\n",
      " [24317     0     9]\n",
      " [24336     0     9]\n",
      " [24349     0     9]\n",
      " [24361     0     9]\n",
      " [24373     0     9]\n",
      " [24401     0     9]\n",
      " [24415     0     9]\n",
      " [24452     0     9]\n",
      " [24501     0     9]\n",
      " [24543     0     9]\n",
      " [24563     0     9]\n",
      " [24568     0     9]\n",
      " [24606     0     9]\n",
      " [24617     0     9]\n",
      " [24662     0     9]\n",
      " [24781     0     9]\n",
      " [24792     0     9]\n",
      " [24810     0     9]\n",
      " [24822     0     9]\n",
      " [24858     0     9]\n",
      " [24919     0     9]\n",
      " [24939     0     9]\n",
      " [24954     0     9]\n",
      " [24968     0     9]\n",
      " [25008     0     9]\n",
      " [25040     0     9]\n",
      " [25054     0     9]\n",
      " [25060     0     9]\n",
      " [25099     0     9]\n",
      " [25138     0     9]\n",
      " [25228     0     9]\n",
      " [25238     0     9]\n",
      " [25246     0     9]\n",
      " [25291     0     9]\n",
      " [25330     0     9]\n",
      " [25343     0     9]\n",
      " [25398     0     9]\n",
      " [25415     0     9]\n",
      " [25431     0     9]\n",
      " [25472     0     9]\n",
      " [25482     0     9]\n",
      " [25677     0     9]\n",
      " [25721     0     9]\n",
      " [25747     0     9]\n",
      " [25780     0     9]\n",
      " [25799     0     9]\n",
      " [25834     0     9]\n",
      " [25870     0     9]\n",
      " [25945     0     9]\n",
      " [25965     0     9]\n",
      " [26010     0     9]\n",
      " [26046     0     9]\n",
      " [26056     0     9]\n",
      " [26101     0     9]\n",
      " [26159     0     9]\n",
      " [26177     0     9]\n",
      " [26222     0     9]\n",
      " [26242     0     9]\n",
      " [26286     0     9]\n",
      " [26371     0     9]\n",
      " [26386     0     9]\n",
      " [26425     0     9]\n",
      " [26443     0     9]\n",
      " [26499     0     9]\n",
      " [26506     0     9]\n",
      " [26535     0     9]\n",
      " [26553     0     9]\n",
      " [26593     0     9]\n",
      " [26646     0     9]\n",
      " [26663     0     9]\n",
      " [26716     0     9]\n",
      " [26815     0     9]\n",
      " [26891     0     9]\n",
      " [26989     0     9]\n",
      " [27029     0     9]\n",
      " [27078     0     9]\n",
      " [27134     0     9]\n",
      " [27151     0     9]\n",
      " [27177     0     9]\n",
      " [27214     0     9]\n",
      " [27377     0     9]\n",
      " [27402     0     9]\n",
      " [27433     0     9]\n",
      " [27498     0     9]\n",
      " [27536     0     9]\n",
      " [27547     0     9]]\n",
      "<Epochs |  155 events (all good), -0.3 – 1.2 s, baseline off, ~10.2 MB, data loaded,\n",
      " '9': 155>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/dt/yj00f34n5x52_p314tnwfjkw0000gn/T/ipykernel_30538/1641304678.py:107: RuntimeWarning: Concatenation of Annotations within Epochs is not supported yet. All annotations will be dropped.\n",
      "  wOnset_epochs = mne.concatenate_epochs(all_tapes_epochs_LIST)\n",
      "/var/folders/dt/yj00f34n5x52_p314tnwfjkw0000gn/T/ipykernel_30538/1641304678.py:107: RuntimeWarning: Concatenation of Annotations within Epochs is not supported yet. All annotations will be dropped.\n",
      "  wOnset_epochs = mne.concatenate_epochs(all_tapes_epochs_LIST)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tape_num= 10\n",
      "wOnset_perTape_DF=           Word  Segment      onset\n",
      "1648      What       10   1.051981\n",
      "1649         a       10   1.160767\n",
      "1650   curious       10   1.308375\n",
      "1651   feeling       10   2.146470\n",
      "1652      said       10   2.787119\n",
      "...        ...      ...        ...\n",
      "1830     could       10  59.244701\n",
      "1831       not       10  59.448239\n",
      "1832  possibly       10  59.855313\n",
      "1833     reach       10  60.430007\n",
      "1834        it       10  60.784961\n",
      "\n",
      "[187 rows x 3 columns]\n",
      "wOnset_datapoints_ndarray= [105.1980798 116.0767    130.8375    214.647     278.7119    306.9088\n",
      " 367.0205    381.0893    411.0007    419.3817    460.2269    478.0483\n",
      " 490.7454    500.4853    645.6674   ] <class 'numpy.ndarray'>\n",
      "tape_start_datapoints_npINT64= 22015\n",
      "abs_wOnsets_dta_ndarray= [22120.1980798 22131.0767    22145.8375    22229.647     22293.7119\n",
      " 22321.9088    22382.0205    22396.0893    22426.0007    22434.3817\n",
      " 22475.2269    22493.0483    22505.7454    22515.4853    22660.6674   ]\n",
      "rounded_abs_wOnsets_dta_ndarray= [22120 22131 22145 22229 22293 22321 22382 22396 22426 22434 22475 22493\n",
      " 22505 22515 22660]\n",
      "[[22120     0    10]\n",
      " [22131     0    10]\n",
      " [22145     0    10]\n",
      " [22229     0    10]\n",
      " [22293     0    10]\n",
      " [22321     0    10]\n",
      " [22382     0    10]\n",
      " [22396     0    10]\n",
      " [22426     0    10]\n",
      " [22434     0    10]\n",
      " [22475     0    10]\n",
      " [22493     0    10]\n",
      " [22505     0    10]\n",
      " [22515     0    10]\n",
      " [22660     0    10]\n",
      " [22676     0    10]\n",
      " [22704     0    10]\n",
      " [22715     0    10]\n",
      " [22739     0    10]\n",
      " [22839     0    10]\n",
      " [22854     0    10]\n",
      " [22872     0    10]\n",
      " [22900     0    10]\n",
      " [22922     0    10]\n",
      " [22950     0    10]\n",
      " [22988     0    10]\n",
      " [23052     0    10]\n",
      " [23067     0    10]\n",
      " [23077     0    10]\n",
      " [23119     0    10]\n",
      " [23154     0    10]\n",
      " [23173     0    10]\n",
      " [23183     0    10]\n",
      " [23200     0    10]\n",
      " [23231     0    10]\n",
      " [23248     0    10]\n",
      " [23266     0    10]\n",
      " [23289     0    10]\n",
      " [23311     0    10]\n",
      " [23328     0    10]\n",
      " [23351     0    10]\n",
      " [23392     0    10]\n",
      " [23404     0    10]\n",
      " [23443     0    10]\n",
      " [23466     0    10]\n",
      " [23474     0    10]\n",
      " [23508     0    10]\n",
      " [23552     0    10]\n",
      " [23582     0    10]\n",
      " [23604     0    10]\n",
      " [23636     0    10]\n",
      " [23793     0    10]\n",
      " [23831     0    10]\n",
      " [23866     0    10]\n",
      " [23887     0    10]\n",
      " [23922     0    10]\n",
      " [23951     0    10]\n",
      " [23954     0    10]\n",
      " [23982     0    10]\n",
      " [24062     0    10]\n",
      " [24074     0    10]\n",
      " [24093     0    10]\n",
      " [24108     0    10]\n",
      " [24127     0    10]\n",
      " [24145     0    10]\n",
      " [24171     0    10]\n",
      " [24178     0    10]\n",
      " [24212     0    10]\n",
      " [24235     0    10]\n",
      " [24333     0    10]\n",
      " [24352     0    10]\n",
      " [24384     0    10]\n",
      " [24391     0    10]\n",
      " [24421     0    10]\n",
      " [24463     0    10]\n",
      " [24493     0    10]\n",
      " [24602     0    10]\n",
      " [24621     0    10]\n",
      " [24627     0    10]\n",
      " [24666     0    10]\n",
      " [24704     0    10]\n",
      " [24721     0    10]\n",
      " [24767     0    10]\n",
      " [24790     0    10]\n",
      " [24827     0    10]\n",
      " [24839     0    10]\n",
      " [24931     0    10]\n",
      " [24944     0    10]\n",
      " [24959     0    10]\n",
      " [25003     0    10]\n",
      " [25019     0    10]\n",
      " [25079     0    10]\n",
      " [25106     0    10]\n",
      " [25112     0    10]\n",
      " [25249     0    10]\n",
      " [25262     0    10]\n",
      " [25299     0    10]\n",
      " [25315     0    10]\n",
      " [25324     0    10]\n",
      " [25349     0    10]\n",
      " [25362     0    10]\n",
      " [25395     0    10]\n",
      " [25535     0    10]\n",
      " [25544     0    10]\n",
      " [25559     0    10]\n",
      " [25580     0    10]\n",
      " [25596     0    10]\n",
      " [25644     0    10]\n",
      " [25663     0    10]\n",
      " [25671     0    10]\n",
      " [25706     0    10]\n",
      " [25718     0    10]\n",
      " [25724     0    10]\n",
      " [25771     0    10]\n",
      " [25790     0    10]\n",
      " [25828     0    10]\n",
      " [25859     0    10]\n",
      " [25872     0    10]\n",
      " [25917     0    10]\n",
      " [25935     0    10]\n",
      " [25961     0    10]\n",
      " [26035     0    10]\n",
      " [26047     0    10]\n",
      " [26064     0    10]\n",
      " [26082     0    10]\n",
      " [26107     0    10]\n",
      " [26150     0    10]\n",
      " [26192     0    10]\n",
      " [26226     0    10]\n",
      " [26259     0    10]\n",
      " [26283     0    10]\n",
      " [26290     0    10]\n",
      " [26398     0    10]\n",
      " [26441     0    10]\n",
      " [26451     0    10]\n",
      " [26499     0    10]\n",
      " [26538     0    10]\n",
      " [26555     0    10]\n",
      " [26592     0    10]\n",
      " [26612     0    10]\n",
      " [26696     0    10]\n",
      " [26714     0    10]\n",
      " [26768     0    10]\n",
      " [26788     0    10]\n",
      " [26820     0    10]\n",
      " [26846     0    10]\n",
      " [26858     0    10]\n",
      " [26894     0    10]\n",
      " [26909     0    10]\n",
      " [27029     0    10]\n",
      " [27041     0    10]\n",
      " [27090     0    10]\n",
      " [27098     0    10]\n",
      " [27128     0    10]\n",
      " [27175     0    10]\n",
      " [27188     0    10]\n",
      " [27205     0    10]\n",
      " [27235     0    10]\n",
      " [27247     0    10]\n",
      " [27261     0    10]\n",
      " [27348     0    10]\n",
      " [27368     0    10]\n",
      " [27401     0    10]\n",
      " [27418     0    10]\n",
      " [27425     0    10]\n",
      " [27474     0    10]\n",
      " [27484     0    10]\n",
      " [27518     0    10]\n",
      " [27556     0    10]\n",
      " [27649     0    10]\n",
      " [27664     0    10]\n",
      " [27679     0    10]\n",
      " [27695     0    10]\n",
      " [27714     0    10]\n",
      " [27739     0    10]\n",
      " [27750     0    10]\n",
      " [27761     0    10]\n",
      " [27799     0    10]\n",
      " [27835     0    10]\n",
      " [27882     0    10]\n",
      " [27902     0    10]\n",
      " [27927     0    10]\n",
      " [27939     0    10]\n",
      " [27959     0    10]\n",
      " [28000     0    10]\n",
      " [28058     0    10]\n",
      " [28093     0    10]]\n",
      "<Epochs |  183 events (all good), -0.3 – 1.2 s, baseline off, ~12.1 MB, data loaded,\n",
      " '10': 183>\n",
      "tape_num= 11\n",
      "wOnset_perTape_DF=              Word  Segment      onset\n",
      "1835          she       11   0.274485\n",
      "1836        could       11   0.489783\n",
      "1837          see       11   0.701863\n",
      "1838           it       11   1.064477\n",
      "1839        quite       11   1.279987\n",
      "...           ...      ...        ...\n",
      "1987           to       11  53.797174\n",
      "1988         make       11  53.890245\n",
      "1989          one       11  54.211688\n",
      "1990  respectable       11  54.517325\n",
      "1991       person       11  55.331149\n",
      "\n",
      "[157 rows x 3 columns]\n",
      "wOnset_datapoints_ndarray= [ 27.448538   48.9783265  70.1863265 106.4477265 127.9987265 161.5225265\n",
      " 213.0055265 236.9511265 245.3320265 357.8762265 369.5823265 386.6109265\n",
      " 420.1347265 433.3048265 489.5769265] <class 'numpy.ndarray'>\n",
      "tape_start_datapoints_npINT64= 29016\n",
      "abs_wOnsets_dta_ndarray= [29043.448538  29064.9783265 29086.1863265 29122.4477265 29143.9987265\n",
      " 29177.5225265 29229.0055265 29252.9511265 29261.3320265 29373.8762265\n",
      " 29385.5823265 29402.6109265 29436.1347265 29449.3048265 29505.5769265]\n",
      "rounded_abs_wOnsets_dta_ndarray= [29043 29064 29086 29122 29143 29177 29229 29252 29261 29373 29385 29402\n",
      " 29436 29449 29505]\n",
      "[[29043     0    11]\n",
      " [29064     0    11]\n",
      " [29086     0    11]\n",
      " [29122     0    11]\n",
      " [29143     0    11]\n",
      " [29177     0    11]\n",
      " [29229     0    11]\n",
      " [29252     0    11]\n",
      " [29261     0    11]\n",
      " [29373     0    11]\n",
      " [29385     0    11]\n",
      " [29402     0    11]\n",
      " [29436     0    11]\n",
      " [29449     0    11]\n",
      " [29505     0    11]\n",
      " [29513     0    11]\n",
      " [29546     0    11]\n",
      " [29565     0    11]\n",
      " [29581     0    11]\n",
      " [29589     0    11]\n",
      " [29602     0    11]\n",
      " [29634     0    11]\n",
      " [29643     0    11]\n",
      " [29651     0    11]\n",
      " [29743     0    11]\n",
      " [29755     0    11]\n",
      " [29766     0    11]\n",
      " [29784     0    11]\n",
      " [29803     0    11]\n",
      " [29935     0    11]\n",
      " [29948     0    11]\n",
      " [29962     0    11]\n",
      " [29982     0    11]\n",
      " [29998     0    11]\n",
      " [30045     0    11]\n",
      " [30090     0    11]\n",
      " [30110     0    11]\n",
      " [30128     0    11]\n",
      " [30232     0    11]\n",
      " [30241     0    11]\n",
      " [30272     0    11]\n",
      " [30300     0    11]\n",
      " [30330     0    11]\n",
      " [30362     0    11]\n",
      " [30388     0    11]\n",
      " [30403     0    11]\n",
      " [30644     0    11]\n",
      " [30670     0    11]\n",
      " [30681     0    11]\n",
      " [30716     0    11]\n",
      " [30749     0    11]\n",
      " [30785     0    11]\n",
      " [30836     0    11]\n",
      " [30858     0    11]\n",
      " [30924     0    11]\n",
      " [30946     0    11]\n",
      " [30992     0    11]\n",
      " [31006     0    11]\n",
      " [31054     0    11]\n",
      " [31082     0    11]\n",
      " [31196     0    11]\n",
      " [31211     0    11]\n",
      " [31271     0    11]\n",
      " [31284     0    11]\n",
      " [31296     0    11]\n",
      " [31321     0    11]\n",
      " [31354     0    11]\n",
      " [31393     0    11]\n",
      " [31562     0    11]\n",
      " [31583     0    11]\n",
      " [31628     0    11]\n",
      " [31654     0    11]\n",
      " [31695     0    11]\n",
      " [31731     0    11]\n",
      " [31750     0    11]\n",
      " [31820     0    11]\n",
      " [31829     0    11]\n",
      " [31851     0    11]\n",
      " [31883     0    11]\n",
      " [31930     0    11]\n",
      " [31973     0    11]\n",
      " [32052     0    11]\n",
      " [32066     0    11]\n",
      " [32125     0    11]\n",
      " [32136     0    11]\n",
      " [32183     0    11]\n",
      " [32228     0    11]\n",
      " [32260     0    11]\n",
      " [32329     0    11]\n",
      " [32346     0    11]\n",
      " [32357     0    11]\n",
      " [32383     0    11]\n",
      " [32425     0    11]\n",
      " [32447     0    11]\n",
      " [32470     0    11]\n",
      " [32562     0    11]\n",
      " [32578     0    11]\n",
      " [32614     0    11]\n",
      " [32659     0    11]\n",
      " [32690     0    11]\n",
      " [32698     0    11]\n",
      " [32745     0    11]\n",
      " [32756     0    11]\n",
      " [32780     0    11]\n",
      " [32819     0    11]\n",
      " [32830     0    11]\n",
      " [32860     0    11]\n",
      " [32902     0    11]\n",
      " [32952     0    11]\n",
      " [32963     0    11]\n",
      " [32969     0    11]\n",
      " [32997     0    11]\n",
      " [33011     0    11]\n",
      " [33057     0    11]\n",
      " [33078     0    11]\n",
      " [33097     0    11]\n",
      " [33131     0    11]\n",
      " [33178     0    11]\n",
      " [33296     0    11]\n",
      " [33309     0    11]\n",
      " [33335     0    11]\n",
      " [33389     0    11]\n",
      " [33431     0    11]\n",
      " [33458     0    11]\n",
      " [33494     0    11]\n",
      " [33508     0    11]\n",
      " [33560     0    11]\n",
      " [33569     0    11]\n",
      " [33589     0    11]\n",
      " [33612     0    11]\n",
      " [33769     0    11]\n",
      " [33777     0    11]\n",
      " [33789     0    11]\n",
      " [33803     0    11]\n",
      " [33837     0    11]\n",
      " [33872     0    11]\n",
      " [33958     0    11]\n",
      " [33975     0    11]\n",
      " [34008     0    11]\n",
      " [34047     0    11]\n",
      " [34060     0    11]\n",
      " [34103     0    11]\n",
      " [34110     0    11]\n",
      " [34131     0    11]\n",
      " [34158     0    11]\n",
      " [34200     0    11]\n",
      " [34253     0    11]\n",
      " [34267     0    11]\n",
      " [34281     0    11]\n",
      " [34321     0    11]\n",
      " [34358     0    11]\n",
      " [34380     0    11]\n",
      " [34395     0    11]\n",
      " [34405     0    11]\n",
      " [34437     0    11]\n",
      " [34467     0    11]\n",
      " [34549     0    11]]\n",
      "<Epochs |  152 events (all good), -0.3 – 1.2 s, baseline off, ~10.1 MB, data loaded,\n",
      " '11': 152>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/dt/yj00f34n5x52_p314tnwfjkw0000gn/T/ipykernel_30538/1641304678.py:107: RuntimeWarning: Concatenation of Annotations within Epochs is not supported yet. All annotations will be dropped.\n",
      "  wOnset_epochs = mne.concatenate_epochs(all_tapes_epochs_LIST)\n",
      "/var/folders/dt/yj00f34n5x52_p314tnwfjkw0000gn/T/ipykernel_30538/1641304678.py:107: RuntimeWarning: Concatenation of Annotations within Epochs is not supported yet. All annotations will be dropped.\n",
      "  wOnset_epochs = mne.concatenate_epochs(all_tapes_epochs_LIST)\n",
      "/var/folders/dt/yj00f34n5x52_p314tnwfjkw0000gn/T/ipykernel_30538/1641304678.py:108: RuntimeWarning: This filename (/Users/neuroling/Downloads/DINGHSIN_Results/Alice_Experiments_Results/EEG_ESLs/Alice_ESLs_wOnset_raw_epochs/S027_ESLs_wOnset_epochs_11Tapes_raw.fif) does not conform to MNE naming conventions. All epochs files should end with -epo.fif, -epo.fif.gz, _epo.fif or _epo.fif.gz\n",
      "  wOnset_epochs.save(wOnset_DIR / Path('%s_ESLs_wOnset_epochs_11Tapes_raw.fif' %subject[4:8]), overwrite=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tape_num= 12\n",
      "wOnset_perTape_DF=          Word  Segment      onset\n",
      "1992     Soon       12   0.229476\n",
      "1993      her       12   0.504358\n",
      "1994      eye       12   0.658032\n",
      "1995     fell       12   0.974924\n",
      "1996       on       12   1.266236\n",
      "...       ...      ...        ...\n",
      "2124  happens       12  45.226353\n",
      "2125     when       12  45.677924\n",
      "2126      one       12  45.896829\n",
      "2127     eats       12  46.064448\n",
      "2128     cake       12  46.327849\n",
      "\n",
      "[137 rows x 3 columns]\n",
      "wOnset_datapoints_ndarray= [ 22.9476225  50.4358225  65.8032225  97.4924225 126.6236225 144.1863225\n",
      " 151.5146225 180.1046225 222.0094225 268.7033225 279.4788225 292.6489225\n",
      " 329.3501225 356.1046225 364.4856225] <class 'numpy.ndarray'>\n",
      "tape_start_datapoints_npINT64= 29067\n",
      "abs_wOnsets_dta_ndarray= [29089.9476225 29117.4358225 29132.8032225 29164.4924225 29193.6236225\n",
      " 29211.1863225 29218.5146225 29247.1046225 29289.0094225 29335.7033225\n",
      " 29346.4788225 29359.6489225 29396.3501225 29423.1046225 29431.4856225]\n",
      "rounded_abs_wOnsets_dta_ndarray= [29089 29117 29132 29164 29193 29211 29218 29247 29289 29335 29346 29359\n",
      " 29396 29423 29431]\n",
      "[[29089     0    12]\n",
      " [29117     0    12]\n",
      " [29132     0    12]\n",
      " [29164     0    12]\n",
      " [29193     0    12]\n",
      " [29211     0    12]\n",
      " [29218     0    12]\n",
      " [29247     0    12]\n",
      " [29289     0    12]\n",
      " [29335     0    12]\n",
      " [29346     0    12]\n",
      " [29359     0    12]\n",
      " [29396     0    12]\n",
      " [29423     0    12]\n",
      " [29431     0    12]\n",
      " [29536     0    12]\n",
      " [29559     0    12]\n",
      " [29597     0    12]\n",
      " [29655     0    12]\n",
      " [29680     0    12]\n",
      " [29713     0    12]\n",
      " [29727     0    12]\n",
      " [29742     0    12]\n",
      " [29751     0    12]\n",
      " [29788     0    12]\n",
      " [29831     0    12]\n",
      " [29928     0    12]\n",
      " [29940     0    12]\n",
      " [29967     0    12]\n",
      " [29978     0    12]\n",
      " [30035     0    12]\n",
      " [30066     0    12]\n",
      " [30143     0    12]\n",
      " [30169     0    12]\n",
      " [30225     0    12]\n",
      " [30260     0    12]\n",
      " [30273     0    12]\n",
      " [30470     0    12]\n",
      " [30552     0    12]\n",
      " [30564     0    12]\n",
      " [30579     0    12]\n",
      " [30603     0    12]\n",
      " [30651     0    12]\n",
      " [30676     0    12]\n",
      " [30718     0    12]\n",
      " [30729     0    12]\n",
      " [30746     0    12]\n",
      " [30759     0    12]\n",
      " [30785     0    12]\n",
      " [30802     0    12]\n",
      " [30825     0    12]\n",
      " [30873     0    12]\n",
      " [30884     0    12]\n",
      " [30903     0    12]\n",
      " [30932     0    12]\n",
      " [30943     0    12]\n",
      " [31033     0    12]\n",
      " [31046     0    12]\n",
      " [31059     0    12]\n",
      " [31072     0    12]\n",
      " [31098     0    12]\n",
      " [31112     0    12]\n",
      " [31130     0    12]\n",
      " [31228     0    12]\n",
      " [31242     0    12]\n",
      " [31263     0    12]\n",
      " [31294     0    12]\n",
      " [31317     0    12]\n",
      " [31327     0    12]\n",
      " [31415     0    12]\n",
      " [31436     0    12]\n",
      " [31468     0    12]\n",
      " [31490     0    12]\n",
      " [31496     0    12]\n",
      " [31502     0    12]\n",
      " [31519     0    12]\n",
      " [31544     0    12]\n",
      " [31554     0    12]\n",
      " [31627     0    12]\n",
      " [31640     0    12]\n",
      " [31655     0    12]\n",
      " [31671     0    12]\n",
      " [31694     0    12]\n",
      " [31719     0    12]\n",
      " [31876     0    12]\n",
      " [31903     0    12]\n",
      " [31929     0    12]\n",
      " [31940     0    12]\n",
      " [31990     0    12]\n",
      " [32096     0    12]\n",
      " [32105     0    12]\n",
      " [32126     0    12]\n",
      " [32187     0    12]\n",
      " [32202     0    12]\n",
      " [32326     0    12]\n",
      " [32355     0    12]\n",
      " [32457     0    12]\n",
      " [32487     0    12]\n",
      " [32608     0    12]\n",
      " [32638     0    12]\n",
      " [32648     0    12]\n",
      " [32683     0    12]\n",
      " [32695     0    12]\n",
      " [32702     0    12]\n",
      " [32731     0    12]\n",
      " [32738     0    12]\n",
      " [32752     0    12]\n",
      " [32781     0    12]\n",
      " [32795     0    12]\n",
      " [32829     0    12]\n",
      " [32851     0    12]\n",
      " [32871     0    12]\n",
      " [32886     0    12]\n",
      " [32903     0    12]\n",
      " [33019     0    12]\n",
      " [33029     0    12]\n",
      " [33046     0    12]\n",
      " [33064     0    12]\n",
      " [33089     0    12]\n",
      " [33163     0    12]\n",
      " [33170     0    12]\n",
      " [33201     0    12]\n",
      " [33212     0    12]\n",
      " [33231     0    12]\n",
      " [33272     0    12]\n",
      " [33279     0    12]\n",
      " [33311     0    12]\n",
      " [33438     0    12]\n",
      " [33454     0    12]\n",
      " [33466     0    12]\n",
      " [33501     0    12]\n",
      " [33532     0    12]\n",
      " [33589     0    12]\n",
      " [33634     0    12]\n",
      " [33656     0    12]\n",
      " [33673     0    12]\n",
      " [33699     0    12]]\n",
      "<Epochs |  137 events (all good), -0.3 – 1.2 s, baseline off, ~9.1 MB, data loaded,\n",
      " '12': 137>\n",
      "subject_num= n_2_ wOnset epoch saved.\n",
      "subject_num= n_2_S023_ICAed_raw.fif\n",
      "tape_num= 2\n",
      "wOnset_perTape_DF=          Word  Segment      onset\n",
      "174       but        2   0.479840\n",
      "175      when        2   0.592424\n",
      "176       the        2   0.810806\n",
      "177    Rabbit        2   0.912952\n",
      "178  actually        2   1.415810\n",
      "..        ...      ...        ...\n",
      "346       was        2  58.681660\n",
      "347     going        2  58.861252\n",
      "348        to        2  59.148599\n",
      "349    happen        2  59.251158\n",
      "350      next        2  59.687374\n",
      "\n",
      "[177 rows x 3 columns]\n",
      "wOnset_datapoints_ndarray= [ 47.9839572  59.2424402  81.0806402  91.2952402 141.5810402 191.8667402\n",
      " 238.5605402 255.7777402 321.1728402 343.1803402 359.5218402 379.0771402\n",
      " 438.4907402 563.7331402 574.7717402] <class 'numpy.ndarray'>\n",
      "tape_start_datapoints_npINT64= 1509\n",
      "abs_wOnsets_dta_ndarray= [1556.9839572 1568.2424402 1590.0806402 1600.2952402 1650.5810402\n",
      " 1700.8667402 1747.5605402 1764.7777402 1830.1728402 1852.1803402\n",
      " 1868.5218402 1888.0771402 1947.4907402 2072.7331402 2083.7717402]\n",
      "rounded_abs_wOnsets_dta_ndarray= [1556 1568 1590 1600 1650 1700 1747 1764 1830 1852 1868 1888 1947 2072\n",
      " 2083]\n",
      "[[1556    0    2]\n",
      " [1568    0    2]\n",
      " [1590    0    2]\n",
      " [1600    0    2]\n",
      " [1650    0    2]\n",
      " [1700    0    2]\n",
      " [1747    0    2]\n",
      " [1764    0    2]\n",
      " [1830    0    2]\n",
      " [1852    0    2]\n",
      " [1868    0    2]\n",
      " [1888    0    2]\n",
      " [1947    0    2]\n",
      " [2072    0    2]\n",
      " [2083    0    2]\n",
      " [2116    0    2]\n",
      " [2137    0    2]\n",
      " [2197    0    2]\n",
      " [2208    0    2]\n",
      " [2224    0    2]\n",
      " [2263    0    2]\n",
      " [2355    0    2]\n",
      " [2403    0    2]\n",
      " [2445    0    2]\n",
      " [2464    0    2]\n",
      " [2478    0    2]\n",
      " [2519    0    2]\n",
      " [2541    0    2]\n",
      " [2553    0    2]\n",
      " [2594    0    2]\n",
      " [2639    0    2]\n",
      " [2646    0    2]\n",
      " [2728    0    2]\n",
      " [2740    0    2]\n",
      " [2751    0    2]\n",
      " [2762    0    2]\n",
      " [2799    0    2]\n",
      " [2841    0    2]\n",
      " [2884    0    2]\n",
      " [2892    0    2]\n",
      " [2929    0    2]\n",
      " [2946    0    2]\n",
      " [2984    0    2]\n",
      " [2994    0    2]\n",
      " [3038    0    2]\n",
      " [3093    0    2]\n",
      " [3121    0    2]\n",
      " [3126    0    2]\n",
      " [3167    0    2]\n",
      " [3179    0    2]\n",
      " [3207    0    2]\n",
      " [3227    0    2]\n",
      " [3240    0    2]\n",
      " [3310    0    2]\n",
      " [3336    0    2]\n",
      " [3374    0    2]\n",
      " [3390    0    2]\n",
      " [3517    0    2]\n",
      " [3538    0    2]\n",
      " [3563    0    2]\n",
      " [3603    0    2]\n",
      " [3612    0    2]\n",
      " [3650    0    2]\n",
      " [3695    0    2]\n",
      " [3749    0    2]\n",
      " [3768    0    2]\n",
      " [3867    0    2]\n",
      " [3895    0    2]\n",
      " [3933    0    2]\n",
      " [3946    0    2]\n",
      " [3977    0    2]\n",
      " [3987    0    2]\n",
      " [4006    0    2]\n",
      " [4022    0    2]\n",
      " [4055    0    2]\n",
      " [4078    0    2]\n",
      " [4088    0    2]\n",
      " [4127    0    2]\n",
      " [4161    0    2]\n",
      " [4191    0    2]\n",
      " [4219    0    2]\n",
      " [4229    0    2]\n",
      " [4374    0    2]\n",
      " [4394    0    2]\n",
      " [4436    0    2]\n",
      " [4492    0    2]\n",
      " [4526    0    2]\n",
      " [4544    0    2]\n",
      " [4585    0    2]\n",
      " [4627    0    2]\n",
      " [4679    0    2]\n",
      " [4707    0    2]\n",
      " [4746    0    2]\n",
      " [4828    0    2]\n",
      " [4855    0    2]\n",
      " [4867    0    2]\n",
      " [4876    0    2]\n",
      " [4916    0    2]\n",
      " [4933    0    2]\n",
      " [4956    0    2]\n",
      " [4965    0    2]\n",
      " [4981    0    2]\n",
      " [5002    0    2]\n",
      " [5158    0    2]\n",
      " [5167    0    2]\n",
      " [5205    0    2]\n",
      " [5224    0    2]\n",
      " [5239    0    2]\n",
      " [5277    0    2]\n",
      " [5296    0    2]\n",
      " [5314    0    2]\n",
      " [5321    0    2]\n",
      " [5362    0    2]\n",
      " [5380    0    2]\n",
      " [5410    0    2]\n",
      " [5469    0    2]\n",
      " [5487    0    2]\n",
      " [5509    0    2]\n",
      " [5534    0    2]\n",
      " [5593    0    2]\n",
      " [5654    0    2]\n",
      " [5688    0    2]\n",
      " [5781    0    2]\n",
      " [5793    0    2]\n",
      " [5835    0    2]\n",
      " [5853    0    2]\n",
      " [5870    0    2]\n",
      " [5875    0    2]\n",
      " [5929    0    2]\n",
      " [5938    0    2]\n",
      " [5964    0    2]\n",
      " [5993    0    2]\n",
      " [6043    0    2]\n",
      " [6094    0    2]\n",
      " [6128    0    2]\n",
      " [6151    0    2]\n",
      " [6176    0    2]\n",
      " [6219    0    2]\n",
      " [6255    0    2]\n",
      " [6276    0    2]\n",
      " [6285    0    2]\n",
      " [6328    0    2]\n",
      " [6361    0    2]\n",
      " [6530    0    2]\n",
      " [6565    0    2]\n",
      " [6578    0    2]\n",
      " [6608    0    2]\n",
      " [6626    0    2]\n",
      " [6662    0    2]\n",
      " [6722    0    2]\n",
      " [6727    0    2]\n",
      " [6753    0    2]\n",
      " [6774    0    2]\n",
      " [6803    0    2]\n",
      " [6917    0    2]\n",
      " [6932    0    2]\n",
      " [6948    0    2]\n",
      " [6968    0    2]\n",
      " [7024    0    2]\n",
      " [7039    0    2]\n",
      " [7071    0    2]\n",
      " [7085    0    2]\n",
      " [7102    0    2]\n",
      " [7126    0    2]\n",
      " [7195    0    2]\n",
      " [7208    0    2]\n",
      " [7233    0    2]\n",
      " [7270    0    2]\n",
      " [7296    0    2]\n",
      " [7310    0    2]\n",
      " [7325    0    2]\n",
      " [7360    0    2]\n",
      " [7377    0    2]\n",
      " [7395    0    2]\n",
      " [7423    0    2]\n",
      " [7434    0    2]\n",
      " [7477    0    2]]\n",
      "<Epochs |  171 events (all good), -0.3 – 1.2 s, baseline off, ~11.3 MB, data loaded,\n",
      " '2': 171>\n",
      "tape_num= 3\n",
      "wOnset_perTape_DF=       Word  Segment      onset\n",
      "351  First        3   0.478723\n",
      "352    she        3   0.986270\n",
      "353  tried        3   1.201781\n",
      "354     to        3   1.501100\n",
      "355   look        3   1.604643\n",
      "..     ...      ...        ...\n",
      "530   this        3  61.269264\n",
      "531   time        3  61.591394\n",
      "532    she        3  62.071440\n",
      "533   said        3  62.263005\n",
      "534  aloud        3  62.538379\n",
      "\n",
      "[184 rows x 3 columns]\n",
      "wOnset_datapoints_ndarray= [ 47.8723402  98.6269787 120.1780787 150.1099787 160.4642787 183.6337787\n",
      " 218.3548787 231.5249787 260.2596787 284.2052787 296.1780787 314.3827787\n",
      " 333.2936787 371.6065787 450.6269787] <class 'numpy.ndarray'>\n",
      "tape_start_datapoints_npINT64= 7310\n",
      "abs_wOnsets_dta_ndarray= [7357.8723402 7408.6269787 7430.1780787 7460.1099787 7470.4642787\n",
      " 7493.6337787 7528.3548787 7541.5249787 7570.2596787 7594.2052787\n",
      " 7606.1780787 7624.3827787 7643.2936787 7681.6065787 7760.6269787]\n",
      "rounded_abs_wOnsets_dta_ndarray= [7357 7408 7430 7460 7470 7493 7528 7541 7570 7594 7606 7624 7643 7681\n",
      " 7760]\n",
      "[[ 7357     0     3]\n",
      " [ 7408     0     3]\n",
      " [ 7430     0     3]\n",
      " [ 7460     0     3]\n",
      " [ 7470     0     3]\n",
      " [ 7493     0     3]\n",
      " [ 7528     0     3]\n",
      " [ 7541     0     3]\n",
      " [ 7570     0     3]\n",
      " [ 7594     0     3]\n",
      " [ 7606     0     3]\n",
      " [ 7624     0     3]\n",
      " [ 7643     0     3]\n",
      " [ 7681     0     3]\n",
      " [ 7760     0     3]\n",
      " [ 7771     0     3]\n",
      " [ 7782     0     3]\n",
      " [ 7798     0     3]\n",
      " [ 7815     0     3]\n",
      " [ 7840     0     3]\n",
      " [ 7854     0     3]\n",
      " [ 7879     0     3]\n",
      " [ 8030     0     3]\n",
      " [ 8050     0     3]\n",
      " [ 8076     0     3]\n",
      " [ 8101     0     3]\n",
      " [ 8112     0     3]\n",
      " [ 8121     0     3]\n",
      " [ 8158     0     3]\n",
      " [ 8166     0     3]\n",
      " [ 8176     0     3]\n",
      " [ 8262     0     3]\n",
      " [ 8277     0     3]\n",
      " [ 8317     0     3]\n",
      " [ 8330     0     3]\n",
      " [ 8343     0     3]\n",
      " [ 8356     0     3]\n",
      " [ 8390     0     3]\n",
      " [ 8407     0     3]\n",
      " [ 8465     0     3]\n",
      " [ 8486     0     3]\n",
      " [ 8717     0     3]\n",
      " [ 8742     0     3]\n",
      " [ 8757     0     3]\n",
      " [ 8785     0     3]\n",
      " [ 8810     0     3]\n",
      " [ 8834     0     3]\n",
      " [ 8888     0     3]\n",
      " [ 8900     0     3]\n",
      " [ 8947     0     3]\n",
      " [ 8964     0     3]\n",
      " [ 8982     0     3]\n",
      " [ 9001     0     3]\n",
      " [ 9137     0     3]\n",
      " [ 9155     0     3]\n",
      " [ 9179     0     3]\n",
      " [ 9206     0     3]\n",
      " [ 9215     0     3]\n",
      " [ 9257     0     3]\n",
      " [ 9273     0     3]\n",
      " [ 9290     0     3]\n",
      " [ 9299     0     3]\n",
      " [ 9308     0     3]\n",
      " [ 9355     0     3]\n",
      " [ 9362     0     3]\n",
      " [ 9382     0     3]\n",
      " [ 9476     0     3]\n",
      " [ 9490     0     3]\n",
      " [ 9510     0     3]\n",
      " [ 9567     0     3]\n",
      " [ 9621     0     3]\n",
      " [ 9743     0     3]\n",
      " [ 9756     0     3]\n",
      " [ 9764     0     3]\n",
      " [ 9779     0     3]\n",
      " [ 9814     0     3]\n",
      " [ 9888     0     3]\n",
      " [ 9900     0     3]\n",
      " [ 9920     0     3]\n",
      " [10034     0     3]\n",
      " [10052     0     3]\n",
      " [10067     0     3]\n",
      " [10086     0     3]\n",
      " [10103     0     3]\n",
      " [10113     0     3]\n",
      " [10145     0     3]\n",
      " [10155     0     3]\n",
      " [10180     0     3]\n",
      " [10197     0     3]\n",
      " [10227     0     3]\n",
      " [10234     0     3]\n",
      " [10271     0     3]\n",
      " [10351     0     3]\n",
      " [10367     0     3]\n",
      " [10385     0     3]\n",
      " [10430     0     3]\n",
      " [10438     0     3]\n",
      " [10458     0     3]\n",
      " [10470     0     3]\n",
      " [10504     0     3]\n",
      " [10521     0     3]\n",
      " [10531     0     3]\n",
      " [10540     0     3]\n",
      " [10590     0     3]\n",
      " [10599     0     3]\n",
      " [10619     0     3]\n",
      " [10641     0     3]\n",
      " [10684     0     3]\n",
      " [10884     0     3]\n",
      " [10963     0     3]\n",
      " [10979     0     3]\n",
      " [11022     0     3]\n",
      " [11035     0     3]\n",
      " [11101     0     3]\n",
      " [11135     0     3]\n",
      " [11162     0     3]\n",
      " [11168     0     3]\n",
      " [11195     0     3]\n",
      " [11215     0     3]\n",
      " [11244     0     3]\n",
      " [11250     0     3]\n",
      " [11271     0     3]\n",
      " [11298     0     3]\n",
      " [11357     0     3]\n",
      " [11365     0     3]\n",
      " [11412     0     3]\n",
      " [11437     0     3]\n",
      " [11577     0     3]\n",
      " [11610     0     3]\n",
      " [11662     0     3]\n",
      " [11676     0     3]\n",
      " [11686     0     3]\n",
      " [11705     0     3]\n",
      " [11735     0     3]\n",
      " [11747     0     3]\n",
      " [11761     0     3]\n",
      " [11852     0     3]\n",
      " [11882     0     3]\n",
      " [11891     0     3]\n",
      " [11910     0     3]\n",
      " [11921     0     3]\n",
      " [11942     0     3]\n",
      " [11991     0     3]\n",
      " [12020     0     3]\n",
      " [12034     0     3]\n",
      " [12062     0     3]\n",
      " [12078     0     3]\n",
      " [12092     0     3]\n",
      " [12117     0     3]\n",
      " [12135     0     3]\n",
      " [12146     0     3]\n",
      " [12176     0     3]\n",
      " [12184     0     3]\n",
      " [12196     0     3]\n",
      " [12311     0     3]\n",
      " [12334     0     3]\n",
      " [12352     0     3]\n",
      " [12378     0     3]\n",
      " [12418     0     3]\n",
      " [12585     0     3]\n",
      " [12686     0     3]\n",
      " [12799     0     3]\n",
      " [12908     0     3]\n",
      " [12918     0     3]\n",
      " [12925     0     3]\n",
      " [12953     0     3]\n",
      " [13010     0     3]\n",
      " [13038     0     3]\n",
      " [13055     0     3]\n",
      " [13069     0     3]\n",
      " [13191     0     3]\n",
      " [13209     0     3]\n",
      " [13252     0     3]\n",
      " [13281     0     3]\n",
      " [13304     0     3]\n",
      " [13355     0     3]\n",
      " [13366     0     3]\n",
      " [13374     0     3]\n",
      " [13415     0     3]\n",
      " [13436     0     3]\n",
      " [13469     0     3]\n",
      " [13517     0     3]\n",
      " [13536     0     3]\n",
      " [13563     0     3]]\n",
      "<Epochs |  177 events (all good), -0.3 – 1.2 s, baseline off, ~11.7 MB, data loaded,\n",
      " '3': 177>\n",
      "tape_num= 4\n",
      "wOnset_perTape_DF=           Word  Segment      onset\n",
      "535       must        4   0.398386\n",
      "536         be        4   0.689428\n",
      "537    getting        4   0.840938\n",
      "538  somewhere        4   1.126350\n",
      "539       near        4   1.542892\n",
      "..         ...      ...        ...\n",
      "744      think        4  68.262788\n",
      "745        you        4  68.437370\n",
      "746      could        4  68.593016\n",
      "747     manage        4  68.760635\n",
      "748         it        4  69.129919\n",
      "\n",
      "[214 rows x 3 columns]\n",
      "wOnset_datapoints_ndarray= [ 39.8385787  68.9427631  84.0937631 112.6349631 154.2891631 177.2879631\n",
      " 184.4716631 225.1791631 234.7573631 248.5197631 312.5805631 335.3288631\n",
      " 347.3015631 380.8254631 399.0834631] <class 'numpy.ndarray'>\n",
      "tape_start_datapoints_npINT64= 7361\n",
      "abs_wOnsets_dta_ndarray= [7400.8385787 7429.9427631 7445.0937631 7473.6349631 7515.2891631\n",
      " 7538.2879631 7545.4716631 7586.1791631 7595.7573631 7609.5197631\n",
      " 7673.5805631 7696.3288631 7708.3015631 7741.8254631 7760.0834631]\n",
      "rounded_abs_wOnsets_dta_ndarray= [7400 7429 7445 7473 7515 7538 7545 7586 7595 7609 7673 7696 7708 7741\n",
      " 7760]\n",
      "[[ 7400     0     4]\n",
      " [ 7429     0     4]\n",
      " [ 7445     0     4]\n",
      " [ 7473     0     4]\n",
      " [ 7515     0     4]\n",
      " [ 7538     0     4]\n",
      " [ 7545     0     4]\n",
      " [ 7586     0     4]\n",
      " [ 7595     0     4]\n",
      " [ 7609     0     4]\n",
      " [ 7673     0     4]\n",
      " [ 7696     0     4]\n",
      " [ 7708     0     4]\n",
      " [ 7741     0     4]\n",
      " [ 7760     0     4]\n",
      " [ 7776     0     4]\n",
      " [ 7824     0     4]\n",
      " [ 7868     0     4]\n",
      " [ 7907     0     4]\n",
      " [ 7951     0     4]\n",
      " [ 7987     0     4]\n",
      " [ 7995     0     4]\n",
      " [ 8078     0     4]\n",
      " [ 8086     0     4]\n",
      " [ 8099     0     4]\n",
      " [ 8130     0     4]\n",
      " [ 8170     0     4]\n",
      " [ 8186     0     4]\n",
      " [ 8207     0     4]\n",
      " [ 8247     0     4]\n",
      " [ 8282     0     4]\n",
      " [ 8294     0     4]\n",
      " [ 8317     0     4]\n",
      " [ 8340     0     4]\n",
      " [ 8353     0     4]\n",
      " [ 8369     0     4]\n",
      " [ 8412     0     4]\n",
      " [ 8421     0     4]\n",
      " [ 8433     0     4]\n",
      " [ 8472     0     4]\n",
      " [ 8535     0     4]\n",
      " [ 8556     0     4]\n",
      " [ 8567     0     4]\n",
      " [ 8589     0     4]\n",
      " [ 8605     0     4]\n",
      " [ 8625     0     4]\n",
      " [ 8636     0     4]\n",
      " [ 8685     0     4]\n",
      " [ 8708     0     4]\n",
      " [ 8784     0     4]\n",
      " [ 8802     0     4]\n",
      " [ 8846     0     4]\n",
      " [ 8872     0     4]\n",
      " [ 8880     0     4]\n",
      " [ 8936     0     4]\n",
      " [ 8954     0     4]\n",
      " [ 8970     0     4]\n",
      " [ 8988     0     4]\n",
      " [ 9004     0     4]\n",
      " [ 9019     0     4]\n",
      " [ 9038     0     4]\n",
      " [ 9069     0     4]\n",
      " [ 9089     0     4]\n",
      " [ 9161     0     4]\n",
      " [ 9192     0     4]\n",
      " [ 9203     0     4]\n",
      " [ 9222     0     4]\n",
      " [ 9240     0     4]\n",
      " [ 9292     0     4]\n",
      " [ 9299     0     4]\n",
      " [ 9328     0     4]\n",
      " [ 9339     0     4]\n",
      " [ 9424     0     4]\n",
      " [ 9473     0     4]\n",
      " [ 9497     0     4]\n",
      " [ 9504     0     4]\n",
      " [ 9532     0     4]\n",
      " [ 9542     0     4]\n",
      " [ 9572     0     4]\n",
      " [ 9679     0     4]\n",
      " [ 9695     0     4]\n",
      " [ 9712     0     4]\n",
      " [ 9726     0     4]\n",
      " [ 9761     0     4]\n",
      " [ 9778     0     4]\n",
      " [ 9843     0     4]\n",
      " [ 9855     0     4]\n",
      " [ 9918     0     4]\n",
      " [ 9931     0     4]\n",
      " [ 9938     0     4]\n",
      " [ 9972     0     4]\n",
      " [10077     0     4]\n",
      " [10120     0     4]\n",
      " [10161     0     4]\n",
      " [10196     0     4]\n",
      " [10229     0     4]\n",
      " [10245     0     4]\n",
      " [10301     0     4]\n",
      " [10378     0     4]\n",
      " [10392     0     4]\n",
      " [10450     0     4]\n",
      " [10554     0     4]\n",
      " [10569     0     4]\n",
      " [10592     0     4]\n",
      " [10604     0     4]\n",
      " [10616     0     4]\n",
      " [10650     0     4]\n",
      " [10688     0     4]\n",
      " [10731     0     4]\n",
      " [10742     0     4]\n",
      " [10877     0     4]\n",
      " [10922     0     4]\n",
      " [10946     0     4]\n",
      " [10987     0     4]\n",
      " [11120     0     4]\n",
      " [11134     0     4]\n",
      " [11173     0     4]\n",
      " [11185     0     4]\n",
      " [11201     0     4]\n",
      " [11240     0     4]\n",
      " [11272     0     4]\n",
      " [11296     0     4]\n",
      " [11349     0     4]\n",
      " [11368     0     4]\n",
      " [11465     0     4]\n",
      " [11501     0     4]\n",
      " [11530     0     4]\n",
      " [11541     0     4]\n",
      " [11553     0     4]\n",
      " [11585     0     4]\n",
      " [11594     0     4]\n",
      " [11618     0     4]\n",
      " [11633     0     4]\n",
      " [11665     0     4]\n",
      " [11676     0     4]\n",
      " [11727     0     4]\n",
      " [11744     0     4]\n",
      " [11771     0     4]\n",
      " [11786     0     4]\n",
      " [11802     0     4]\n",
      " [11842     0     4]\n",
      " [11971     0     4]\n",
      " [11986     0     4]\n",
      " [12085     0     4]\n",
      " [12117     0     4]\n",
      " [12256     0     4]\n",
      " [12271     0     4]\n",
      " [12296     0     4]\n",
      " [12330     0     4]\n",
      " [12357     0     4]\n",
      " [12370     0     4]\n",
      " [12405     0     4]\n",
      " [12417     0     4]\n",
      " [12437     0     4]\n",
      " [12485     0     4]\n",
      " [12506     0     4]\n",
      " [12553     0     4]\n",
      " [12567     0     4]\n",
      " [12581     0     4]\n",
      " [12598     0     4]\n",
      " [12609     0     4]\n",
      " [12648     0     4]\n",
      " [12658     0     4]\n",
      " [12682     0     4]\n",
      " [12694     0     4]\n",
      " [12722     0     4]\n",
      " [12878     0     4]\n",
      " [12884     0     4]\n",
      " [12901     0     4]\n",
      " [12921     0     4]\n",
      " [12938     0     4]\n",
      " [12953     0     4]\n",
      " [12982     0     4]\n",
      " [12999     0     4]\n",
      " [13018     0     4]\n",
      " [13034     0     4]\n",
      " [13057     0     4]\n",
      " [13064     0     4]\n",
      " [13072     0     4]\n",
      " [13121     0     4]\n",
      " [13147     0     4]\n",
      " [13160     0     4]\n",
      " [13264     0     4]\n",
      " [13298     0     4]\n",
      " [13364     0     4]\n",
      " [13388     0     4]\n",
      " [13412     0     4]\n",
      " [13423     0     4]\n",
      " [13484     0     4]\n",
      " [13501     0     4]\n",
      " [13683     0     4]\n",
      " [13689     0     4]\n",
      " [13707     0     4]\n",
      " [13735     0     4]\n",
      " [13741     0     4]\n",
      " [13793     0     4]\n",
      " [13802     0     4]\n",
      " [13817     0     4]\n",
      " [13897     0     4]\n",
      " [13940     0     4]\n",
      " [14012     0     4]\n",
      " [14026     0     4]\n",
      " [14034     0     4]\n",
      " [14046     0     4]\n",
      " [14086     0     4]\n",
      " [14105     0     4]\n",
      " [14126     0     4]\n",
      " [14164     0     4]\n",
      " [14176     0     4]\n",
      " [14187     0     4]\n",
      " [14204     0     4]\n",
      " [14220     0     4]\n",
      " [14237     0     4]\n",
      " [14273     0     4]]\n",
      "<Epochs |  211 events (all good), -0.3 – 1.2 s, baseline off, ~13.9 MB, data loaded,\n",
      " '4': 211>\n",
      "tape_num= 5\n",
      "wOnset_perTape_DF=           Word  Segment      onset\n",
      "749        And        5   0.561146\n",
      "750       what        5   0.689847\n",
      "751         an        5   0.936113\n",
      "752   ignorant        5   1.115705\n",
      "753     little        5   1.618562\n",
      "..         ...      ...        ...\n",
      "937     saying        5  64.085883\n",
      "938         to        5  64.547542\n",
      "939        her        5  64.691215\n",
      "940       very        5  64.858834\n",
      "941  earnestly        5  65.313800\n",
      "\n",
      "[193 rows x 3 columns]\n",
      "wOnset_datapoints_ndarray= [ 56.1145631  68.9847173  93.6113173 111.5705173 161.8562173 185.8018173\n",
      " 210.7547173 222.0976173 231.2984173 252.8494173 264.8222173 284.7481173\n",
      " 410.8902173 452.7950173 466.6011173] <class 'numpy.ndarray'>\n",
      "tape_start_datapoints_npINT64= 7381\n",
      "abs_wOnsets_dta_ndarray= [7437.1145631 7449.9847173 7474.6113173 7492.5705173 7542.8562173\n",
      " 7566.8018173 7591.7547173 7603.0976173 7612.2984173 7633.8494173\n",
      " 7645.8222173 7665.7481173 7791.8902173 7833.7950173 7847.6011173]\n",
      "rounded_abs_wOnsets_dta_ndarray= [7437 7449 7474 7492 7542 7566 7591 7603 7612 7633 7645 7665 7791 7833\n",
      " 7847]\n",
      "[[ 7437     0     5]\n",
      " [ 7449     0     5]\n",
      " [ 7474     0     5]\n",
      " [ 7492     0     5]\n",
      " [ 7542     0     5]\n",
      " [ 7566     0     5]\n",
      " [ 7591     0     5]\n",
      " [ 7603     0     5]\n",
      " [ 7612     0     5]\n",
      " [ 7633     0     5]\n",
      " [ 7645     0     5]\n",
      " [ 7665     0     5]\n",
      " [ 7791     0     5]\n",
      " [ 7833     0     5]\n",
      " [ 7847     0     5]\n",
      " [ 7861     0     5]\n",
      " [ 7893     0     5]\n",
      " [ 7907     0     5]\n",
      " [ 7918     0     5]\n",
      " [ 8019     0     5]\n",
      " [ 8064     0     5]\n",
      " [ 8072     0     5]\n",
      " [ 8092     0     5]\n",
      " [ 8111     0     5]\n",
      " [ 8124     0     5]\n",
      " [ 8151     0     5]\n",
      " [ 8168     0     5]\n",
      " [ 8347     0     5]\n",
      " [ 8407     0     5]\n",
      " [ 8462     0     5]\n",
      " [ 8579     0     5]\n",
      " [ 8596     0     5]\n",
      " [ 8613     0     5]\n",
      " [ 8652     0     5]\n",
      " [ 8682     0     5]\n",
      " [ 8694     0     5]\n",
      " [ 8726     0     5]\n",
      " [ 8747     0     5]\n",
      " [ 8789     0     5]\n",
      " [ 8813     0     5]\n",
      " [ 8845     0     5]\n",
      " [ 8900     0     5]\n",
      " [ 9060     0     5]\n",
      " [ 9093     0     5]\n",
      " [ 9112     0     5]\n",
      " [ 9145     0     5]\n",
      " [ 9161     0     5]\n",
      " [ 9199     0     5]\n",
      " [ 9237     0     5]\n",
      " [ 9273     0     5]\n",
      " [ 9281     0     5]\n",
      " [ 9312     0     5]\n",
      " [ 9471     0     5]\n",
      " [ 9506     0     5]\n",
      " [ 9529     0     5]\n",
      " [ 9540     0     5]\n",
      " [ 9693     0     5]\n",
      " [ 9703     0     5]\n",
      " [ 9726     0     5]\n",
      " [ 9737     0     5]\n",
      " [ 9745     0     5]\n",
      " [ 9785     0     5]\n",
      " [ 9796     0     5]\n",
      " [ 9842     0     5]\n",
      " [ 9854     0     5]\n",
      " [ 9888     0     5]\n",
      " [ 9899     0     5]\n",
      " [ 9929     0     5]\n",
      " [10057     0     5]\n",
      " [10090     0     5]\n",
      " [10107     0     5]\n",
      " [10132     0     5]\n",
      " [10140     0     5]\n",
      " [10173     0     5]\n",
      " [10184     0     5]\n",
      " [10194     0     5]\n",
      " [10228     0     5]\n",
      " [10247     0     5]\n",
      " [10282     0     5]\n",
      " [10370     0     5]\n",
      " [10387     0     5]\n",
      " [10391     0     5]\n",
      " [10415     0     5]\n",
      " [10454     0     5]\n",
      " [10463     0     5]\n",
      " [10478     0     5]\n",
      " [10501     0     5]\n",
      " [10507     0     5]\n",
      " [10515     0     5]\n",
      " [10556     0     5]\n",
      " [10577     0     5]\n",
      " [10587     0     5]\n",
      " [10614     0     5]\n",
      " [10639     0     5]\n",
      " [10646     0     5]\n",
      " [10755     0     5]\n",
      " [10765     0     5]\n",
      " [10781     0     5]\n",
      " [10791     0     5]\n",
      " [10818     0     5]\n",
      " [10850     0     5]\n",
      " [10855     0     5]\n",
      " [10897     0     5]\n",
      " [10906     0     5]\n",
      " [11016     0     5]\n",
      " [11032     0     5]\n",
      " [11043     0     5]\n",
      " [11096     0     5]\n",
      " [11121     0     5]\n",
      " [11160     0     5]\n",
      " [11167     0     5]\n",
      " [11332     0     5]\n",
      " [11352     0     5]\n",
      " [11377     0     5]\n",
      " [11424     0     5]\n",
      " [11463     0     5]\n",
      " [11475     0     5]\n",
      " [11496     0     5]\n",
      " [11521     0     5]\n",
      " [11619     0     5]\n",
      " [11636     0     5]\n",
      " [11662     0     5]\n",
      " [11681     0     5]\n",
      " [11723     0     5]\n",
      " [11739     0     5]\n",
      " [11794     0     5]\n",
      " [11802     0     5]\n",
      " [11808     0     5]\n",
      " [11845     0     5]\n",
      " [11872     0     5]\n",
      " [11890     0     5]\n",
      " [11972     0     5]\n",
      " [11987     0     5]\n",
      " [12029     0     5]\n",
      " [12049     0     5]\n",
      " [12135     0     5]\n",
      " [12147     0     5]\n",
      " [12188     0     5]\n",
      " [12211     0     5]\n",
      " [12294     0     5]\n",
      " [12310     0     5]\n",
      " [12388     0     5]\n",
      " [12403     0     5]\n",
      " [12435     0     5]\n",
      " [12453     0     5]\n",
      " [12575     0     5]\n",
      " [12587     0     5]\n",
      " [12596     0     5]\n",
      " [12636     0     5]\n",
      " [12649     0     5]\n",
      " [12667     0     5]\n",
      " [12687     0     5]\n",
      " [12701     0     5]\n",
      " [12749     0     5]\n",
      " [12786     0     5]\n",
      " [12870     0     5]\n",
      " [12888     0     5]\n",
      " [12908     0     5]\n",
      " [12921     0     5]\n",
      " [12942     0     5]\n",
      " [12978     0     5]\n",
      " [13000     0     5]\n",
      " [13014     0     5]\n",
      " [13035     0     5]\n",
      " [13061     0     5]\n",
      " [13174     0     5]\n",
      " [13194     0     5]\n",
      " [13216     0     5]\n",
      " [13231     0     5]\n",
      " [13252     0     5]\n",
      " [13274     0     5]\n",
      " [13317     0     5]\n",
      " [13349     0     5]\n",
      " [13366     0     5]\n",
      " [13384     0     5]\n",
      " [13422     0     5]\n",
      " [13462     0     5]\n",
      " [13472     0     5]\n",
      " [13507     0     5]\n",
      " [13519     0     5]\n",
      " [13540     0     5]\n",
      " [13556     0     5]\n",
      " [13598     0     5]\n",
      " [13632     0     5]\n",
      " [13645     0     5]\n",
      " [13676     0     5]\n",
      " [13694     0     5]\n",
      " [13775     0     5]\n",
      " [13789     0     5]\n",
      " [13835     0     5]\n",
      " [13850     0     5]\n",
      " [13866     0     5]\n",
      " [13912     0     5]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/dt/yj00f34n5x52_p314tnwfjkw0000gn/T/ipykernel_30538/1641304678.py:107: RuntimeWarning: Concatenation of Annotations within Epochs is not supported yet. All annotations will be dropped.\n",
      "  wOnset_epochs = mne.concatenate_epochs(all_tapes_epochs_LIST)\n",
      "/var/folders/dt/yj00f34n5x52_p314tnwfjkw0000gn/T/ipykernel_30538/1641304678.py:107: RuntimeWarning: Concatenation of Annotations within Epochs is not supported yet. All annotations will be dropped.\n",
      "  wOnset_epochs = mne.concatenate_epochs(all_tapes_epochs_LIST)\n",
      "/var/folders/dt/yj00f34n5x52_p314tnwfjkw0000gn/T/ipykernel_30538/1641304678.py:107: RuntimeWarning: Concatenation of Annotations within Epochs is not supported yet. All annotations will be dropped.\n",
      "  wOnset_epochs = mne.concatenate_epochs(all_tapes_epochs_LIST)\n",
      "/var/folders/dt/yj00f34n5x52_p314tnwfjkw0000gn/T/ipykernel_30538/1641304678.py:107: RuntimeWarning: Concatenation of Annotations within Epochs is not supported yet. All annotations will be dropped.\n",
      "  wOnset_epochs = mne.concatenate_epochs(all_tapes_epochs_LIST)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Epochs |  186 events (all good), -0.3 – 1.2 s, baseline off, ~12.3 MB, data loaded,\n",
      " '5': 186>\n",
      "tape_num= 6\n",
      "wOnset_perTape_DF=        Word  Segment      onset\n",
      "942     Now        6   0.323245\n",
      "943   Dinah        6   0.568709\n",
      "944    tell        6   1.039809\n",
      "945      me        6   1.422938\n",
      "946     the        6   1.590557\n",
      "...     ...      ...        ...\n",
      "1134   ever        6  61.825659\n",
      "1135     to        6  62.101034\n",
      "1136    get        6  62.268653\n",
      "1137    out        6  62.436272\n",
      "1138  again        6  62.663755\n",
      "\n",
      "[197 rows x 3 columns]\n",
      "wOnset_datapoints_ndarray= [ 32.3245298  56.8708743 103.9808743 142.2937743 159.0556743 173.0401743\n",
      " 238.0761743 260.0501743 284.7699743 320.6883743 337.9041743 353.4880743\n",
      " 473.9400743 496.7131743 597.2597743] <class 'numpy.ndarray'>\n",
      "tape_start_datapoints_npINT64= 13482\n",
      "abs_wOnsets_dta_ndarray= [13514.3245298 13538.8708743 13585.9808743 13624.2937743 13641.0556743\n",
      " 13655.0401743 13720.0761743 13742.0501743 13766.7699743 13802.6883743\n",
      " 13819.9041743 13835.4880743 13955.9400743 13978.7131743 14079.2597743]\n",
      "rounded_abs_wOnsets_dta_ndarray= [13514 13538 13585 13624 13641 13655 13720 13742 13766 13802 13819 13835\n",
      " 13955 13978 14079]\n",
      "[[13514     0     6]\n",
      " [13538     0     6]\n",
      " [13585     0     6]\n",
      " [13624     0     6]\n",
      " [13641     0     6]\n",
      " [13655     0     6]\n",
      " [13720     0     6]\n",
      " [13742     0     6]\n",
      " [13766     0     6]\n",
      " [13802     0     6]\n",
      " [13819     0     6]\n",
      " [13835     0     6]\n",
      " [13955     0     6]\n",
      " [13978     0     6]\n",
      " [14079     0     6]\n",
      " [14155     0     6]\n",
      " [14204     0     6]\n",
      " [14234     0     6]\n",
      " [14257     0     6]\n",
      " [14303     0     6]\n",
      " [14338     0     6]\n",
      " [14347     0     6]\n",
      " [14373     0     6]\n",
      " [14383     0     6]\n",
      " [14428     0     6]\n",
      " [14443     0     6]\n",
      " [14465     0     6]\n",
      " [14572     0     6]\n",
      " [14589     0     6]\n",
      " [14596     0     6]\n",
      " [14630     0     6]\n",
      " [14649     0     6]\n",
      " [14810     0     6]\n",
      " [14850     0     6]\n",
      " [14867     0     6]\n",
      " [14887     0     6]\n",
      " [14895     0     6]\n",
      " [14917     0     6]\n",
      " [14986     0     6]\n",
      " [15002     0     6]\n",
      " [15019     0     6]\n",
      " [15055     0     6]\n",
      " [15075     0     6]\n",
      " [15089     0     6]\n",
      " [15104     0     6]\n",
      " [15137     0     6]\n",
      " [15151     0     6]\n",
      " [15156     0     6]\n",
      " [15287     0     6]\n",
      " [15308     0     6]\n",
      " [15337     0     6]\n",
      " [15369     0     6]\n",
      " [15383     0     6]\n",
      " [15390     0     6]\n",
      " [15404     0     6]\n",
      " [15430     0     6]\n",
      " [15470     0     6]\n",
      " [15577     0     6]\n",
      " [15626     0     6]\n",
      " [15640     0     6]\n",
      " [15665     0     6]\n",
      " [15700     0     6]\n",
      " [15727     0     6]\n",
      " [15823     0     6]\n",
      " [15836     0     6]\n",
      " [15844     0     6]\n",
      " [15872     0     6]\n",
      " [15906     0     6]\n",
      " [15919     0     6]\n",
      " [15956     0     6]\n",
      " [15968     0     6]\n",
      " [16008     0     6]\n",
      " [16061     0     6]\n",
      " [16091     0     6]\n",
      " [16203     0     6]\n",
      " [16218     0     6]\n",
      " [16235     0     6]\n",
      " [16255     0     6]\n",
      " [16261     0     6]\n",
      " [16302     0     6]\n",
      " [16310     0     6]\n",
      " [16322     0     6]\n",
      " [16409     0     6]\n",
      " [16440     0     6]\n",
      " [16463     0     6]\n",
      " [16504     0     6]\n",
      " [16521     0     6]\n",
      " [16532     0     6]\n",
      " [16582     0     6]\n",
      " [16600     0     6]\n",
      " [16627     0     6]\n",
      " [16663     0     6]\n",
      " [16674     0     6]\n",
      " [16701     0     6]\n",
      " [16712     0     6]\n",
      " [16734     0     6]\n",
      " [16749     0     6]\n",
      " [16788     0     6]\n",
      " [16804     0     6]\n",
      " [16816     0     6]\n",
      " [16844     0     6]\n",
      " [16852     0     6]\n",
      " [16945     0     6]\n",
      " [16970     0     6]\n",
      " [16987     0     6]\n",
      " [17015     0     6]\n",
      " [17029     0     6]\n",
      " [17090     0     6]\n",
      " [17103     0     6]\n",
      " [17129     0     6]\n",
      " [17141     0     6]\n",
      " [17154     0     6]\n",
      " [17247     0     6]\n",
      " [17267     0     6]\n",
      " [17284     0     6]\n",
      " [17317     0     6]\n",
      " [17359     0     6]\n",
      " [17372     0     6]\n",
      " [17384     0     6]\n",
      " [17404     0     6]\n",
      " [17434     0     6]\n",
      " [17441     0     6]\n",
      " [17517     0     6]\n",
      " [17532     0     6]\n",
      " [17542     0     6]\n",
      " [17580     0     6]\n",
      " [17602     0     6]\n",
      " [17625     0     6]\n",
      " [17657     0     6]\n",
      " [17674     0     6]\n",
      " [17688     0     6]\n",
      " [17783     0     6]\n",
      " [17807     0     6]\n",
      " [17837     0     6]\n",
      " [17887     0     6]\n",
      " [17899     0     6]\n",
      " [17905     0     6]\n",
      " [17954     0     6]\n",
      " [17995     0     6]\n",
      " [18037     0     6]\n",
      " [18069     0     6]\n",
      " [18088     0     6]\n",
      " [18112     0     6]\n",
      " [18151     0     6]\n",
      " [18170     0     6]\n",
      " [18181     0     6]\n",
      " [18208     0     6]\n",
      " [18218     0     6]\n",
      " [18261     0     6]\n",
      " [18291     0     6]\n",
      " [18312     0     6]\n",
      " [18326     0     6]\n",
      " [18443     0     6]\n",
      " [18461     0     6]\n",
      " [18473     0     6]\n",
      " [18522     0     6]\n",
      " [18540     0     6]\n",
      " [18573     0     6]\n",
      " [18581     0     6]\n",
      " [18670     0     6]\n",
      " [18687     0     6]\n",
      " [18705     0     6]\n",
      " [18720     0     6]\n",
      " [18743     0     6]\n",
      " [18833     0     6]\n",
      " [18846     0     6]\n",
      " [18867     0     6]\n",
      " [18903     0     6]\n",
      " [18912     0     6]\n",
      " [18928     0     6]\n",
      " [18953     0     6]\n",
      " [18961     0     6]\n",
      " [18977     0     6]\n",
      " [19006     0     6]\n",
      " [19028     0     6]\n",
      " [19068     0     6]\n",
      " [19076     0     6]\n",
      " [19099     0     6]\n",
      " [19114     0     6]\n",
      " [19143     0     6]\n",
      " [19186     0     6]\n",
      " [19222     0     6]\n",
      " [19316     0     6]\n",
      " [19336     0     6]\n",
      " [19367     0     6]\n",
      " [19423     0     6]\n",
      " [19452     0     6]\n",
      " [19459     0     6]\n",
      " [19546     0     6]\n",
      " [19601     0     6]\n",
      " [19620     0     6]\n",
      " [19638     0     6]\n",
      " [19664     0     6]\n",
      " [19692     0     6]\n",
      " [19708     0     6]\n",
      " [19725     0     6]\n",
      " [19748     0     6]]\n",
      "<Epochs |  195 events (all good), -0.3 – 1.2 s, baseline off, ~12.9 MB, data loaded,\n",
      " '6': 195>\n",
      "tape_num= 7\n",
      "wOnset_perTape_DF=           Word  Segment      onset\n",
      "1139  Suddenly        7   0.586736\n",
      "1140       she        7   1.179532\n",
      "1141      came        7   1.418988\n",
      "1142      upon        7   1.694362\n",
      "1143         a        7   2.051148\n",
      "...        ...      ...        ...\n",
      "1312       her        7  61.175179\n",
      "1313      head        7  61.294906\n",
      "1314    though        7  61.675837\n",
      "1315       the        7  61.845655\n",
      "1316   doorway        7  61.965383\n",
      "\n",
      "[178 rows x 3 columns]\n",
      "wOnset_datapoints_ndarray= [ 58.6736359 117.9532195 141.8988195 169.4362195 205.1148195 230.4974195\n",
      " 274.7968195 299.9396195 337.0553195 425.6539195 446.0076195 471.1505195\n",
      " 479.5315195 527.4226195 650.7423195] <class 'numpy.ndarray'>\n",
      "tape_start_datapoints_npINT64= 13553\n",
      "abs_wOnsets_dta_ndarray= [13611.6736359 13670.9532195 13694.8988195 13722.4362195 13758.1148195\n",
      " 13783.4974195 13827.7968195 13852.9396195 13890.0553195 13978.6539195\n",
      " 13999.0076195 14024.1505195 14032.5315195 14080.4226195 14203.7423195]\n",
      "rounded_abs_wOnsets_dta_ndarray= [13611 13670 13694 13722 13758 13783 13827 13852 13890 13978 13999 14024\n",
      " 14032 14080 14203]\n",
      "[[13611     0     7]\n",
      " [13670     0     7]\n",
      " [13694     0     7]\n",
      " [13722     0     7]\n",
      " [13758     0     7]\n",
      " [13783     0     7]\n",
      " [13827     0     7]\n",
      " [13852     0     7]\n",
      " [13890     0     7]\n",
      " [13978     0     7]\n",
      " [13999     0     7]\n",
      " [14024     0     7]\n",
      " [14032     0     7]\n",
      " [14080     0     7]\n",
      " [14203     0     7]\n",
      " [14216     0     7]\n",
      " [14233     0     7]\n",
      " [14273     0     7]\n",
      " [14297     0     7]\n",
      " [14319     0     7]\n",
      " [14350     0     7]\n",
      " [14359     0     7]\n",
      " [14402     0     7]\n",
      " [14446     0     7]\n",
      " [14536     0     7]\n",
      " [14556     0     7]\n",
      " [14609     0     7]\n",
      " [14655     0     7]\n",
      " [14713     0     7]\n",
      " [14728     0     7]\n",
      " [14745     0     7]\n",
      " [14758     0     7]\n",
      " [14783     0     7]\n",
      " [14822     0     7]\n",
      " [14839     0     7]\n",
      " [14856     0     7]\n",
      " [14865     0     7]\n",
      " [14873     0     7]\n",
      " [14908     0     7]\n",
      " [14918     0     7]\n",
      " [14928     0     7]\n",
      " [15069     0     7]\n",
      " [15082     0     7]\n",
      " [15140     0     7]\n",
      " [15174     0     7]\n",
      " [15185     0     7]\n",
      " [15232     0     7]\n",
      " [15245     0     7]\n",
      " [15266     0     7]\n",
      " [15303     0     7]\n",
      " [15312     0     7]\n",
      " [15322     0     7]\n",
      " [15349     0     7]\n",
      " [15371     0     7]\n",
      " [15386     0     7]\n",
      " [15482     0     7]\n",
      " [15496     0     7]\n",
      " [15510     0     7]\n",
      " [15541     0     7]\n",
      " [15567     0     7]\n",
      " [15578     0     7]\n",
      " [15593     0     7]\n",
      " [15613     0     7]\n",
      " [15645     0     7]\n",
      " [15672     0     7]\n",
      " [15685     0     7]\n",
      " [15795     0     7]\n",
      " [15851     0     7]\n",
      " [15866     0     7]\n",
      " [15875     0     7]\n",
      " [15918     0     7]\n",
      " [15950     0     7]\n",
      " [15986     0     7]\n",
      " [16009     0     7]\n",
      " [16039     0     7]\n",
      " [16075     0     7]\n",
      " [16085     0     7]\n",
      " [16116     0     7]\n",
      " [16170     0     7]\n",
      " [16193     0     7]\n",
      " [16217     0     7]\n",
      " [16236     0     7]\n",
      " [16279     0     7]\n",
      " [16385     0     7]\n",
      " [16405     0     7]\n",
      " [16450     0     7]\n",
      " [16467     0     7]\n",
      " [16481     0     7]\n",
      " [16490     0     7]\n",
      " [16524     0     7]\n",
      " [16576     0     7]\n",
      " [16610     0     7]\n",
      " [16661     0     7]\n",
      " [16700     0     7]\n",
      " [16810     0     7]\n",
      " [16830     0     7]\n",
      " [16868     0     7]\n",
      " [16877     0     7]\n",
      " [16909     0     7]\n",
      " [16947     0     7]\n",
      " [16973     0     7]\n",
      " [16985     0     7]\n",
      " [16992     0     7]\n",
      " [17059     0     7]\n",
      " [17077     0     7]\n",
      " [17090     0     7]\n",
      " [17108     0     7]\n",
      " [17168     0     7]\n",
      " [17213     0     7]\n",
      " [17234     0     7]\n",
      " [17436     0     7]\n",
      " [17481     0     7]\n",
      " [17524     0     7]\n",
      " [17533     0     7]\n",
      " [17584     0     7]\n",
      " [17608     0     7]\n",
      " [17636     0     7]\n",
      " [17646     0     7]\n",
      " [17672     0     7]\n",
      " [17707     0     7]\n",
      " [17712     0     7]\n",
      " [17757     0     7]\n",
      " [17894     0     7]\n",
      " [17917     0     7]\n",
      " [17944     0     7]\n",
      " [17978     0     7]\n",
      " [17995     0     7]\n",
      " [18006     0     7]\n",
      " [18038     0     7]\n",
      " [18142     0     7]\n",
      " [18166     0     7]\n",
      " [18203     0     7]\n",
      " [18249     0     7]\n",
      " [18266     0     7]\n",
      " [18293     0     7]\n",
      " [18321     0     7]\n",
      " [18328     0     7]\n",
      " [18418     0     7]\n",
      " [18448     0     7]\n",
      " [18465     0     7]\n",
      " [18551     0     7]\n",
      " [18586     0     7]\n",
      " [18610     0     7]\n",
      " [18639     0     7]\n",
      " [18773     0     7]\n",
      " [18788     0     7]\n",
      " [18811     0     7]\n",
      " [18858     0     7]\n",
      " [18868     0     7]\n",
      " [18887     0     7]\n",
      " [18903     0     7]\n",
      " [18915     0     7]\n",
      " [18932     0     7]\n",
      " [18972     0     7]\n",
      " [19019     0     7]\n",
      " [19037     0     7]\n",
      " [19080     0     7]\n",
      " [19120     0     7]\n",
      " [19154     0     7]\n",
      " [19185     0     7]\n",
      " [19221     0     7]\n",
      " [19235     0     7]\n",
      " [19270     0     7]\n",
      " [19332     0     7]\n",
      " [19343     0     7]\n",
      " [19375     0     7]\n",
      " [19404     0     7]\n",
      " [19551     0     7]\n",
      " [19565     0     7]\n",
      " [19583     0     7]\n",
      " [19608     0     7]\n",
      " [19627     0     7]\n",
      " [19654     0     7]\n",
      " [19670     0     7]\n",
      " [19682     0     7]\n",
      " [19720     0     7]\n",
      " [19737     0     7]\n",
      " [19749     0     7]]\n",
      "<Epochs |  178 events (all good), -0.3 – 1.2 s, baseline off, ~11.8 MB, data loaded,\n",
      " '7': 178>\n",
      "tape_num= 8\n",
      "wOnset_perTape_DF=        Word  Segment      onset\n",
      "1317    and        8   0.342000\n",
      "1318   even        8   0.453317\n",
      "1319     if        8   0.696699\n",
      "1320     my        8   0.960100\n",
      "1321   head        8   1.067855\n",
      "...     ...      ...        ...\n",
      "1487     do        8  55.663774\n",
      "1488   that        8  55.855338\n",
      "1489     in        8  56.190576\n",
      "1490      a        8  56.366154\n",
      "1491  hurry        8  56.444074\n",
      "\n",
      "[175 rows x 3 columns]\n",
      "wOnset_datapoints_ndarray= [ 34.2        45.3316684  69.6698684  96.0099684 106.7854684 139.1120684\n",
      " 158.2684684 178.5899684 250.4589684 277.9963684 304.3431684 420.4725684\n",
      " 428.9338684 448.0099684 467.1664684] <class 'numpy.ndarray'>\n",
      "tape_start_datapoints_npINT64= 19954\n",
      "abs_wOnsets_dta_ndarray= [19988.2       19999.3316684 20023.6698684 20050.0099684 20060.7854684\n",
      " 20093.1120684 20112.2684684 20132.5899684 20204.4589684 20231.9963684\n",
      " 20258.3431684 20374.4725684 20382.9338684 20402.0099684 20421.1664684]\n",
      "rounded_abs_wOnsets_dta_ndarray= [19988 19999 20023 20050 20060 20093 20112 20132 20204 20231 20258 20374\n",
      " 20382 20402 20421]\n",
      "[[19988     0     8]\n",
      " [19999     0     8]\n",
      " [20023     0     8]\n",
      " [20050     0     8]\n",
      " [20060     0     8]\n",
      " [20093     0     8]\n",
      " [20112     0     8]\n",
      " [20132     0     8]\n",
      " [20204     0     8]\n",
      " [20231     0     8]\n",
      " [20258     0     8]\n",
      " [20374     0     8]\n",
      " [20382     0     8]\n",
      " [20402     0     8]\n",
      " [20421     0     8]\n",
      " [20437     0     8]\n",
      " [20481     0     8]\n",
      " [20516     0     8]\n",
      " [20546     0     8]\n",
      " [20578     0     8]\n",
      " [20585     0     8]\n",
      " [20708     0     8]\n",
      " [20721     0     8]\n",
      " [20739     0     8]\n",
      " [20750     0     8]\n",
      " [20779     0     8]\n",
      " [20787     0     8]\n",
      " [20802     0     8]\n",
      " [20832     0     8]\n",
      " [20849     0     8]\n",
      " [20862     0     8]\n",
      " [20867     0     8]\n",
      " [21007     0     8]\n",
      " [21018     0     8]\n",
      " [21050     0     8]\n",
      " [21064     0     8]\n",
      " [21128     0     8]\n",
      " [21148     0     8]\n",
      " [21163     0     8]\n",
      " [21194     0     8]\n",
      " [21211     0     8]\n",
      " [21229     0     8]\n",
      " [21244     0     8]\n",
      " [21394     0     8]\n",
      " [21411     0     8]\n",
      " [21424     0     8]\n",
      " [21483     0     8]\n",
      " [21514     0     8]\n",
      " [21547     0     8]\n",
      " [21563     0     8]\n",
      " [21577     0     8]\n",
      " [21587     0     8]\n",
      " [21612     0     8]\n",
      " [21645     0     8]\n",
      " [21657     0     8]\n",
      " [21708     0     8]\n",
      " [21790     0     8]\n",
      " [21803     0     8]\n",
      " [21844     0     8]\n",
      " [21857     0     8]\n",
      " [21895     0     8]\n",
      " [21902     0     8]\n",
      " [21930     0     8]\n",
      " [21946     0     8]\n",
      " [21978     0     8]\n",
      " [22009     0     8]\n",
      " [22047     0     8]\n",
      " [22098     0     8]\n",
      " [22112     0     8]\n",
      " [22151     0     8]\n",
      " [22332     0     8]\n",
      " [22354     0     8]\n",
      " [22394     0     8]\n",
      " [22401     0     8]\n",
      " [22418     0     8]\n",
      " [22434     0     8]\n",
      " [22473     0     8]\n",
      " [22487     0     8]\n",
      " [22521     0     8]\n",
      " [22540     0     8]\n",
      " [22552     0     8]\n",
      " [22581     0     8]\n",
      " [22658     0     8]\n",
      " [22670     0     8]\n",
      " [22688     0     8]\n",
      " [22713     0     8]\n",
      " [22741     0     8]\n",
      " [22751     0     8]\n",
      " [22761     0     8]\n",
      " [22845     0     8]\n",
      " [22869     0     8]\n",
      " [22906     0     8]\n",
      " [22924     0     8]\n",
      " [22951     0     8]\n",
      " [22977     0     8]\n",
      " [23014     0     8]\n",
      " [23041     0     8]\n",
      " [23061     0     8]\n",
      " [23110     0     8]\n",
      " [23130     0     8]\n",
      " [23138     0     8]\n",
      " [23168     0     8]\n",
      " [23200     0     8]\n",
      " [23209     0     8]\n",
      " [23233     0     8]\n",
      " [23249     0     8]\n",
      " [23291     0     8]\n",
      " [23300     0     8]\n",
      " [23342     0     8]\n",
      " [23378     0     8]\n",
      " [23396     0     8]\n",
      " [23416     0     8]\n",
      " [23604     0     8]\n",
      " [23632     0     8]\n",
      " [23672     0     8]\n",
      " [23692     0     8]\n",
      " [23723     0     8]\n",
      " [23736     0     8]\n",
      " [23774     0     8]\n",
      " [23817     0     8]\n",
      " [23838     0     8]\n",
      " [23943     0     8]\n",
      " [23959     0     8]\n",
      " [24021     0     8]\n",
      " [24043     0     8]\n",
      " [24092     0     8]\n",
      " [24118     0     8]\n",
      " [24202     0     8]\n",
      " [24223     0     8]\n",
      " [24319     0     8]\n",
      " [24332     0     8]\n",
      " [24356     0     8]\n",
      " [24363     0     8]\n",
      " [24391     0     8]\n",
      " [24404     0     8]\n",
      " [24414     0     8]\n",
      " [24452     0     8]\n",
      " [24468     0     8]\n",
      " [24473     0     8]\n",
      " [24515     0     8]\n",
      " [24575     0     8]\n",
      " [24591     0     8]\n",
      " [24600     0     8]\n",
      " [24663     0     8]\n",
      " [24701     0     8]\n",
      " [24767     0     8]\n",
      " [24835     0     8]\n",
      " [24873     0     8]\n",
      " [24895     0     8]\n",
      " [24904     0     8]\n",
      " [24922     0     8]\n",
      " [24963     0     8]\n",
      " [25059     0     8]\n",
      " [25079     0     8]\n",
      " [25096     0     8]\n",
      " [25125     0     8]\n",
      " [25161     0     8]\n",
      " [25186     0     8]\n",
      " [25192     0     8]\n",
      " [25221     0     8]\n",
      " [25261     0     8]\n",
      " [25298     0     8]\n",
      " [25312     0     8]\n",
      " [25322     0     8]\n",
      " [25374     0     8]\n",
      " [25398     0     8]\n",
      " [25444     0     8]\n",
      " [25460     0     8]\n",
      " [25483     0     8]\n",
      " [25508     0     8]\n",
      " [25520     0     8]\n",
      " [25539     0     8]\n",
      " [25573     0     8]\n",
      " [25590     0     8]\n",
      " [25598     0     8]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/dt/yj00f34n5x52_p314tnwfjkw0000gn/T/ipykernel_30538/1641304678.py:107: RuntimeWarning: Concatenation of Annotations within Epochs is not supported yet. All annotations will be dropped.\n",
      "  wOnset_epochs = mne.concatenate_epochs(all_tapes_epochs_LIST)\n",
      "/var/folders/dt/yj00f34n5x52_p314tnwfjkw0000gn/T/ipykernel_30538/1641304678.py:107: RuntimeWarning: Concatenation of Annotations within Epochs is not supported yet. All annotations will be dropped.\n",
      "  wOnset_epochs = mne.concatenate_epochs(all_tapes_epochs_LIST)\n",
      "/var/folders/dt/yj00f34n5x52_p314tnwfjkw0000gn/T/ipykernel_30538/1641304678.py:107: RuntimeWarning: Concatenation of Annotations within Epochs is not supported yet. All annotations will be dropped.\n",
      "  wOnset_epochs = mne.concatenate_epochs(all_tapes_epochs_LIST)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Epochs |  172 events (all good), -0.3 – 1.2 s, baseline off, ~11.4 MB, data loaded,\n",
      " '8': 172>\n",
      "tape_num= 9\n",
      "wOnset_perTape_DF=           Word  Segment      onset\n",
      "1492        No        9   0.432017\n",
      "1493         I        9   1.046815\n",
      "1494        ll        9   1.198494\n",
      "1495      look        9   1.394026\n",
      "1496     first        9   1.753210\n",
      "...        ...      ...        ...\n",
      "1643      very        9  54.086271\n",
      "1644      soon        9  54.397564\n",
      "1645  finished        9  55.044094\n",
      "1646        it        9  55.423901\n",
      "1647       off        9  55.536451\n",
      "\n",
      "[156 rows x 3 columns]\n",
      "wOnset_datapoints_ndarray= [ 43.2017422 104.6814784 119.8493784 139.4025784 175.3209784 213.3840784\n",
      " 235.1848784 270.9578784 278.9662784 311.8107784 344.1372784 353.1518784\n",
      " 362.0964784 398.0148784 447.0263784] <class 'numpy.ndarray'>\n",
      "tape_start_datapoints_npINT64= 20005\n",
      "abs_wOnsets_dta_ndarray= [20048.2017422 20109.6814784 20124.8493784 20144.4025784 20180.3209784\n",
      " 20218.3840784 20240.1848784 20275.9578784 20283.9662784 20316.8107784\n",
      " 20349.1372784 20358.1518784 20367.0964784 20403.0148784 20452.0263784]\n",
      "rounded_abs_wOnsets_dta_ndarray= [20048 20109 20124 20144 20180 20218 20240 20275 20283 20316 20349 20358\n",
      " 20367 20403 20452]\n",
      "[[20048     0     9]\n",
      " [20109     0     9]\n",
      " [20124     0     9]\n",
      " [20144     0     9]\n",
      " [20180     0     9]\n",
      " [20218     0     9]\n",
      " [20240     0     9]\n",
      " [20275     0     9]\n",
      " [20283     0     9]\n",
      " [20316     0     9]\n",
      " [20349     0     9]\n",
      " [20358     0     9]\n",
      " [20367     0     9]\n",
      " [20403     0     9]\n",
      " [20452     0     9]\n",
      " [20464     0     9]\n",
      " [20553     0     9]\n",
      " [20563     0     9]\n",
      " [20585     0     9]\n",
      " [20604     0     9]\n",
      " [20626     0     9]\n",
      " [20679     0     9]\n",
      " [20711     0     9]\n",
      " [20735     0     9]\n",
      " [20800     0     9]\n",
      " [20831     0     9]\n",
      " [20876     0     9]\n",
      " [20886     0     9]\n",
      " [20892     0     9]\n",
      " [20937     0     9]\n",
      " [21020     0     9]\n",
      " [21037     0     9]\n",
      " [21066     0     9]\n",
      " [21087     0     9]\n",
      " [21105     0     9]\n",
      " [21146     0     9]\n",
      " [21200     0     9]\n",
      " [21208     0     9]\n",
      " [21235     0     9]\n",
      " [21294     0     9]\n",
      " [21375     0     9]\n",
      " [21397     0     9]\n",
      " [21436     0     9]\n",
      " [21453     0     9]\n",
      " [21496     0     9]\n",
      " [21518     0     9]\n",
      " [21563     0     9]\n",
      " [21572     0     9]\n",
      " [21632     0     9]\n",
      " [21675     0     9]\n",
      " [21690     0     9]\n",
      " [21724     0     9]\n",
      " [21735     0     9]\n",
      " [21770     0     9]\n",
      " [21842     0     9]\n",
      " [21875     0     9]\n",
      " [21957     0     9]\n",
      " [21970     0     9]\n",
      " [21978     0     9]\n",
      " [22007     0     9]\n",
      " [22044     0     9]\n",
      " [22082     0     9]\n",
      " [22106     0     9]\n",
      " [22147     0     9]\n",
      " [22165     0     9]\n",
      " [22180     0     9]\n",
      " [22197     0     9]\n",
      " [22223     0     9]\n",
      " [22238     0     9]\n",
      " [22259     0     9]\n",
      " [22328     0     9]\n",
      " [22347     0     9]\n",
      " [22360     0     9]\n",
      " [22372     0     9]\n",
      " [22384     0     9]\n",
      " [22412     0     9]\n",
      " [22426     0     9]\n",
      " [22463     0     9]\n",
      " [22512     0     9]\n",
      " [22554     0     9]\n",
      " [22574     0     9]\n",
      " [22579     0     9]\n",
      " [22617     0     9]\n",
      " [22628     0     9]\n",
      " [22673     0     9]\n",
      " [22792     0     9]\n",
      " [22803     0     9]\n",
      " [22821     0     9]\n",
      " [22833     0     9]\n",
      " [22869     0     9]\n",
      " [22930     0     9]\n",
      " [22950     0     9]\n",
      " [22965     0     9]\n",
      " [22979     0     9]\n",
      " [23019     0     9]\n",
      " [23051     0     9]\n",
      " [23065     0     9]\n",
      " [23071     0     9]\n",
      " [23110     0     9]\n",
      " [23149     0     9]\n",
      " [23239     0     9]\n",
      " [23249     0     9]\n",
      " [23257     0     9]\n",
      " [23302     0     9]\n",
      " [23341     0     9]\n",
      " [23354     0     9]\n",
      " [23409     0     9]\n",
      " [23426     0     9]\n",
      " [23442     0     9]\n",
      " [23483     0     9]\n",
      " [23493     0     9]\n",
      " [23688     0     9]\n",
      " [23732     0     9]\n",
      " [23758     0     9]\n",
      " [23791     0     9]\n",
      " [23810     0     9]\n",
      " [23845     0     9]\n",
      " [23881     0     9]\n",
      " [23956     0     9]\n",
      " [23976     0     9]\n",
      " [24021     0     9]\n",
      " [24057     0     9]\n",
      " [24067     0     9]\n",
      " [24112     0     9]\n",
      " [24170     0     9]\n",
      " [24188     0     9]\n",
      " [24233     0     9]\n",
      " [24253     0     9]\n",
      " [24297     0     9]\n",
      " [24382     0     9]\n",
      " [24397     0     9]\n",
      " [24436     0     9]\n",
      " [24454     0     9]\n",
      " [24510     0     9]\n",
      " [24517     0     9]\n",
      " [24546     0     9]\n",
      " [24564     0     9]\n",
      " [24604     0     9]\n",
      " [24657     0     9]\n",
      " [24674     0     9]\n",
      " [24727     0     9]\n",
      " [24826     0     9]\n",
      " [24902     0     9]\n",
      " [25000     0     9]\n",
      " [25040     0     9]\n",
      " [25089     0     9]\n",
      " [25145     0     9]\n",
      " [25162     0     9]\n",
      " [25188     0     9]\n",
      " [25225     0     9]\n",
      " [25388     0     9]\n",
      " [25413     0     9]\n",
      " [25444     0     9]\n",
      " [25509     0     9]\n",
      " [25547     0     9]\n",
      " [25558     0     9]]\n",
      "<Epochs |  156 events (all good), -0.3 – 1.2 s, baseline off, ~10.3 MB, data loaded,\n",
      " '9': 156>\n",
      "tape_num= 10\n",
      "wOnset_perTape_DF=           Word  Segment      onset\n",
      "1648      What       10   1.051981\n",
      "1649         a       10   1.160767\n",
      "1650   curious       10   1.308375\n",
      "1651   feeling       10   2.146470\n",
      "1652      said       10   2.787119\n",
      "...        ...      ...        ...\n",
      "1830     could       10  59.244701\n",
      "1831       not       10  59.448239\n",
      "1832  possibly       10  59.855313\n",
      "1833     reach       10  60.430007\n",
      "1834        it       10  60.784961\n",
      "\n",
      "[187 rows x 3 columns]\n",
      "wOnset_datapoints_ndarray= [105.1980798 116.0767    130.8375    214.647     278.7119    306.9088\n",
      " 367.0205    381.0893    411.0007    419.3817    460.2269    478.0483\n",
      " 490.7454    500.4853    645.6674   ] <class 'numpy.ndarray'>\n",
      "tape_start_datapoints_npINT64= 20026\n",
      "abs_wOnsets_dta_ndarray= [20131.1980798 20142.0767    20156.8375    20240.647     20304.7119\n",
      " 20332.9088    20393.0205    20407.0893    20437.0007    20445.3817\n",
      " 20486.2269    20504.0483    20516.7454    20526.4853    20671.6674   ]\n",
      "rounded_abs_wOnsets_dta_ndarray= [20131 20142 20156 20240 20304 20332 20393 20407 20437 20445 20486 20504\n",
      " 20516 20526 20671]\n",
      "[[20131     0    10]\n",
      " [20142     0    10]\n",
      " [20156     0    10]\n",
      " [20240     0    10]\n",
      " [20304     0    10]\n",
      " [20332     0    10]\n",
      " [20393     0    10]\n",
      " [20407     0    10]\n",
      " [20437     0    10]\n",
      " [20445     0    10]\n",
      " [20486     0    10]\n",
      " [20504     0    10]\n",
      " [20516     0    10]\n",
      " [20526     0    10]\n",
      " [20671     0    10]\n",
      " [20687     0    10]\n",
      " [20715     0    10]\n",
      " [20726     0    10]\n",
      " [20750     0    10]\n",
      " [20850     0    10]\n",
      " [20865     0    10]\n",
      " [20883     0    10]\n",
      " [20911     0    10]\n",
      " [20933     0    10]\n",
      " [20961     0    10]\n",
      " [20999     0    10]\n",
      " [21063     0    10]\n",
      " [21078     0    10]\n",
      " [21088     0    10]\n",
      " [21130     0    10]\n",
      " [21165     0    10]\n",
      " [21184     0    10]\n",
      " [21194     0    10]\n",
      " [21211     0    10]\n",
      " [21242     0    10]\n",
      " [21259     0    10]\n",
      " [21277     0    10]\n",
      " [21300     0    10]\n",
      " [21322     0    10]\n",
      " [21339     0    10]\n",
      " [21362     0    10]\n",
      " [21403     0    10]\n",
      " [21415     0    10]\n",
      " [21454     0    10]\n",
      " [21477     0    10]\n",
      " [21485     0    10]\n",
      " [21519     0    10]\n",
      " [21563     0    10]\n",
      " [21593     0    10]\n",
      " [21615     0    10]\n",
      " [21647     0    10]\n",
      " [21804     0    10]\n",
      " [21842     0    10]\n",
      " [21877     0    10]\n",
      " [21898     0    10]\n",
      " [21933     0    10]\n",
      " [21962     0    10]\n",
      " [21965     0    10]\n",
      " [21993     0    10]\n",
      " [22073     0    10]\n",
      " [22085     0    10]\n",
      " [22104     0    10]\n",
      " [22119     0    10]\n",
      " [22138     0    10]\n",
      " [22156     0    10]\n",
      " [22182     0    10]\n",
      " [22189     0    10]\n",
      " [22223     0    10]\n",
      " [22246     0    10]\n",
      " [22344     0    10]\n",
      " [22363     0    10]\n",
      " [22395     0    10]\n",
      " [22402     0    10]\n",
      " [22432     0    10]\n",
      " [22474     0    10]\n",
      " [22504     0    10]\n",
      " [22613     0    10]\n",
      " [22632     0    10]\n",
      " [22638     0    10]\n",
      " [22677     0    10]\n",
      " [22715     0    10]\n",
      " [22732     0    10]\n",
      " [22778     0    10]\n",
      " [22801     0    10]\n",
      " [22838     0    10]\n",
      " [22850     0    10]\n",
      " [22942     0    10]\n",
      " [22955     0    10]\n",
      " [22970     0    10]\n",
      " [23014     0    10]\n",
      " [23030     0    10]\n",
      " [23090     0    10]\n",
      " [23117     0    10]\n",
      " [23123     0    10]\n",
      " [23260     0    10]\n",
      " [23273     0    10]\n",
      " [23310     0    10]\n",
      " [23326     0    10]\n",
      " [23335     0    10]\n",
      " [23360     0    10]\n",
      " [23373     0    10]\n",
      " [23406     0    10]\n",
      " [23546     0    10]\n",
      " [23555     0    10]\n",
      " [23570     0    10]\n",
      " [23591     0    10]\n",
      " [23607     0    10]\n",
      " [23655     0    10]\n",
      " [23674     0    10]\n",
      " [23682     0    10]\n",
      " [23717     0    10]\n",
      " [23729     0    10]\n",
      " [23735     0    10]\n",
      " [23782     0    10]\n",
      " [23801     0    10]\n",
      " [23839     0    10]\n",
      " [23870     0    10]\n",
      " [23883     0    10]\n",
      " [23928     0    10]\n",
      " [23946     0    10]\n",
      " [23972     0    10]\n",
      " [24046     0    10]\n",
      " [24058     0    10]\n",
      " [24075     0    10]\n",
      " [24093     0    10]\n",
      " [24118     0    10]\n",
      " [24161     0    10]\n",
      " [24203     0    10]\n",
      " [24237     0    10]\n",
      " [24270     0    10]\n",
      " [24294     0    10]\n",
      " [24301     0    10]\n",
      " [24409     0    10]\n",
      " [24452     0    10]\n",
      " [24462     0    10]\n",
      " [24510     0    10]\n",
      " [24549     0    10]\n",
      " [24566     0    10]\n",
      " [24603     0    10]\n",
      " [24623     0    10]\n",
      " [24707     0    10]\n",
      " [24725     0    10]\n",
      " [24779     0    10]\n",
      " [24799     0    10]\n",
      " [24831     0    10]\n",
      " [24857     0    10]\n",
      " [24869     0    10]\n",
      " [24905     0    10]\n",
      " [24920     0    10]\n",
      " [25040     0    10]\n",
      " [25052     0    10]\n",
      " [25101     0    10]\n",
      " [25109     0    10]\n",
      " [25139     0    10]\n",
      " [25186     0    10]\n",
      " [25199     0    10]\n",
      " [25216     0    10]\n",
      " [25246     0    10]\n",
      " [25258     0    10]\n",
      " [25272     0    10]\n",
      " [25359     0    10]\n",
      " [25379     0    10]\n",
      " [25412     0    10]\n",
      " [25429     0    10]\n",
      " [25436     0    10]\n",
      " [25485     0    10]\n",
      " [25495     0    10]\n",
      " [25529     0    10]\n",
      " [25567     0    10]\n",
      " [25660     0    10]\n",
      " [25675     0    10]\n",
      " [25690     0    10]\n",
      " [25706     0    10]\n",
      " [25725     0    10]\n",
      " [25750     0    10]\n",
      " [25761     0    10]\n",
      " [25772     0    10]\n",
      " [25810     0    10]\n",
      " [25846     0    10]\n",
      " [25893     0    10]\n",
      " [25913     0    10]\n",
      " [25938     0    10]\n",
      " [25950     0    10]\n",
      " [25970     0    10]\n",
      " [26011     0    10]\n",
      " [26069     0    10]\n",
      " [26104     0    10]]\n",
      "<Epochs |  187 events (all good), -0.3 – 1.2 s, baseline off, ~12.4 MB, data loaded,\n",
      " '10': 187>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/dt/yj00f34n5x52_p314tnwfjkw0000gn/T/ipykernel_30538/1641304678.py:107: RuntimeWarning: Concatenation of Annotations within Epochs is not supported yet. All annotations will be dropped.\n",
      "  wOnset_epochs = mne.concatenate_epochs(all_tapes_epochs_LIST)\n",
      "/var/folders/dt/yj00f34n5x52_p314tnwfjkw0000gn/T/ipykernel_30538/1641304678.py:107: RuntimeWarning: Concatenation of Annotations within Epochs is not supported yet. All annotations will be dropped.\n",
      "  wOnset_epochs = mne.concatenate_epochs(all_tapes_epochs_LIST)\n",
      "/var/folders/dt/yj00f34n5x52_p314tnwfjkw0000gn/T/ipykernel_30538/1641304678.py:107: RuntimeWarning: Concatenation of Annotations within Epochs is not supported yet. All annotations will be dropped.\n",
      "  wOnset_epochs = mne.concatenate_epochs(all_tapes_epochs_LIST)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tape_num= 11\n",
      "wOnset_perTape_DF=              Word  Segment      onset\n",
      "1835          she       11   0.274485\n",
      "1836        could       11   0.489783\n",
      "1837          see       11   0.701863\n",
      "1838           it       11   1.064477\n",
      "1839        quite       11   1.279987\n",
      "...           ...      ...        ...\n",
      "1987           to       11  53.797174\n",
      "1988         make       11  53.890245\n",
      "1989          one       11  54.211688\n",
      "1990  respectable       11  54.517325\n",
      "1991       person       11  55.331149\n",
      "\n",
      "[157 rows x 3 columns]\n",
      "wOnset_datapoints_ndarray= [ 27.448538   48.9783265  70.1863265 106.4477265 127.9987265 161.5225265\n",
      " 213.0055265 236.9511265 245.3320265 357.8762265 369.5823265 386.6109265\n",
      " 420.1347265 433.3048265 489.5769265] <class 'numpy.ndarray'>\n",
      "tape_start_datapoints_npINT64= 27027\n",
      "abs_wOnsets_dta_ndarray= [27054.448538  27075.9783265 27097.1863265 27133.4477265 27154.9987265\n",
      " 27188.5225265 27240.0055265 27263.9511265 27272.3320265 27384.8762265\n",
      " 27396.5823265 27413.6109265 27447.1347265 27460.3048265 27516.5769265]\n",
      "rounded_abs_wOnsets_dta_ndarray= [27054 27075 27097 27133 27154 27188 27240 27263 27272 27384 27396 27413\n",
      " 27447 27460 27516]\n",
      "[[27054     0    11]\n",
      " [27075     0    11]\n",
      " [27097     0    11]\n",
      " [27133     0    11]\n",
      " [27154     0    11]\n",
      " [27188     0    11]\n",
      " [27240     0    11]\n",
      " [27263     0    11]\n",
      " [27272     0    11]\n",
      " [27384     0    11]\n",
      " [27396     0    11]\n",
      " [27413     0    11]\n",
      " [27447     0    11]\n",
      " [27460     0    11]\n",
      " [27516     0    11]\n",
      " [27524     0    11]\n",
      " [27557     0    11]\n",
      " [27576     0    11]\n",
      " [27592     0    11]\n",
      " [27600     0    11]\n",
      " [27613     0    11]\n",
      " [27645     0    11]\n",
      " [27654     0    11]\n",
      " [27662     0    11]\n",
      " [27754     0    11]\n",
      " [27766     0    11]\n",
      " [27777     0    11]\n",
      " [27795     0    11]\n",
      " [27814     0    11]\n",
      " [27946     0    11]\n",
      " [27959     0    11]\n",
      " [27973     0    11]\n",
      " [27993     0    11]\n",
      " [28009     0    11]\n",
      " [28056     0    11]\n",
      " [28101     0    11]\n",
      " [28121     0    11]\n",
      " [28139     0    11]\n",
      " [28243     0    11]\n",
      " [28252     0    11]\n",
      " [28283     0    11]\n",
      " [28311     0    11]\n",
      " [28341     0    11]\n",
      " [28373     0    11]\n",
      " [28399     0    11]\n",
      " [28414     0    11]\n",
      " [28655     0    11]\n",
      " [28681     0    11]\n",
      " [28692     0    11]\n",
      " [28727     0    11]\n",
      " [28760     0    11]\n",
      " [28796     0    11]\n",
      " [28847     0    11]\n",
      " [28869     0    11]\n",
      " [28935     0    11]\n",
      " [28957     0    11]\n",
      " [29003     0    11]\n",
      " [29017     0    11]\n",
      " [29065     0    11]\n",
      " [29093     0    11]\n",
      " [29207     0    11]\n",
      " [29222     0    11]\n",
      " [29282     0    11]\n",
      " [29295     0    11]\n",
      " [29307     0    11]\n",
      " [29332     0    11]\n",
      " [29365     0    11]\n",
      " [29404     0    11]\n",
      " [29573     0    11]\n",
      " [29594     0    11]\n",
      " [29639     0    11]\n",
      " [29665     0    11]\n",
      " [29706     0    11]\n",
      " [29742     0    11]\n",
      " [29761     0    11]\n",
      " [29831     0    11]\n",
      " [29840     0    11]\n",
      " [29862     0    11]\n",
      " [29894     0    11]\n",
      " [29941     0    11]\n",
      " [29984     0    11]\n",
      " [30063     0    11]\n",
      " [30077     0    11]\n",
      " [30136     0    11]\n",
      " [30147     0    11]\n",
      " [30194     0    11]\n",
      " [30239     0    11]\n",
      " [30271     0    11]\n",
      " [30340     0    11]\n",
      " [30357     0    11]\n",
      " [30368     0    11]\n",
      " [30394     0    11]\n",
      " [30436     0    11]\n",
      " [30458     0    11]\n",
      " [30481     0    11]\n",
      " [30573     0    11]\n",
      " [30589     0    11]\n",
      " [30625     0    11]\n",
      " [30670     0    11]\n",
      " [30701     0    11]\n",
      " [30709     0    11]\n",
      " [30756     0    11]\n",
      " [30767     0    11]\n",
      " [30791     0    11]\n",
      " [30830     0    11]\n",
      " [30841     0    11]\n",
      " [30871     0    11]\n",
      " [30913     0    11]\n",
      " [30963     0    11]\n",
      " [30974     0    11]\n",
      " [30980     0    11]\n",
      " [31008     0    11]\n",
      " [31022     0    11]\n",
      " [31068     0    11]\n",
      " [31089     0    11]\n",
      " [31108     0    11]\n",
      " [31142     0    11]\n",
      " [31189     0    11]\n",
      " [31307     0    11]\n",
      " [31320     0    11]\n",
      " [31346     0    11]\n",
      " [31400     0    11]\n",
      " [31442     0    11]\n",
      " [31469     0    11]\n",
      " [31505     0    11]\n",
      " [31519     0    11]\n",
      " [31571     0    11]\n",
      " [31580     0    11]\n",
      " [31600     0    11]\n",
      " [31623     0    11]\n",
      " [31780     0    11]\n",
      " [31788     0    11]\n",
      " [31800     0    11]\n",
      " [31814     0    11]\n",
      " [31848     0    11]\n",
      " [31883     0    11]\n",
      " [31969     0    11]\n",
      " [31986     0    11]\n",
      " [32019     0    11]\n",
      " [32058     0    11]\n",
      " [32071     0    11]\n",
      " [32114     0    11]\n",
      " [32121     0    11]\n",
      " [32142     0    11]\n",
      " [32169     0    11]\n",
      " [32211     0    11]\n",
      " [32264     0    11]\n",
      " [32278     0    11]\n",
      " [32292     0    11]\n",
      " [32332     0    11]\n",
      " [32369     0    11]\n",
      " [32391     0    11]\n",
      " [32406     0    11]\n",
      " [32416     0    11]\n",
      " [32448     0    11]\n",
      " [32478     0    11]\n",
      " [32560     0    11]]\n",
      "<Epochs |  154 events (all good), -0.3 – 1.2 s, baseline off, ~10.2 MB, data loaded,\n",
      " '11': 154>\n",
      "tape_num= 12\n",
      "wOnset_perTape_DF=          Word  Segment      onset\n",
      "1992     Soon       12   0.229476\n",
      "1993      her       12   0.504358\n",
      "1994      eye       12   0.658032\n",
      "1995     fell       12   0.974924\n",
      "1996       on       12   1.266236\n",
      "...       ...      ...        ...\n",
      "2124  happens       12  45.226353\n",
      "2125     when       12  45.677924\n",
      "2126      one       12  45.896829\n",
      "2127     eats       12  46.064448\n",
      "2128     cake       12  46.327849\n",
      "\n",
      "[137 rows x 3 columns]\n",
      "wOnset_datapoints_ndarray= [ 22.9476225  50.4358225  65.8032225  97.4924225 126.6236225 144.1863225\n",
      " 151.5146225 180.1046225 222.0094225 268.7033225 279.4788225 292.6489225\n",
      " 329.3501225 356.1046225 364.4856225] <class 'numpy.ndarray'>\n",
      "tape_start_datapoints_npINT64= 27078\n",
      "abs_wOnsets_dta_ndarray= [27100.9476225 27128.4358225 27143.8032225 27175.4924225 27204.6236225\n",
      " 27222.1863225 27229.5146225 27258.1046225 27300.0094225 27346.7033225\n",
      " 27357.4788225 27370.6489225 27407.3501225 27434.1046225 27442.4856225]\n",
      "rounded_abs_wOnsets_dta_ndarray= [27100 27128 27143 27175 27204 27222 27229 27258 27300 27346 27357 27370\n",
      " 27407 27434 27442]\n",
      "[[27100     0    12]\n",
      " [27128     0    12]\n",
      " [27143     0    12]\n",
      " [27175     0    12]\n",
      " [27204     0    12]\n",
      " [27222     0    12]\n",
      " [27229     0    12]\n",
      " [27258     0    12]\n",
      " [27300     0    12]\n",
      " [27346     0    12]\n",
      " [27357     0    12]\n",
      " [27370     0    12]\n",
      " [27407     0    12]\n",
      " [27434     0    12]\n",
      " [27442     0    12]\n",
      " [27547     0    12]\n",
      " [27570     0    12]\n",
      " [27608     0    12]\n",
      " [27666     0    12]\n",
      " [27691     0    12]\n",
      " [27724     0    12]\n",
      " [27738     0    12]\n",
      " [27753     0    12]\n",
      " [27762     0    12]\n",
      " [27799     0    12]\n",
      " [27842     0    12]\n",
      " [27939     0    12]\n",
      " [27951     0    12]\n",
      " [27978     0    12]\n",
      " [27989     0    12]\n",
      " [28046     0    12]\n",
      " [28077     0    12]\n",
      " [28154     0    12]\n",
      " [28180     0    12]\n",
      " [28236     0    12]\n",
      " [28271     0    12]\n",
      " [28284     0    12]\n",
      " [28481     0    12]\n",
      " [28563     0    12]\n",
      " [28575     0    12]\n",
      " [28590     0    12]\n",
      " [28614     0    12]\n",
      " [28662     0    12]\n",
      " [28687     0    12]\n",
      " [28729     0    12]\n",
      " [28740     0    12]\n",
      " [28757     0    12]\n",
      " [28770     0    12]\n",
      " [28796     0    12]\n",
      " [28813     0    12]\n",
      " [28836     0    12]\n",
      " [28884     0    12]\n",
      " [28895     0    12]\n",
      " [28914     0    12]\n",
      " [28943     0    12]\n",
      " [28954     0    12]\n",
      " [29044     0    12]\n",
      " [29057     0    12]\n",
      " [29070     0    12]\n",
      " [29083     0    12]\n",
      " [29109     0    12]\n",
      " [29123     0    12]\n",
      " [29141     0    12]\n",
      " [29239     0    12]\n",
      " [29253     0    12]\n",
      " [29274     0    12]\n",
      " [29305     0    12]\n",
      " [29328     0    12]\n",
      " [29338     0    12]\n",
      " [29426     0    12]\n",
      " [29447     0    12]\n",
      " [29479     0    12]\n",
      " [29501     0    12]\n",
      " [29507     0    12]\n",
      " [29513     0    12]\n",
      " [29530     0    12]\n",
      " [29555     0    12]\n",
      " [29565     0    12]\n",
      " [29638     0    12]\n",
      " [29651     0    12]\n",
      " [29666     0    12]\n",
      " [29682     0    12]\n",
      " [29705     0    12]\n",
      " [29730     0    12]\n",
      " [29887     0    12]\n",
      " [29914     0    12]\n",
      " [29940     0    12]\n",
      " [29951     0    12]\n",
      " [30001     0    12]\n",
      " [30107     0    12]\n",
      " [30116     0    12]\n",
      " [30137     0    12]\n",
      " [30198     0    12]\n",
      " [30213     0    12]\n",
      " [30337     0    12]\n",
      " [30366     0    12]\n",
      " [30468     0    12]\n",
      " [30498     0    12]\n",
      " [30619     0    12]\n",
      " [30649     0    12]\n",
      " [30659     0    12]\n",
      " [30694     0    12]\n",
      " [30706     0    12]\n",
      " [30713     0    12]\n",
      " [30742     0    12]\n",
      " [30749     0    12]\n",
      " [30763     0    12]\n",
      " [30792     0    12]\n",
      " [30806     0    12]\n",
      " [30840     0    12]\n",
      " [30862     0    12]\n",
      " [30882     0    12]\n",
      " [30897     0    12]\n",
      " [30914     0    12]\n",
      " [31030     0    12]\n",
      " [31040     0    12]\n",
      " [31057     0    12]\n",
      " [31075     0    12]\n",
      " [31100     0    12]\n",
      " [31174     0    12]\n",
      " [31181     0    12]\n",
      " [31212     0    12]\n",
      " [31223     0    12]\n",
      " [31242     0    12]\n",
      " [31283     0    12]\n",
      " [31290     0    12]\n",
      " [31322     0    12]\n",
      " [31449     0    12]\n",
      " [31465     0    12]\n",
      " [31477     0    12]\n",
      " [31512     0    12]\n",
      " [31543     0    12]\n",
      " [31600     0    12]\n",
      " [31645     0    12]\n",
      " [31667     0    12]\n",
      " [31684     0    12]\n",
      " [31710     0    12]]\n",
      "<Epochs |  136 events (all good), -0.3 – 1.2 s, baseline off, ~9.0 MB, data loaded,\n",
      " '12': 136>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/dt/yj00f34n5x52_p314tnwfjkw0000gn/T/ipykernel_30538/1641304678.py:107: RuntimeWarning: Concatenation of Annotations within Epochs is not supported yet. All annotations will be dropped.\n",
      "  wOnset_epochs = mne.concatenate_epochs(all_tapes_epochs_LIST)\n",
      "/var/folders/dt/yj00f34n5x52_p314tnwfjkw0000gn/T/ipykernel_30538/1641304678.py:108: RuntimeWarning: This filename (/Users/neuroling/Downloads/DINGHSIN_Results/Alice_Experiments_Results/EEG_ESLs/Alice_ESLs_wOnset_raw_epochs/S023_ESLs_wOnset_epochs_11Tapes_raw.fif) does not conform to MNE naming conventions. All epochs files should end with -epo.fif, -epo.fif.gz, _epo.fif or _epo.fif.gz\n",
      "  wOnset_epochs.save(wOnset_DIR / Path('%s_ESLs_wOnset_epochs_11Tapes_raw.fif' %subject[4:8]), overwrite=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "subject_num= n_2_ wOnset epoch saved.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\n    # 5. Combine all words from all tapes into one Dataset\\n    # This 'ds' will have a column for 'EEG' and can have a column for 'Subject'\\n    ds_all_words = eelbrain.combine(all_tapes_epochs)\\n    \\n    # Now you can access the data for HHSA:\\n    # eeg_data = ds_all_words['eeg'].get_data()\\n    \""
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## (Use this!!!)Trying the old way (Sub order 1st then tape 2nd)##\n",
    "\n",
    "# epochs parameters\n",
    "# Define your epoch window\n",
    "# We use a 1.5s window (including buffers for HHSA)\n",
    "tmin, tmax = -0.3, 1.2 \n",
    "\n",
    "for subject in ESL_SUBJECTS[0:3]:\n",
    "    print(\"subject_num=\", subject)\n",
    "    \n",
    "    # 1. Load Raw as an Eelbrain-compatible object\n",
    "    raw = mne.io.read_raw_fif(EEG_DIR / f'{subject}', preload=True)\n",
    "    raw_sfreq = raw.info['sfreq']\n",
    "    \n",
    "    # 2. Get the events for the 12 tapes\n",
    "    events_DICT = eelbrain.load.mne.events(raw)\n",
    "    trial_indexes = [STIMULI.index(stimulus) for stimulus in events_DICT['event'] if stimulus in STIMULI]  # type(trial_indexes)==LIST\n",
    "\n",
    "    if len(events_DICT['event'])==12:\n",
    "        # Get the actual word onset based on EEG triggers datapoints\n",
    "        all_tapes_epochs_LIST = []\n",
    "        for i, stimulus_idx in enumerate(trial_indexes):\n",
    "            print(\"tape_num=\", stimulus_idx+1)\n",
    "            \n",
    "            # Find the word onset time based on the segment sequence    \n",
    "            wOnset_perTape_DF = word_onset_essentials_DF.loc[word_onset_essentials_DF[\"Segment\"] == stimulus_idx+1, :] #.to_numpy()\n",
    "            print(\"wOnset_perTape_DF=\", wOnset_perTape_DF)\n",
    "            #wOnset_time_ndarray = wOnset_perTape_DF[\"onset\"].to_numpy() #*raw_sfreq\n",
    "            wOnset_datapoints_ndarray = wOnset_perTape_DF[\"onset\"].to_numpy()*raw_sfreq\n",
    "            print(\"wOnset_datapoints_ndarray=\", wOnset_datapoints_ndarray[0:15], type(wOnset_datapoints_ndarray))\n",
    "    \n",
    "            # Get the tape start time\n",
    "            tape_start_datapoints_npINT64 = events_DICT[i]['i_start']\n",
    "            #tape_start_time_npFLOAT64 = tape_start_datapoints_npINT64 / raw_sfreq\n",
    "            print(\"tape_start_datapoints_npINT64=\", tape_start_datapoints_npINT64)\n",
    "            #print(\"tape_start_time_npFLOAT64=\", tape_start_time_npFLOAT64, type(tape_start_time_npFLOAT64))\n",
    "    \n",
    "            # Get the actual word onset time by the triggers\n",
    "            #absolute_onsets_time_ndarray = tape_start_time_npFLOAT64 + wOnset_time_ndarray\n",
    "            #print(\"absolute_onsets_time_ndarray=\", absolute_onsets_time_ndarray[0:15])\n",
    "            abs_wOnsets_dta_ndarray = tape_start_datapoints_npINT64 + wOnset_datapoints_ndarray\n",
    "            print(\"abs_wOnsets_dta_ndarray=\", abs_wOnsets_dta_ndarray[0:15])\n",
    "            \n",
    "            # To exclude the decimal but leave the integer along, and turn FLOAT into INT\n",
    "            abs_wOnsets_dta_ndarray = np.trunc(abs_wOnsets_dta_ndarray).astype(int)\n",
    "            print(\"rounded_abs_wOnsets_dta_ndarray=\", abs_wOnsets_dta_ndarray[0:15])\n",
    "            \n",
    "            # Make epochs\n",
    "            # Create the empty (N, 3) event matrix based on wOnset per tape\n",
    "            wOnset_events = len(abs_wOnsets_dta_ndarray)\n",
    "            wOnset_perTape_events = np.zeros((wOnset_events, 3), dtype=int)\n",
    "            # Fill the columns\n",
    "            wOnset_perTape_events[:, 0] = abs_wOnsets_dta_ndarray  # Column 0: The sample indices\n",
    "            wOnset_perTape_events[:, 2] = stimulus_idx+1           # Column 2: The event ID (e.g., 1)\n",
    "            print(wOnset_perTape_events)\n",
    "            \n",
    "            #word_perTape_epochs = mne.epochs(raw, tmin=tmin, tmax=tmax, baseline=None, events=wOnset_perTape_events)\n",
    "            tape_perTape_epochs = mne.Epochs(raw, events=wOnset_perTape_events, event_id=stimulus_idx+1, tmin=tmin, tmax=tmax, baseline=None, preload=True)\n",
    "            print(tape_perTape_epochs)\n",
    "            all_tapes_epochs_LIST.append(tape_perTape_epochs)\n",
    "            wOnset_epochs = mne.concatenate_epochs(all_tapes_epochs_LIST)\n",
    "        wOnset_epochs.save(wOnset_DIR / Path('%s_ESLs_wOnset_epochs_allTapes_raw.fif' %subject[4:8]), overwrite=True)\n",
    "        print(\"subject_num=\", subject[:4], \"wOnset epoch saved.\")\n",
    "    \n",
    "    else:  # For those who only start on the 2nd tape\n",
    "        # Get the actual word onset based on EEG triggers datapoints\n",
    "        all_tapes_epochs_LIST = []\n",
    "        for i, stimulus_idx in enumerate(trial_indexes[1:]):\n",
    "            print(\"tape_num=\", stimulus_idx+1)\n",
    "            \n",
    "            # Find the word onset time based on the segment sequence    \n",
    "            wOnset_perTape_DF = word_onset_essentials_DF.loc[word_onset_essentials_DF[\"Segment\"] == stimulus_idx+1, :] #.to_numpy()\n",
    "            print(\"wOnset_perTape_DF=\", wOnset_perTape_DF)\n",
    "            #wOnset_time_ndarray = wOnset_perTape_DF[\"onset\"].to_numpy() #*raw_sfreq\n",
    "            wOnset_datapoints_ndarray = wOnset_perTape_DF[\"onset\"].to_numpy()*raw_sfreq\n",
    "            print(\"wOnset_datapoints_ndarray=\", wOnset_datapoints_ndarray[0:15], type(wOnset_datapoints_ndarray))\n",
    "    \n",
    "            # Get the tape start time\n",
    "            tape_start_datapoints_npINT64 = events_DICT[i]['i_start']\n",
    "            #tape_start_time_npFLOAT64 = tape_start_datapoints_npINT64 / raw_sfreq\n",
    "            print(\"tape_start_datapoints_npINT64=\", tape_start_datapoints_npINT64)\n",
    "            #print(\"tape_start_time_npFLOAT64=\", tape_start_time_npFLOAT64, type(tape_start_time_npFLOAT64))\n",
    "    \n",
    "            # Get the actual word onset time by the triggers\n",
    "            #absolute_onsets_time_ndarray = tape_start_time_npFLOAT64 + wOnset_time_ndarray\n",
    "            #print(\"absolute_onsets_time_ndarray=\", absolute_onsets_time_ndarray[0:15])\n",
    "            abs_wOnsets_dta_ndarray = tape_start_datapoints_npINT64 + wOnset_datapoints_ndarray\n",
    "            print(\"abs_wOnsets_dta_ndarray=\", abs_wOnsets_dta_ndarray[0:15])\n",
    "            \n",
    "            # To exclude the decimal but leave the integer along, and turn FLOAT into INT\n",
    "            abs_wOnsets_dta_ndarray = np.trunc(abs_wOnsets_dta_ndarray).astype(int)\n",
    "            print(\"rounded_abs_wOnsets_dta_ndarray=\", abs_wOnsets_dta_ndarray[0:15])\n",
    "            \n",
    "            # Make epochs\n",
    "            # Create the empty (N, 3) event matrix based on wOnset per tape\n",
    "            wOnset_events = len(abs_wOnsets_dta_ndarray)\n",
    "            wOnset_perTape_events = np.zeros((wOnset_events, 3), dtype=int)\n",
    "            # Fill the columns\n",
    "            wOnset_perTape_events[:, 0] = abs_wOnsets_dta_ndarray  # Column 0: The sample indices\n",
    "            wOnset_perTape_events[:, 2] = stimulus_idx+1           # Column 2: The event ID (e.g., 1)\n",
    "            print(wOnset_perTape_events)\n",
    "            \n",
    "            #word_perTape_epochs = mne.epochs(raw, tmin=tmin, tmax=tmax, baseline=None, events=wOnset_perTape_events)\n",
    "            tape_perTape_epochs = mne.Epochs(raw, events=wOnset_perTape_events, event_id=stimulus_idx+1, tmin=tmin, tmax=tmax, baseline=None, preload=True)\n",
    "            print(tape_perTape_epochs)\n",
    "            all_tapes_epochs_LIST.append(tape_perTape_epochs)\n",
    "            wOnset_epochs = mne.concatenate_epochs(all_tapes_epochs_LIST)\n",
    "        wOnset_epochs.save(wOnset_DIR / Path('%s_ESLs_wOnset_epochs_11Tapes_raw.fif' %subject[4:8]), overwrite=True)\n",
    "        print(\"subject_num=\", subject[:4], \"wOnset epoch saved.\")\n",
    "    \n",
    "\n",
    "\"\"\"\n",
    "    # 5. Combine all words from all tapes into one Dataset\n",
    "    # This 'ds' will have a column for 'EEG' and can have a column for 'Subject'\n",
    "    ds_all_words = eelbrain.combine(all_tapes_epochs)\n",
    "    \n",
    "    # Now you can access the data for HHSA:\n",
    "    # eeg_data = ds_all_words['eeg'].get_data()\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "1ef6d81d-35f7-4656-8353-4a451591a71c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wOnset_datapoints_ndarray= [  4.6     56.2721  78.4543 125.6929 135.2925 161.6327 231.0749 279.9918\n",
      " 293.8712 330.449  348.4082 365.4596 410.6667 427.4286 439.8799] <class 'numpy.ndarray'>\n",
      "subject_num= S44_Alice-natives_sfreq-100_raw.fif\n",
      "tape_num= 1\n",
      "tape_start_datapoints_npINT64= 172\n",
      "abs_wOnsets_dta_ndarray= [176.6    228.2721 250.4543 297.6929 307.2925 333.6327 403.0749 451.9918\n",
      " 465.8712 502.449  520.4082 537.4596 582.6667 599.4286 611.8799]\n",
      "rounded_abs_wOnsets_dta_ndarray= [176 228 250 297 307 333 403 451 465 502 520 537 582 599 611]\n",
      "[[ 176    0    1]\n",
      " [ 228    0    1]\n",
      " [ 250    0    1]\n",
      " [ 297    0    1]\n",
      " [ 307    0    1]\n",
      " [ 333    0    1]\n",
      " [ 403    0    1]\n",
      " [ 451    0    1]\n",
      " [ 465    0    1]\n",
      " [ 502    0    1]\n",
      " [ 520    0    1]\n",
      " [ 537    0    1]\n",
      " [ 582    0    1]\n",
      " [ 599    0    1]\n",
      " [ 611    0    1]\n",
      " [ 650    0    1]\n",
      " [ 662    0    1]\n",
      " [ 675    0    1]\n",
      " [ 715    0    1]\n",
      " [ 761    0    1]\n",
      " [ 777    0    1]\n",
      " [ 886    0    1]\n",
      " [ 910    0    1]\n",
      " [ 921    0    1]\n",
      " [ 967    0    1]\n",
      " [ 998    0    1]\n",
      " [1028    0    1]\n",
      " [1049    0    1]\n",
      " [1060    0    1]\n",
      " [1095    0    1]\n",
      " [1103    0    1]\n",
      " [1142    0    1]\n",
      " [1168    0    1]\n",
      " [1253    0    1]\n",
      " [1264    0    1]\n",
      " [1273    0    1]\n",
      " [1301    0    1]\n",
      " [1314    0    1]\n",
      " [1364    0    1]\n",
      " [1375    0    1]\n",
      " [1460    0    1]\n",
      " [1473    0    1]\n",
      " [1549    0    1]\n",
      " [1566    0    1]\n",
      " [1583    0    1]\n",
      " [1594    0    1]\n",
      " [1612    0    1]\n",
      " [1644    0    1]\n",
      " [1654    0    1]\n",
      " [1675    0    1]\n",
      " [1715    0    1]\n",
      " [1756    0    1]\n",
      " [1795    0    1]\n",
      " [1828    0    1]\n",
      " [1882    0    1]\n",
      " [1898    0    1]\n",
      " [2124    0    1]\n",
      " [2144    0    1]\n",
      " [2164    0    1]\n",
      " [2189    0    1]\n",
      " [2264    0    1]\n",
      " [2274    0    1]\n",
      " [2298    0    1]\n",
      " [2322    0    1]\n",
      " [2388    0    1]\n",
      " [2413    0    1]\n",
      " [2436    0    1]\n",
      " [2445    0    1]\n",
      " [2464    0    1]\n",
      " [2510    0    1]\n",
      " [2523    0    1]\n",
      " [2531    0    1]\n",
      " [2561    0    1]\n",
      " [2588    0    1]\n",
      " [2608    0    1]\n",
      " [2620    0    1]\n",
      " [2645    0    1]\n",
      " [2677    0    1]\n",
      " [2726    0    1]\n",
      " [2740    0    1]\n",
      " [2859    0    1]\n",
      " [2886    0    1]\n",
      " [2903    0    1]\n",
      " [2949    0    1]\n",
      " [2960    0    1]\n",
      " [2997    0    1]\n",
      " [3009    0    1]\n",
      " [3053    0    1]\n",
      " [3101    0    1]\n",
      " [3119    0    1]\n",
      " [3132    0    1]\n",
      " [3159    0    1]\n",
      " [3167    0    1]\n",
      " [3208    0    1]\n",
      " [3217    0    1]\n",
      " [3256    0    1]\n",
      " [3274    0    1]\n",
      " [3289    0    1]\n",
      " [3323    0    1]\n",
      " [3330    0    1]\n",
      " [3455    0    1]\n",
      " [3475    0    1]\n",
      " [3579    0    1]\n",
      " [3591    0    1]\n",
      " [3628    0    1]\n",
      " [3669    0    1]\n",
      " [3686    0    1]\n",
      " [3723    0    1]\n",
      " [3766    0    1]\n",
      " [3787    0    1]\n",
      " [3828    0    1]\n",
      " [3848    0    1]\n",
      " [4018    0    1]\n",
      " [4035    0    1]\n",
      " [4052    0    1]\n",
      " [4089    0    1]\n",
      " [4118    0    1]\n",
      " [4176    0    1]\n",
      " [4249    0    1]\n",
      " [4265    0    1]\n",
      " [4354    0    1]\n",
      " [4376    0    1]\n",
      " [4392    0    1]\n",
      " [4433    0    1]\n",
      " [4452    0    1]\n",
      " [4462    0    1]\n",
      " [4485    0    1]\n",
      " [4519    0    1]\n",
      " [4550    0    1]\n",
      " [4567    0    1]\n",
      " [4577    0    1]\n",
      " [4587    0    1]\n",
      " [4618    0    1]\n",
      " [4635    0    1]\n",
      " [4652    0    1]\n",
      " [4662    0    1]\n",
      " [4697    0    1]\n",
      " [4721    0    1]\n",
      " [4740    0    1]\n",
      " [4852    0    1]\n",
      " [4865    0    1]\n",
      " [4937    0    1]\n",
      " [4949    0    1]\n",
      " [5002    0    1]\n",
      " [5009    0    1]\n",
      " [5029    0    1]\n",
      " [5043    0    1]\n",
      " [5178    0    1]\n",
      " [5190    0    1]\n",
      " [5208    0    1]\n",
      " [5232    0    1]\n",
      " [5244    0    1]\n",
      " [5277    0    1]\n",
      " [5344    0    1]\n",
      " [5353    0    1]\n",
      " [5393    0    1]\n",
      " [5405    0    1]\n",
      " [5427    0    1]\n",
      " [5464    0    1]\n",
      " [5487    0    1]\n",
      " [5510    0    1]\n",
      " [5527    0    1]\n",
      " [5551    0    1]\n",
      " [5584    0    1]\n",
      " [5608    0    1]\n",
      " [5641    0    1]\n",
      " [5654    0    1]\n",
      " [5677    0    1]\n",
      " [5686    0    1]\n",
      " [5734    0    1]\n",
      " [5745    0    1]\n",
      " [5760    0    1]\n",
      " [5791    0    1]\n",
      " [5815    0    1]]\n",
      "<Epochs |  174 events (all good), -0.3 – 1.2 s, baseline off, ~11.9 MB, data loaded,\n",
      " '1': 174>\n",
      "subject_num= S20_Alice-natives_sfreq-100_raw.fif\n",
      "tape_num= 1\n",
      "tape_start_datapoints_npINT64= 413\n",
      "abs_wOnsets_dta_ndarray= [417.6    469.2721 491.4543 538.6929 548.2925 574.6327 644.0749 692.9918\n",
      " 706.8712 743.449  761.4082 778.4596 823.6667 840.4286 852.8799]\n",
      "rounded_abs_wOnsets_dta_ndarray= [417 469 491 538 548 574 644 692 706 743 761 778 823 840 852]\n",
      "[[ 417    0    1]\n",
      " [ 469    0    1]\n",
      " [ 491    0    1]\n",
      " [ 538    0    1]\n",
      " [ 548    0    1]\n",
      " [ 574    0    1]\n",
      " [ 644    0    1]\n",
      " [ 692    0    1]\n",
      " [ 706    0    1]\n",
      " [ 743    0    1]\n",
      " [ 761    0    1]\n",
      " [ 778    0    1]\n",
      " [ 823    0    1]\n",
      " [ 840    0    1]\n",
      " [ 852    0    1]\n",
      " [ 891    0    1]\n",
      " [ 903    0    1]\n",
      " [ 916    0    1]\n",
      " [ 956    0    1]\n",
      " [1002    0    1]\n",
      " [1018    0    1]\n",
      " [1127    0    1]\n",
      " [1151    0    1]\n",
      " [1162    0    1]\n",
      " [1208    0    1]\n",
      " [1239    0    1]\n",
      " [1269    0    1]\n",
      " [1290    0    1]\n",
      " [1301    0    1]\n",
      " [1336    0    1]\n",
      " [1344    0    1]\n",
      " [1383    0    1]\n",
      " [1409    0    1]\n",
      " [1494    0    1]\n",
      " [1505    0    1]\n",
      " [1514    0    1]\n",
      " [1542    0    1]\n",
      " [1555    0    1]\n",
      " [1605    0    1]\n",
      " [1616    0    1]\n",
      " [1701    0    1]\n",
      " [1714    0    1]\n",
      " [1790    0    1]\n",
      " [1807    0    1]\n",
      " [1824    0    1]\n",
      " [1835    0    1]\n",
      " [1853    0    1]\n",
      " [1885    0    1]\n",
      " [1895    0    1]\n",
      " [1916    0    1]\n",
      " [1956    0    1]\n",
      " [1997    0    1]\n",
      " [2036    0    1]\n",
      " [2069    0    1]\n",
      " [2123    0    1]\n",
      " [2139    0    1]\n",
      " [2365    0    1]\n",
      " [2385    0    1]\n",
      " [2405    0    1]\n",
      " [2430    0    1]\n",
      " [2505    0    1]\n",
      " [2515    0    1]\n",
      " [2539    0    1]\n",
      " [2563    0    1]\n",
      " [2629    0    1]\n",
      " [2654    0    1]\n",
      " [2677    0    1]\n",
      " [2686    0    1]\n",
      " [2705    0    1]\n",
      " [2751    0    1]\n",
      " [2764    0    1]\n",
      " [2772    0    1]\n",
      " [2802    0    1]\n",
      " [2829    0    1]\n",
      " [2849    0    1]\n",
      " [2861    0    1]\n",
      " [2886    0    1]\n",
      " [2918    0    1]\n",
      " [2967    0    1]\n",
      " [2981    0    1]\n",
      " [3100    0    1]\n",
      " [3127    0    1]\n",
      " [3144    0    1]\n",
      " [3190    0    1]\n",
      " [3201    0    1]\n",
      " [3238    0    1]\n",
      " [3250    0    1]\n",
      " [3294    0    1]\n",
      " [3342    0    1]\n",
      " [3360    0    1]\n",
      " [3373    0    1]\n",
      " [3400    0    1]\n",
      " [3408    0    1]\n",
      " [3449    0    1]\n",
      " [3458    0    1]\n",
      " [3497    0    1]\n",
      " [3515    0    1]\n",
      " [3530    0    1]\n",
      " [3564    0    1]\n",
      " [3571    0    1]\n",
      " [3696    0    1]\n",
      " [3716    0    1]\n",
      " [3820    0    1]\n",
      " [3832    0    1]\n",
      " [3869    0    1]\n",
      " [3910    0    1]\n",
      " [3927    0    1]\n",
      " [3964    0    1]\n",
      " [4007    0    1]\n",
      " [4028    0    1]\n",
      " [4069    0    1]\n",
      " [4089    0    1]\n",
      " [4259    0    1]\n",
      " [4276    0    1]\n",
      " [4293    0    1]\n",
      " [4330    0    1]\n",
      " [4359    0    1]\n",
      " [4417    0    1]\n",
      " [4490    0    1]\n",
      " [4506    0    1]\n",
      " [4595    0    1]\n",
      " [4617    0    1]\n",
      " [4633    0    1]\n",
      " [4674    0    1]\n",
      " [4693    0    1]\n",
      " [4703    0    1]\n",
      " [4726    0    1]\n",
      " [4760    0    1]\n",
      " [4791    0    1]\n",
      " [4808    0    1]\n",
      " [4818    0    1]\n",
      " [4828    0    1]\n",
      " [4859    0    1]\n",
      " [4876    0    1]\n",
      " [4893    0    1]\n",
      " [4903    0    1]\n",
      " [4938    0    1]\n",
      " [4962    0    1]\n",
      " [4981    0    1]\n",
      " [5093    0    1]\n",
      " [5106    0    1]\n",
      " [5178    0    1]\n",
      " [5190    0    1]\n",
      " [5243    0    1]\n",
      " [5250    0    1]\n",
      " [5270    0    1]\n",
      " [5284    0    1]\n",
      " [5419    0    1]\n",
      " [5431    0    1]\n",
      " [5449    0    1]\n",
      " [5473    0    1]\n",
      " [5485    0    1]\n",
      " [5518    0    1]\n",
      " [5585    0    1]\n",
      " [5594    0    1]\n",
      " [5634    0    1]\n",
      " [5646    0    1]\n",
      " [5668    0    1]\n",
      " [5705    0    1]\n",
      " [5728    0    1]\n",
      " [5751    0    1]\n",
      " [5768    0    1]\n",
      " [5792    0    1]\n",
      " [5825    0    1]\n",
      " [5849    0    1]\n",
      " [5882    0    1]\n",
      " [5895    0    1]\n",
      " [5918    0    1]\n",
      " [5927    0    1]\n",
      " [5975    0    1]\n",
      " [5986    0    1]\n",
      " [6001    0    1]\n",
      " [6032    0    1]\n",
      " [6056    0    1]]\n",
      "<Epochs |  174 events (all good), -0.3 – 1.2 s, baseline off, ~11.9 MB, data loaded,\n",
      " '1': 174>\n",
      "subject_num= S13_Alice-natives_sfreq-100_raw.fif\n",
      "tape_num= 1\n",
      "tape_start_datapoints_npINT64= 853\n",
      "abs_wOnsets_dta_ndarray= [ 857.6     909.2721  931.4543  978.6929  988.2925 1014.6327 1084.0749\n",
      " 1132.9918 1146.8712 1183.449  1201.4082 1218.4596 1263.6667 1280.4286\n",
      " 1292.8799]\n",
      "rounded_abs_wOnsets_dta_ndarray= [ 857  909  931  978  988 1014 1084 1132 1146 1183 1201 1218 1263 1280\n",
      " 1292]\n",
      "[[ 857    0    1]\n",
      " [ 909    0    1]\n",
      " [ 931    0    1]\n",
      " [ 978    0    1]\n",
      " [ 988    0    1]\n",
      " [1014    0    1]\n",
      " [1084    0    1]\n",
      " [1132    0    1]\n",
      " [1146    0    1]\n",
      " [1183    0    1]\n",
      " [1201    0    1]\n",
      " [1218    0    1]\n",
      " [1263    0    1]\n",
      " [1280    0    1]\n",
      " [1292    0    1]\n",
      " [1331    0    1]\n",
      " [1343    0    1]\n",
      " [1356    0    1]\n",
      " [1396    0    1]\n",
      " [1442    0    1]\n",
      " [1458    0    1]\n",
      " [1567    0    1]\n",
      " [1591    0    1]\n",
      " [1602    0    1]\n",
      " [1648    0    1]\n",
      " [1679    0    1]\n",
      " [1709    0    1]\n",
      " [1730    0    1]\n",
      " [1741    0    1]\n",
      " [1776    0    1]\n",
      " [1784    0    1]\n",
      " [1823    0    1]\n",
      " [1849    0    1]\n",
      " [1934    0    1]\n",
      " [1945    0    1]\n",
      " [1954    0    1]\n",
      " [1982    0    1]\n",
      " [1995    0    1]\n",
      " [2045    0    1]\n",
      " [2056    0    1]\n",
      " [2141    0    1]\n",
      " [2154    0    1]\n",
      " [2230    0    1]\n",
      " [2247    0    1]\n",
      " [2264    0    1]\n",
      " [2275    0    1]\n",
      " [2293    0    1]\n",
      " [2325    0    1]\n",
      " [2335    0    1]\n",
      " [2356    0    1]\n",
      " [2396    0    1]\n",
      " [2437    0    1]\n",
      " [2476    0    1]\n",
      " [2509    0    1]\n",
      " [2563    0    1]\n",
      " [2579    0    1]\n",
      " [2805    0    1]\n",
      " [2825    0    1]\n",
      " [2845    0    1]\n",
      " [2870    0    1]\n",
      " [2945    0    1]\n",
      " [2955    0    1]\n",
      " [2979    0    1]\n",
      " [3003    0    1]\n",
      " [3069    0    1]\n",
      " [3094    0    1]\n",
      " [3117    0    1]\n",
      " [3126    0    1]\n",
      " [3145    0    1]\n",
      " [3191    0    1]\n",
      " [3204    0    1]\n",
      " [3212    0    1]\n",
      " [3242    0    1]\n",
      " [3269    0    1]\n",
      " [3289    0    1]\n",
      " [3301    0    1]\n",
      " [3326    0    1]\n",
      " [3358    0    1]\n",
      " [3407    0    1]\n",
      " [3421    0    1]\n",
      " [3540    0    1]\n",
      " [3567    0    1]\n",
      " [3584    0    1]\n",
      " [3630    0    1]\n",
      " [3641    0    1]\n",
      " [3678    0    1]\n",
      " [3690    0    1]\n",
      " [3734    0    1]\n",
      " [3782    0    1]\n",
      " [3800    0    1]\n",
      " [3813    0    1]\n",
      " [3840    0    1]\n",
      " [3848    0    1]\n",
      " [3889    0    1]\n",
      " [3898    0    1]\n",
      " [3937    0    1]\n",
      " [3955    0    1]\n",
      " [3970    0    1]\n",
      " [4004    0    1]\n",
      " [4011    0    1]\n",
      " [4136    0    1]\n",
      " [4156    0    1]\n",
      " [4260    0    1]\n",
      " [4272    0    1]\n",
      " [4309    0    1]\n",
      " [4350    0    1]\n",
      " [4367    0    1]\n",
      " [4404    0    1]\n",
      " [4447    0    1]\n",
      " [4468    0    1]\n",
      " [4509    0    1]\n",
      " [4529    0    1]\n",
      " [4699    0    1]\n",
      " [4716    0    1]\n",
      " [4733    0    1]\n",
      " [4770    0    1]\n",
      " [4799    0    1]\n",
      " [4857    0    1]\n",
      " [4930    0    1]\n",
      " [4946    0    1]\n",
      " [5035    0    1]\n",
      " [5057    0    1]\n",
      " [5073    0    1]\n",
      " [5114    0    1]\n",
      " [5133    0    1]\n",
      " [5143    0    1]\n",
      " [5166    0    1]\n",
      " [5200    0    1]\n",
      " [5231    0    1]\n",
      " [5248    0    1]\n",
      " [5258    0    1]\n",
      " [5268    0    1]\n",
      " [5299    0    1]\n",
      " [5316    0    1]\n",
      " [5333    0    1]\n",
      " [5343    0    1]\n",
      " [5378    0    1]\n",
      " [5402    0    1]\n",
      " [5421    0    1]\n",
      " [5533    0    1]\n",
      " [5546    0    1]\n",
      " [5618    0    1]\n",
      " [5630    0    1]\n",
      " [5683    0    1]\n",
      " [5690    0    1]\n",
      " [5710    0    1]\n",
      " [5724    0    1]\n",
      " [5859    0    1]\n",
      " [5871    0    1]\n",
      " [5889    0    1]\n",
      " [5913    0    1]\n",
      " [5925    0    1]\n",
      " [5958    0    1]\n",
      " [6025    0    1]\n",
      " [6034    0    1]\n",
      " [6074    0    1]\n",
      " [6086    0    1]\n",
      " [6108    0    1]\n",
      " [6145    0    1]\n",
      " [6168    0    1]\n",
      " [6191    0    1]\n",
      " [6208    0    1]\n",
      " [6232    0    1]\n",
      " [6265    0    1]\n",
      " [6289    0    1]\n",
      " [6322    0    1]\n",
      " [6335    0    1]\n",
      " [6358    0    1]\n",
      " [6367    0    1]\n",
      " [6415    0    1]\n",
      " [6426    0    1]\n",
      " [6441    0    1]\n",
      " [6472    0    1]\n",
      " [6496    0    1]]\n",
      "<Epochs |  174 events (all good), -0.3 – 1.2 s, baseline off, ~11.9 MB, data loaded,\n",
      " '1': 174>\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'tape_word_epochs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[138], line 56\u001b[0m\n\u001b[1;32m     54\u001b[0m     tape_perTape_epochs \u001b[38;5;241m=\u001b[39m mne\u001b[38;5;241m.\u001b[39mEpochs(raw, events\u001b[38;5;241m=\u001b[39mwOnset_perTape_events, event_id\u001b[38;5;241m=\u001b[39mi\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m, tmin\u001b[38;5;241m=\u001b[39mtmin, tmax\u001b[38;5;241m=\u001b[39mtmax, baseline\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, preload\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     55\u001b[0m     \u001b[38;5;28mprint\u001b[39m(tape_perTape_epochs)\n\u001b[0;32m---> 56\u001b[0m all_tapes_epochs\u001b[38;5;241m.\u001b[39mappend(tape_word_epochs)\n\u001b[1;32m     60\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;124;03mfor i, stimulus_idx in enumerate(trial_indexes):\u001b[39;00m\n\u001b[1;32m     62\u001b[0m \u001b[38;5;124;03m    # We find the start of the tape in the raw EEG\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[38;5;124;03m# eeg_data = ds_all_words['eeg'].get_data()\u001b[39;00m\n\u001b[1;32m     89\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tape_word_epochs' is not defined"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "## (Not using this version) Trying the old way (Tape order 1st then subject cut 2nd)##\n",
    "\n",
    "# epochs parameters\n",
    "# Define your epoch window\n",
    "# We use a 1.5s window (including buffers for HHSA)\n",
    "tmin, tmax = -0.3, 1.2 \n",
    "\n",
    "# Get the actual word onset based on EEG triggers datapoints\n",
    "for i, stimulus_idx in enumerate(trial_indexes):\n",
    "    # Find the word onset time based on the segment sequence    \n",
    "    wOnset_perTape_DF = word_onset_essentials_DF.loc[word_onset_essentials_DF[\"Segment\"] == i+1, :] #.to_numpy()\n",
    "    #wOnset_time_ndarray = wOnset_perTape_DF[\"onset\"].to_numpy() #*raw_sfreq\n",
    "    wOnset_datapoints_ndarray = wOnset_perTape_DF[\"onset\"].to_numpy()*raw_sfreq\n",
    "    print(\"wOnset_datapoints_ndarray=\", wOnset_datapoints_ndarray[0:15], type(wOnset_datapoints_ndarray))\n",
    "\n",
    "    for subject in SUBJECTS[0:3]:\n",
    "        print(\"subject_num=\", subject)\n",
    "        print(\"tape_num=\", i+1)\n",
    "        \n",
    "        # 1. Load Raw as an Eelbrain-compatible object\n",
    "        raw = mne.io.read_raw_fif(EEG_DIR / f'{subject}', preload=True)\n",
    "        raw_sfreq = raw.info['sfreq']\n",
    "        \n",
    "        # 2. Get the events for the 12 tapes\n",
    "        events_DICT = eelbrain.load.mne.events(raw)\n",
    "\n",
    "        # Get the tape start time\n",
    "        tape_start_datapoints_npINT64 = events_DICT[i]['i_start']\n",
    "        #tape_start_time_npFLOAT64 = tape_start_datapoints_npINT64 / raw_sfreq\n",
    "        print(\"tape_start_datapoints_npINT64=\", tape_start_datapoints_npINT64)\n",
    "        #print(\"tape_start_time_npFLOAT64=\", tape_start_time_npFLOAT64, type(tape_start_time_npFLOAT64))\n",
    "\n",
    "        # Get the actual word onset time by the triggers\n",
    "        #absolute_onsets_time_ndarray = tape_start_time_npFLOAT64 + wOnset_time_ndarray\n",
    "        #print(\"absolute_onsets_time_ndarray=\", absolute_onsets_time_ndarray[0:15])\n",
    "        abs_wOnsets_dta_ndarray = tape_start_datapoints_npINT64 + wOnset_datapoints_ndarray\n",
    "        print(\"abs_wOnsets_dta_ndarray=\", abs_wOnsets_dta_ndarray[0:15])\n",
    "        \n",
    "        # To exclude the decimal but leave the integer along, and turn FLOAT into INT\n",
    "        abs_wOnsets_dta_ndarray = np.trunc(abs_wOnsets_dta_ndarray).astype(int)\n",
    "        print(\"rounded_abs_wOnsets_dta_ndarray=\", abs_wOnsets_dta_ndarray[0:15])\n",
    "\n",
    "        # Make epochs\n",
    "        # Create the empty (N, 3) event matrix based on wOnset per tape\n",
    "        wOnset_events = len(abs_wOnsets_dta_ndarray)\n",
    "        wOnset_perTape_events = np.zeros((wOnset_events, 3), dtype=int)\n",
    "        # Fill the columns\n",
    "        wOnset_perTape_events[:, 0] = abs_wOnsets_dta_ndarray  # Column 0: The sample indices\n",
    "        wOnset_perTape_events[:, 2] = i+1           # Column 2: The event ID (e.g., 1)\n",
    "        print(wOnset_perTape_events)\n",
    "\n",
    "        \n",
    "        #word_perTape_epochs = mne.epochs(raw, tmin=tmin, tmax=tmax, baseline=None, events=wOnset_perTape_events)\n",
    "        tape_perTape_epochs = mne.Epochs(raw, events=wOnset_perTape_events, event_id=i+1, tmin=tmin, tmax=tmax, baseline=None, preload=True)\n",
    "        print(tape_perTape_epochs)\n",
    "    all_tapes_epochs.append(tape_word_epochs)\n",
    "\"\"\"        \n",
    "    \n",
    "\n",
    "    \"\"\"(Gemini-Produced)\n",
    "    for i, stimulus_idx in enumerate(trial_indexes):\n",
    "        # We find the start of the tape in the raw EEG\n",
    "        tape_start = events[i]['i_start']#['time']\n",
    "        print([i], tape_start, type(tape_start))\n",
    "        \n",
    "        # Get word onset times for this specific tape from your list\n",
    "        # word_onsets[stimulus_idx] is your impulse predictor\n",
    "        onsets = word_onsets[stimulus_idx].time.times[word_onsets[stimulus_idx].x > 0]\n",
    "        print(onsets, len(onsets))\n",
    "    \n",
    "        \n",
    "        # Convert relative word times to absolute EEG times\n",
    "        absolute_onsets = tape_start + onsets\n",
    "        \n",
    "        # Create segments (Epochs) directly in Eelbrain\n",
    "        # This is much faster and more accurate than manual padding/cropping\n",
    "        tape_word_epochs = mne.epochs(\n",
    "            raw, tmin=tmin, tmax=tmax, baseline=None, \n",
    "            events=absolute_onsets\n",
    "        )\n",
    "        all_tapes_epochs.append(tape_word_epochs)\n",
    "    \n",
    "    # 5. Combine all words from all tapes into one Dataset\n",
    "    # This 'ds' will have a column for 'EEG' and can have a column for 'Subject'\n",
    "    ds_all_words = eelbrain.combine(all_tapes_epochs)\n",
    "    \n",
    "    # Now you can access the data for HHSA:\n",
    "    # eeg_data = ds_all_words['eeg'].get_data()\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a31e8146-2195-473f-82b8-cec8f4056a3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load stimuli\n",
    "# ------------\n",
    "# Make sure to name the stimuli so that the TRFs can later be distinguished\n",
    "# Load the gammatone-spectrograms; use the time axis of these as reference\n",
    "gammatone = [eelbrain.load.unpickle(PREDICTOR_audio_DIR / f'{stimulus}~gammatone-8.pickle') for stimulus in STIMULI]\n",
    "\n",
    "# Resample the spectrograms to 100 Hz (time-step = 0.01 s), which we will use for TRFs\n",
    "gammatone = [x.bin(0.01, dim='time', label='start') for x in gammatone]\n",
    "\n",
    "# Pad onset with 100 ms and offset with 1 second; make sure to give the predictor a unique name as that will make it easier to identify the TRF later\n",
    "gammatone = [eelbrain.pad(x, tstart=-0.100, tstop=x.time.tstop + 1, name='gammatone') for x in gammatone]\n",
    "\n",
    "# Load the broad-band envelope and process it in the same way\n",
    "envelope = [eelbrain.load.unpickle(PREDICTOR_audio_DIR / f'{stimulus}~gammatone-1.pickle') for stimulus in STIMULI]  # Load in the data\n",
    "envelope = [x.bin(0.01, dim='time', label='start') for x in envelope]\n",
    "envelope = [eelbrain.pad(x, tstart=-0.100, tstop=x.time.tstop + 1, name='envelope') for x in envelope]\n",
    "onset_envelope = [eelbrain.load.unpickle(PREDICTOR_audio_DIR / f'{stimulus}~gammatone-on-1.pickle') for stimulus in STIMULI]\n",
    "onset_envelope = [x.bin(0.01, dim='time', label='start') for x in onset_envelope]\n",
    "onset_envelope = [eelbrain.pad(x, tstart=-0.100, tstop=x.time.tstop + 1, name='onset') for x in onset_envelope]\n",
    "\n",
    "# Load onset spectrograms and make sure the time dimension is equal to the gammatone spectrograms\n",
    "gammatone_onsets = [eelbrain.load.unpickle(PREDICTOR_audio_DIR / f'{stimulus}~gammatone-on-8.pickle') for stimulus in STIMULI]\n",
    "gammatone_onsets = [x.bin(0.01, dim='time', label='start') for x in gammatone_onsets]\n",
    "gammatone_onsets = [eelbrain.set_time(x, gt.time, name='gammatone_on') for x, gt in zip(gammatone_onsets, gammatone)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6973146b-a3bb-45c9-b959-46dfd49466ab",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'word_onsets' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 29\u001b[0m\n\u001b[1;32m     25\u001b[0m     tape_start \u001b[38;5;241m=\u001b[39m events[i][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mi_start\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;66;03m#['time']\u001b[39;00m\n\u001b[1;32m     27\u001b[0m     \u001b[38;5;66;03m# Get word onset times for this specific tape from your list\u001b[39;00m\n\u001b[1;32m     28\u001b[0m     \u001b[38;5;66;03m# word_onsets[stimulus_idx] is your impulse predictor\u001b[39;00m\n\u001b[0;32m---> 29\u001b[0m     onsets \u001b[38;5;241m=\u001b[39m word_onsets[stimulus_idx]\u001b[38;5;241m.\u001b[39mtime\u001b[38;5;241m.\u001b[39mtimes[word_onsets[stimulus_idx]\u001b[38;5;241m.\u001b[39mx \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     30\u001b[0m     \u001b[38;5;28mprint\u001b[39m(onsets, \u001b[38;5;28mlen\u001b[39m(onsets))\n\u001b[1;32m     32\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;124;03m    # Convert relative word times to absolute EEG times\u001b[39;00m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;124;03m    absolute_onsets = tape_start + onsets\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;124;03m# eeg_data = ds_all_words['eeg'].get_data()\u001b[39;00m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'word_onsets' is not defined"
     ]
    }
   ],
   "source": [
    "## Got to the wrong length of the word onset\n",
    "\n",
    "## Gemini-Produced\n",
    "## To segment the raw EEG based on word start time == word onset time ##\n",
    "# ... your loading code ...\n",
    "\n",
    "for subject in SUBJECTS:\n",
    "    # 1. Load Raw as an Eelbrain-compatible object\n",
    "    raw = mne.io.read_raw_fif(EEG_DIR / f'{subject}', preload=True)\n",
    "    raw_sfreq = raw.info['sfreq']\n",
    "    \n",
    "    # 2. Get the events for the 12 tapes\n",
    "    events = eelbrain.load.mne.events(raw)\n",
    "    trial_indexes = [STIMULI.index(stimulus) for stimulus in events['event']]\n",
    "    \n",
    "    # 3. Define your epoch window\n",
    "    # We use a 1.5s window (including buffers for HHSA)\n",
    "    tmin, tmax = -0.3, 1.2 \n",
    "    \n",
    "    # 4. Extract segments for each tape\n",
    "    # This creates a list of NDVars, each containing the epochs for one tape\n",
    "    all_tapes_epochs = []\n",
    "    \n",
    "    for i, stimulus_idx in enumerate(trial_indexes):\n",
    "        # We find the start of the tape in the raw EEG\n",
    "        tape_start = events[i]['i_start']#['time']\n",
    "        \n",
    "        # Get word onset times for this specific tape from your list\n",
    "        # word_onsets[stimulus_idx] is your impulse predictor\n",
    "        onsets = word_onsets[stimulus_idx].time.times[word_onsets[stimulus_idx].x > 0]\n",
    "        print(onsets, len(onsets))\n",
    "\n",
    "        \"\"\"\n",
    "        # Convert relative word times to absolute EEG times\n",
    "        absolute_onsets = tape_start + onsets\n",
    "        \n",
    "        # Create segments (Epochs) directly in Eelbrain\n",
    "        # This is much faster and more accurate than manual padding/cropping\n",
    "        tape_word_epochs = mne.epochs(\n",
    "            raw, tmin=tmin, tmax=tmax, baseline=None, \n",
    "            events=absolute_onsets\n",
    "        )\n",
    "        all_tapes_epochs.append(tape_word_epochs)\n",
    "\n",
    "    # 5. Combine all words from all tapes into one Dataset\n",
    "    # This 'ds' will have a column for 'EEG' and can have a column for 'Subject'\n",
    "    ds_all_words = eelbrain.combine(all_tapes_epochs)\n",
    "    \n",
    "    # Now you can access the data for HHSA:\n",
    "    # eeg_data = ds_all_words['eeg'].get_data()\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "905b472f-1749-48cb-8b3e-85b9c14126d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== WORD ONSET IS DOWN BELOW =====\n",
      "<NDVar 'word': 500 time>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\n# Estimate TRFs\\n# -------------\\n# Loop through subjects to estimate TRFs\\nfor subject in SUBJECTS:\\n    subject_trf_dir = TRF_DIR / subject[:3]\\n    subject_trf_dir.mkdir(exist_ok=True)\\n    # Generate all TRF paths so we can check whether any new TRFs need to be estimated\\n    trf_paths = {model: subject_trf_dir / f'{subject[:3]} {model}.pickle' for model in models}\\n    # Skip this subject if all files already exist\\n    #if all(path.exists() for path in trf_paths.values()):\\n        #continue\\n    # Load the EEG data\\n    raw = mne.io.read_raw_fif(EEG_DIR / f'{subject}', preload=True)  # subject /\\n    # Band-pass filter the raw data between 0.5 and 20 Hz\\n    raw.filter(0.5, 20)\\n    # Interpolate bad channels\\n    raw.interpolate_bads()\\n    # Extract the events marking the stimulus presentation from the EEG file\\n    events = eelbrain.load.fiff.events(raw)\\n    # Not all subjects have all trials; determine which stimuli are present\\n    trial_indexes = [STIMULI.index(stimulus) for stimulus in events['event']]\\n    # Extract the EEG data segments corresponding to the stimuli\\n    trial_durations = [durations[i] for i in trial_indexes]\\n    eeg = eelbrain.load.fiff.variable_length_epochs(events, -0.100, trial_durations, connectivity='auto')  #, decim=5 #decim=5 meaning to resample to sfreq=100Hz\\n    # Since trials are of unequal length, we will concatenate them for the TRF estimation.\\n    eeg_concatenated = eelbrain.concatenate(eeg)\\n    \\n    pprint(models.items)\\n    \""
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## This is the time point of every word onset time according to the Alice csv file ##\n",
    "\n",
    "# Load word tables and convert tables into continuous time-series with matching time dimension\n",
    "word_tables = [eelbrain.load.unpickle(PREDICTOR_word_DIR / f'{stimulus}~word.pickle') for stimulus in STIMULI]\n",
    "word_onsets = [eelbrain.event_impulse_predictor(gt.time, ds=ds, name='word') for gt, ds in zip(gammatone, word_tables)]\n",
    "\n",
    "#print(word_tables[-1]) #  the onset & offset of each tape\n",
    "print(\"===== WORD ONSET IS DOWN BELOW =====\")\n",
    "print(word_onsets[0][0:5])\n",
    "# This is the original Durations of 12 tapes based on gammatone\n",
    "# Extract the duration of the stimuli, so we can later match the EEG to the stimuli\n",
    "durations = [gt.time.tmax for stimulus, gt in zip(STIMULI, gammatone)]\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "# Estimate TRFs\n",
    "# -------------\n",
    "# Loop through subjects to estimate TRFs\n",
    "for subject in SUBJECTS:\n",
    "    subject_trf_dir = TRF_DIR / subject[:3]\n",
    "    subject_trf_dir.mkdir(exist_ok=True)\n",
    "    # Generate all TRF paths so we can check whether any new TRFs need to be estimated\n",
    "    trf_paths = {model: subject_trf_dir / f'{subject[:3]} {model}.pickle' for model in models}\n",
    "    # Skip this subject if all files already exist\n",
    "    #if all(path.exists() for path in trf_paths.values()):\n",
    "        #continue\n",
    "    # Load the EEG data\n",
    "    raw = mne.io.read_raw_fif(EEG_DIR / f'{subject}', preload=True)  # subject /\n",
    "    # Band-pass filter the raw data between 0.5 and 20 Hz\n",
    "    raw.filter(0.5, 20)\n",
    "    # Interpolate bad channels\n",
    "    raw.interpolate_bads()\n",
    "    # Extract the events marking the stimulus presentation from the EEG file\n",
    "    events = eelbrain.load.fiff.events(raw)\n",
    "    # Not all subjects have all trials; determine which stimuli are present\n",
    "    trial_indexes = [STIMULI.index(stimulus) for stimulus in events['event']]\n",
    "    # Extract the EEG data segments corresponding to the stimuli\n",
    "    trial_durations = [durations[i] for i in trial_indexes]\n",
    "    eeg = eelbrain.load.fiff.variable_length_epochs(events, -0.100, trial_durations, connectivity='auto')  #, decim=5 #decim=5 meaning to resample to sfreq=100Hz\n",
    "    # Since trials are of unequal length, we will concatenate them for the TRF estimation.\n",
    "    eeg_concatenated = eelbrain.concatenate(eeg)\n",
    "    \n",
    "    pprint(models.items)\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94f36ef5-03af-4e7e-84fa-68e3009bf109",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import eelbrain\n",
    "from pathlib import Path\n",
    "import re\n",
    "import emd  # Ensure you ran: pip install EMD-signal\n",
    "from scipy.signal import hilbert\n",
    "\"\"\"\n",
    "\n",
    "## Conduct HHSA ##\n",
    "## Step one\n",
    "\n",
    "\n",
    "# ==========================================\n",
    "# 1. CORE ANALYSIS FUNCTIONS\n",
    "# ==========================================\n",
    "def get_inst_freq_amp(signal, fs):\n",
    "    \"\"\"\n",
    "    Calculates instantaneous amplitude and frequency using Hilbert Transform.\n",
    "    \"\"\"\n",
    "    analytic_signal = hilbert(signal)\n",
    "    amplitude = np.abs(analytic_signal)\n",
    "    instantaneous_phase = np.unwrap(np.angle(analytic_signal))\n",
    "    \n",
    "    # Derivative of phase for frequency\n",
    "    inst_freq = np.diff(instantaneous_phase) / (2.0 * np.pi) * fs\n",
    "    # Pad last point to match length\n",
    "    inst_freq = np.append(inst_freq, inst_freq[-1])\n",
    "    \n",
    "    return amplitude, inst_freq\n",
    "\n",
    "def run_hhsa(signal, fs):\n",
    "    \"\"\"\n",
    "    Performs Two-Layer EMD with Mirror Padding for short signals.\n",
    "    \"\"\"\n",
    "    if signal.ndim > 1: signal = signal.flatten()\n",
    "    \n",
    "    n_samples = len(signal)\n",
    "    \n",
    "    # Safety Check for empty/tiny signals\n",
    "    if n_samples < 10: return None\n",
    "\n",
    "    # --- A. MIRROR PADDING (Crucial for 114-point TRFs) ---\n",
    "    # We reflect the signal to make it 3x longer so EMD works\n",
    "    pad_width = n_samples\n",
    "    padded_signal = np.pad(signal, pad_width, mode='reflect')\n",
    "    \n",
    "    # --- B. LAYER 1: CARRIER DECOMPOSITION ---\n",
    "    try:\n",
    "        # Use emd.sift.sift (Quinn library)\n",
    "        # max_imfs=5 is enough for a simple TRF response\n",
    "        imfs_layer1 = emd.sift.sift(padded_signal, max_imfs=5)\n",
    "        imfs_layer1 = imfs_layer1.T  # Transpose to (N_IMFs, N_Time)\n",
    "    except Exception:\n",
    "        return None\n",
    "        \n",
    "    holo_points = []\n",
    "    \n",
    "    for imf_c in imfs_layer1:\n",
    "        # Un-pad: Extract the middle 'real' part\n",
    "        imf_c_real = imf_c[pad_width : pad_width + n_samples]\n",
    "        \n",
    "        # Get Carrier Frequency & Envelope\n",
    "        env_c, freq_c = get_inst_freq_amp(imf_c_real, fs)\n",
    "        \n",
    "        # Skip flat/empty IMFs\n",
    "        if np.sum(np.abs(env_c)) < 1e-10: continue\n",
    "\n",
    "        # --- C. LAYER 2: AM DECOMPOSITION ---\n",
    "        # Pad the envelope before sifting\n",
    "        padded_env = np.pad(env_c, pad_width, mode='reflect')\n",
    "        \n",
    "        try:\n",
    "            imfs_layer2 = emd.sift.sift(padded_env, max_imfs=5)\n",
    "            imfs_layer2 = imfs_layer2.T\n",
    "        except:\n",
    "            continue\n",
    "            \n",
    "        for imf_am in imfs_layer2:\n",
    "            # Un-pad AM result\n",
    "            imf_am_real = imf_am[pad_width : pad_width + n_samples]\n",
    "            \n",
    "            _, freq_am = get_inst_freq_amp(imf_am_real, fs)\n",
    "            power_am = imf_am_real**2\n",
    "            \n",
    "            # Filter for valid graph range\n",
    "            mask = (freq_c > 0) & (freq_c < fs/2) & (freq_am > 0) & (freq_am < fs/2)\n",
    "            idx = np.where(mask)[0]\n",
    "            \n",
    "            if len(idx) > 0:\n",
    "                # Store [Carrier_Freq, AM_Freq, Power]\n",
    "                points = np.vstack((freq_c[idx], freq_am[idx], power_am[idx])).T\n",
    "                holo_points.append(points)\n",
    "                \n",
    "    if not holo_points: return None\n",
    "    return np.vstack(holo_points)\n",
    "\n",
    "# ==========================================\n",
    "# 2. EXPERIMENT CONFIGURATION\n",
    "# ==========================================\n",
    "DATA_ROOT = Path(\"/Users/neuroling/Downloads/DINGHSIN_Results/Alice_Experiments_Results\")\n",
    "EEG_DIR = DATA_ROOT / 'EEG_ESLs' / 'Alice_ESL_ICAed_fif'\n",
    "TRF_DIR = DATA_ROOT / 'TRFs_ESLs'\n",
    "\n",
    "# Extract Subjects\n",
    "ESL_SUBJECTS = [path.name for path in EEG_DIR.iterdir() if re.match(r'n_2_S\\d*', path.name)]\n",
    "print(f\"Found {len(ESL_SUBJECTS)} subjects.\")\n",
    "\n",
    "# Settings\n",
    "TARGET_MODEL = 'Fzero'\n",
    "LIMIT_CARRIER = 5  # Hz\n",
    "LIMIT_AM = 5       # Hz\n",
    "NBINS = 50\n",
    "\n",
    "group_spectrum_sum = None\n",
    "n_subjects_processed = 0\n",
    "\n",
    "# ==========================================\n",
    "# 3. MAIN LOOP\n",
    "# ==========================================\n",
    "print(f\"Starting Group HHSA on Model: {TARGET_MODEL}\")\n",
    "\n",
    "for subject in ESL_SUBJECTS:\n",
    "    subject_id_short = subject[4:8] # 'S010'\n",
    "    file_path = TRF_DIR / subject_id_short / f'{subject_id_short} {TARGET_MODEL}.pickle'\n",
    "    \n",
    "    if not file_path.exists():\n",
    "        continue\n",
    "\n",
    "    try:\n",
    "        # --- LOAD DATA ---\n",
    "        trf_obj = eelbrain.load.unpickle(file_path)\n",
    "        \n",
    "        # Handle h vs h_scaled\n",
    "        if hasattr(trf_obj, 'h_scaled'):\n",
    "            data_ndvar = trf_obj.h_scaled\n",
    "        else:\n",
    "            data_ndvar = trf_obj.h\n",
    "\n",
    "        # Handle Tuple (Partitioned Data)\n",
    "        if isinstance(data_ndvar, tuple):\n",
    "            data_ndvar = data_ndvar[0]\n",
    "\n",
    "        # --- EXTRACT PREDICTOR ---\n",
    "        trf_final = None\n",
    "        \n",
    "        # Strategy 1: Try name 'envelope'\n",
    "        try:\n",
    "            trf_final = data_ndvar['Fzero']\n",
    "        except:\n",
    "            # Strategy 2: Try Index\n",
    "            # If dims are [predictor, time], we grab the 2nd predictor (index 1)\n",
    "            # Assuming the order is [F0, Envelope]\n",
    "            dims = data_ndvar.dimnames\n",
    "            non_time_dims = [d for d in dims if d != 'time' and d != 'sensor']\n",
    "            \n",
    "            if len(non_time_dims) > 0:\n",
    "                dim_name = non_time_dims[0]\n",
    "                # Index 1 = Envelope. Change to 0 if you want F0.\n",
    "                trf_final = data_ndvar.sub(**{dim_name: 1}) \n",
    "            else:\n",
    "                trf_final = data_ndvar\n",
    "\n",
    "        # Average Sensors\n",
    "        if 'sensor' in trf_final.dimnames:\n",
    "            trf_final = trf_final.mean('sensor')\n",
    "            \n",
    "        trf_vector = trf_final.x\n",
    "        fs = 1.0 / trf_final.time.tstep\n",
    "        \n",
    "        # --- RUN HHSA ---\n",
    "        # print(f\"  Processing {subject_id_short}...\")\n",
    "        holo_data = run_hhsa(trf_vector, fs)\n",
    "        \n",
    "        if holo_data is None: \n",
    "            continue\n",
    "            \n",
    "        # --- DEBUG PRINT ---\n",
    "        # Print the average frequencies found for this subject\n",
    "        avg_fc = np.mean(holo_data[:, 0])\n",
    "        avg_fam = np.mean(holo_data[:, 1])\n",
    "        print(f\"  Subject {subject_id_short}: Avg Carrier={avg_fc:.2f}Hz, Avg AM={avg_fam:.2f}Hz\")\n",
    "        # -------------------\n",
    "        \n",
    "\n",
    "        # --- BIN RESULTS ---\n",
    "        fc = holo_data[:, 0]\n",
    "        fam = holo_data[:, 1]\n",
    "        power = holo_data[:, 2]\n",
    "        \n",
    "        H_subj, xedges, yedges = np.histogram2d(fc, fam, bins=NBINS, weights=power,\n",
    "                                           range=[[0, LIMIT_CARRIER], [0, LIMIT_AM]])\n",
    "        \n",
    "        if group_spectrum_sum is None:\n",
    "            group_spectrum_sum = H_subj\n",
    "        else:\n",
    "            group_spectrum_sum += H_subj\n",
    "            \n",
    "        n_subjects_processed += 1\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"  [Error] Failed on {subject_id_short}: {e}\")\n",
    "        continue\n",
    "\n",
    "# ==========================================\n",
    "# 4. PLOT FINAL RESULT\n",
    "# ==========================================\n",
    "if n_subjects_processed > 0:\n",
    "    group_avg_spectrum = group_spectrum_sum / n_subjects_processed\n",
    "    \n",
    "    plt.figure(figsize=(10, 8))\n",
    "    # Note: .T is used because imshow expects [rows, cols] = [y, x]\n",
    "    plt.imshow(group_avg_spectrum.T, origin='lower', cmap='jet', aspect='auto',\n",
    "               extent=[0, LIMIT_CARRIER, 0, LIMIT_AM], interpolation='gaussian')\n",
    "    \n",
    "    plt.colorbar(label='Modulation Power (a.u.)')\n",
    "    plt.xlabel('Carrier Frequency (Hz)')\n",
    "    plt.ylabel('AM Frequency (Hz)')\n",
    "    plt.title(f'Group HHSA (N={n_subjects_processed})\\nModel: {TARGET_MODEL} | Predictor: Envelope')\n",
    "    \n",
    "    # Diagonal line (1:1 coupling)\n",
    "    plt.plot([0, LIMIT_AM], [0, LIMIT_AM], 'w--', alpha=0.5)\n",
    "    plt.savefig(TRF_DIR / 'ESLs_Fzero_HHSA_TRF.png')\n",
    "    plt.show()\n",
    "    print(\"Success!\")\n",
    "else:\n",
    "    print(\"No subjects processed. Please check if pickle files contain the expected data structure.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c8ada7a-18b9-46c9-9480-435c3278c2cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import eelbrain\n",
    "from pathlib import Path\n",
    "import emd\n",
    "from scipy.signal import hilbert\n",
    "\"\"\"\n",
    "# Version 1 of IMFs in each layers (=second EMD)\n",
    "\n",
    "# ==========================================\n",
    "# 1. CONFIGURATION\n",
    "# ==========================================\n",
    "DATA_ROOT = Path(\"/Users/neuroling/Downloads/DINGHSIN_Results/Alice_Experiments_Results\")\n",
    "TRF_DIR = DATA_ROOT / 'TRFs_ESLs'\n",
    "TARGET_MODEL = 'Fzero+envelope'\n",
    "TARGET_SUBJECT = 'S010'  # <--- Change this to look at different subjects\n",
    "\n",
    "# Which Layer 1 IMF do you want to decompose further?\n",
    "# 0 = First IMF (Fastest/Highest Freq), 1 = Second IMF, etc.\n",
    "TARGET_IMF_INDEX = 1 \n",
    "\n",
    "# ==========================================\n",
    "# 2. LOAD DATA (Robust Loading)\n",
    "# ==========================================\n",
    "file_path = TRF_DIR / TARGET_SUBJECT / f'{TARGET_SUBJECT} {TARGET_MODEL}.pickle'\n",
    "print(f\"Loading {TARGET_SUBJECT}...\")\n",
    "\n",
    "try:\n",
    "    trf_obj = eelbrain.load.unpickle(file_path)\n",
    "    \n",
    "    # Handle h vs h_scaled\n",
    "    if hasattr(trf_obj, 'h_scaled'):\n",
    "        data_ndvar = trf_obj.h_scaled\n",
    "    else:\n",
    "        data_ndvar = trf_obj.h\n",
    "        \n",
    "    # Handle Tuple\n",
    "    if isinstance(data_ndvar, tuple):\n",
    "        data_ndvar = data_ndvar[0]\n",
    "\n",
    "    # Extract Predictor (Strategy: Index)\n",
    "    # Assumes order is [F0, Envelope] -> Index 1 is Envelope\n",
    "    # If your model is just 'envelope', it might be Index 0.\n",
    "    try:\n",
    "        # Try finding 'envelope' by name\n",
    "        trf_final = data_ndvar['envelope']\n",
    "        pred_name = \"Envelope\"\n",
    "    except:\n",
    "        # Fallback to Index 1\n",
    "        dims = data_ndvar.dimnames\n",
    "        non_time_dims = [d for d in dims if d != 'time' and d != 'sensor']\n",
    "        if len(non_time_dims) > 0:\n",
    "            trf_final = data_ndvar.sub(**{non_time_dims[0]: 1})\n",
    "            pred_name = \"Predictor (Index 1)\"\n",
    "        else:\n",
    "            trf_final = data_ndvar\n",
    "            pred_name = \"Predictor\"\n",
    "\n",
    "    # Average Sensors\n",
    "    if 'sensor' in trf_final.dimnames:\n",
    "        trf_final = trf_final.mean('sensor')\n",
    "        \n",
    "    signal = trf_final.x\n",
    "    times = trf_final.time.times\n",
    "    fs = 1.0 / trf_final.time.tstep\n",
    "\n",
    "    if signal.ndim > 1: signal = signal.flatten()\n",
    "    print(f\"Data Loaded: {len(signal)} samples\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error loading: {e}\")\n",
    "    exit()\n",
    "\n",
    "# ==========================================\n",
    "# 3. PROCESSING (With Mirror Padding)\n",
    "# ==========================================\n",
    "\n",
    "# --- A. Layer 1 Decomposition ---\n",
    "pad_width = len(signal)\n",
    "padded_signal = np.pad(signal, pad_width, mode='reflect')\n",
    "\n",
    "# Run EMD (Sift)\n",
    "imfs_layer1_padded = emd.sift.sift(padded_signal, max_imfs=5)\n",
    "\n",
    "# Un-pad Layer 1\n",
    "# Note: emd output is (Samples, IMFs)\n",
    "imfs_layer1 = imfs_layer1_padded[pad_width : pad_width + len(signal), :]\n",
    "n_imfs1 = imfs_layer1.shape[1]\n",
    "\n",
    "# --- B. Layer 2 Decomposition (Target IMF) ---\n",
    "# Extract the target IMF (e.g., IMF 0)\n",
    "target_imf_padded = imfs_layer1_padded[:, TARGET_IMF_INDEX]\n",
    "\n",
    "# Get Envelope (using Hilbert)\n",
    "analytic = hilbert(target_imf_padded)\n",
    "envelope_padded = np.abs(analytic)\n",
    "\n",
    "# Run EMD on Envelope\n",
    "imfs_layer2_padded = emd.sift.sift(envelope_padded, max_imfs=4)\n",
    "\n",
    "# Un-pad Layer 2\n",
    "envelope_real = envelope_padded[pad_width : pad_width + len(signal)]\n",
    "imfs_layer2 = imfs_layer2_padded[pad_width : pad_width + len(signal), :]\n",
    "n_imfs2 = imfs_layer2.shape[1]\n",
    "\n",
    "# ==========================================\n",
    "# 4. PLOTTING\n",
    "# ==========================================\n",
    "\n",
    "# --- FIGURE 1: LAYER 1 (Carrier) ---\n",
    "fig1, axes1 = plt.subplots(n_imfs1 + 1, 1, figsize=(10, 8), sharex=True)\n",
    "fig1.suptitle(f\"Layer 1: Carrier Decomposition ({TARGET_SUBJECT})\", fontsize=14)\n",
    "\n",
    "# Plot Original Signal\n",
    "axes1[0].plot(times, signal, 'k', label='Original TRF')\n",
    "axes1[0].set_title(f\"Original Signal: {pred_name}\")\n",
    "axes1[0].legend(loc='upper right')\n",
    "\n",
    "# Plot IMFs\n",
    "for i in range(n_imfs1):\n",
    "    ax = axes1[i + 1]\n",
    "    ax.plot(times, imfs_layer1[:, i], 'b')\n",
    "    ax.set_ylabel(f\"IMF {i+1}\")\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "axes1[-1].set_xlabel(\"Time (s)\")\n",
    "plt.tight_layout()\n",
    "#plt.savefig(TRF_DIR / 'ESLs_S010_layer1-IMFs_HHSA_TRF.png')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# --- FIGURE 2: LAYER 2 (Amplitude Modulation) ---\n",
    "fig2, axes2 = plt.subplots(n_imfs2 + 1, 1, figsize=(10, 8), sharex=True)\n",
    "fig2.suptitle(f\"Layer 2: AM Decomposition of Carrier IMF {TARGET_IMF_INDEX+1}\", fontsize=14)\n",
    "\n",
    "# Plot Envelope\n",
    "axes2[0].plot(times, envelope_real, 'r', label=f'Envelope of IMF {TARGET_IMF_INDEX+1}')\n",
    "axes2[0].set_title(\"Amplitude Envelope (Input to Layer 2)\")\n",
    "axes2[0].legend(loc='upper right')\n",
    "\n",
    "# Plot AM IMFs\n",
    "for i in range(n_imfs2):\n",
    "    ax = axes2[i + 1]\n",
    "    ax.plot(times, imfs_layer2[:, i], 'g')\n",
    "    ax.set_ylabel(f\"AM IMF {i+1}\")\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "axes2[-1].set_xlabel(\"Time (s)\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(TRF_DIR / 'ESLs_S010_layer2-IMF2_HHSA_TRF.png')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
